\chapter{Boolean Formulas and Equations}
\label{ch:Boolean-Formulas}

\section{Reasoning with Equations}
\label{sec:math-and-equations}
\index{symbolic logic}\index{logic, symbolic}Symbolic logic, 
like other parts of mathematics, starts from a small
collection of axioms and employs rules of inference to find
additional propositions consistent with those axioms. This
chapter will define a grammar of logic formulas, specify a few
equations stating that certain formulas carry the same meaning as others,
and derive new equations
using substitution of equals for equals as the rule of
inference.

You will probably find this familiar from your
experience with numeric algebra, but the discourse here will attend carefully
to details, and this formality may extend beyond what you are
accustomed to. What it buys us is mechanization. That is,
logic formulas and reasoning about them will amount to
mechanized computation, and this will make it possible for
computers to check that our reasoning follows all the rules,
without exception. This provides a higher level of confidence
in conclusions than would otherwise be possible.

\begin{aside}
\emph{Hold on to your seat!}
This section illustrates an essential method used throughout the book.
It introduces the notion of ``formality'' in mathematics.
That is, \index{formalism}formality in the sense of being based on formulas.
The formulas have a prescribed grammar similar to the one
for ordinary numeric formulas.
The grammar determines which formulas are well formed
(that is, grammatically correct) and which are not.
For example, ``$x+3\times(y + z)$'' conforms to the grammar
of numeric formulas,
so it is grammatically correct,
but the non-formula ``$x+3\times(y + ) \times z$'' is not.

Things may seem overly simple in the beginning.
Then, suddenly, you may find yourself thrashing around in deep water.
Take a deep breath, and slowly work  through the material.
It provides a basis for everything to follow.
The ideas and methods call for careful study and frequent review.
When things start to go off track,
just slow down, back up a little, and try again.
Gradually, the pieces will fall into place.
\caption{Hold on to Your Seat}
\label{aside-hold-on-to-seat}
\end{aside}

We will be doing all of this in the domain of symbolic logic, which
includes operations like ``logical or'' and ``logical negation'',
rather than arithmetic operations, such as addition and
multiplication.
We will be doing Boolean algebra, rather than numeric algebra,
but the rule of inference that the reasoning is based on,
namely substitution of equals for equals,
applies equally well to both Boolean and numeric formulas.
To illustrate the level of formality that we are shooting for,
let's see how it works with a problem
in the familiar domain of numeric algebra.

You are surely familiar with the equation $(-1)\times(-1) = 1$, but you may
not know that it is a consequence of some basic facts about
arithmetic.
That is, the fact that multiplying two
negative numbers produces a positive one
is not independent of other facts about numbers.
Instead, it is an inference one can draw
from an acceptance of other familiar equations.
We will derived the equation $(-1)\times(-1) = 1$
from equations that you have accepted without question for a long time.

The equations in Figure~\ref{fig-02-01} (page \pageref{fig-02-01})
express some standard rules of numeric computation.
In those equations, the letters stand in
place of numbers. They can also stand in place of other
formulas.
So, the variable $x$ stands for a grammatically correct formula,
which could be something simple, such as ``$2$'',
it could be a more complicated formula, such as ``$3\times(y + 1)$''.

We refer to letters used in this way as
\index{variable}
``variables'' even though, within a particular equation, they
stand for a fixed number or a particular formula.
The formula associated with a variable, though unspecified,
is the same for every occurrence of the variable in the equation.
That is, if $x$ stands for $3\times(y + 1)$ at one point in the
equation, then everywhere else $x$ occurs in the equation,
it stands for that same formula, $3\times(y + 1)$.
This is the usual custom in algebra.

\begin{figure}
\begin{center}
\begin{tabular}{ll}
$x+0 = x$                 & \{$+$ identity\} \\
$(-x)+ x = 0$             & \{$+$ complement\} \\
$x \times 1 = x$          & \{$\times$ identity\} \\
$x \times 0 = 0$          & \{$\times$ null\} \\
$x+y = y+x$               & \{$+$ commutative\} \\
$x \times y = y \times x$ & \{$\times$ commutative\} \\
$x+(y+z) = (x+y)+z$       & \{$+$ associative\} \\
$x \times (y \times z) = (x \times y) \times z$ & \{$\times$ associative\} \\
$x\times(y+z) = (x \times y)+(x \times z)$      & \{distributive law\} \\
\end{tabular}
\end{center}
\index{equation!\{$+$ identity\}}
\index{equation!\{$+$ complement\}}
\index{equation!\{$\times$ identity\}}
\index{equation!\{$\times$ null\}}
\index{equation!\{$+$ commutative\}}
\index{equation!\{$\times$ commutative\}}
\index{equation!\{$+$ associative\}}
\index{equation!numeric algebra}
\index{equation!algebra}
\index{axiom!algebra}
\index{axiom!numeric algebra}
\caption{Equations of Numeric Algebra}
\label{fig-02-01}
\end{figure}

If we accept the equations of Figure~\ref{fig-02-01} (page \pageref{fig-02-01}),
we can apply one of them to transform the formula $(-1)\times(-1)$ to a new formula that
stands for the same number. Then, we can apply another equation to
transform that formula to a new one, and so on.
We look for a way to apply the
accepted equations one by one, so that in the end we
arrive at the formula ``1''. At every step, we know that the
new formula stands for the same value as the old one, so in
the end we know that $(-1)\times(-1) = 1$.

Figure~\ref{fig-02-02} (page \pageref{fig-02-02})
displays this sort of equation-by-equation derivation of the
formula ``1'' from the formula ``$(-1)\times(-1)$''. To
understand Figure~\ref{fig-02-02}, you must remember that each
variable can denote any
grammatically correct formula. For example, in the
\{$+$ identity\} equation, $x + 0 = x$, the variable $x$ could stand for
a number, such as 3, or it could stand for a more complicated
formula, such as $(1 + 3)$. It could even stand for a formula
with variables in it, such as $(a + (b \times c))$ or
$(((-1) \times (x + 3)) + (x + y))$.

Another crucial point is that each step cites
exactly one equation from Figure~\ref{fig-02-01} (page \pageref{fig-02-01})
to justify the transformation from the formula in the previous step.
We are so accustomed to calculating with numeric formulas that
we often combine many basic steps into one. When we reason formally,
we must not do this. We must justify each step by citing an equation
from a list of known equations. In our proof of $(-1)\times(-1) = 1$,
we will justify steps by citing equations from Figure~\ref{fig-02-01}
and from no other source. We will not skip steps.
Think of that as you go through the proof, line by line.

The first step in the proof
(Figure~\ref{fig-02-02}, page \pageref{fig-02-02}) uses a version of the
\{$+$ identity\} equation in which the variable $x$ stands for the
formula $((-1)\times(-1))$.
In this context, the \{$+$ identity\} equation
leads to the new formula $((-1)\times(-1)) + 0$.

The second step in the proof reads the \{$+$ complement\}
equation backwards (equations go both ways), and in a form
where the variable $x$ stands for the number 1.
When $x$ is 1, the \{$+$ complement\} equation is
$(-1) + 1 = 0$.
Reading the equation backwards, we can substitute
$((-1) + 1)$ for $0$,
and that leads to the formula $((-1)\times(-1)) + ((-1) + 1)$.
So, we know now that
$(-1)\times(-1) = ((-1)\times(-1)) + ((-1) + 1)$.

Doesn't really seem like progress does it?
But, we press on anyway, one step at a time.
The transformations, step by step, finally confirm that the two formulas
$(-1)\times(-1)$ and 1 represent the same number.

Pay particular attention to the last three lines of the proof.
Most people tend to jump from the formula $0+1$ to the
formula $1$ in one step. That jump requires knowing the equation
$0+1 = 1$. However, that equation is not among those listed in
Figure~\ref{fig-02-01} (page \pageref{fig-02-01}).
We want to do the proof without citing any equations
other than those in Figure~\ref{fig-02-01}, so we need two steps
to get from ``$(0+1)$'' to ``$1$'',
and those are the last two steps in the proof.

\begin{figure}
\begin{center}
\begin{tabular}{lll}
    & $(-1)\times(-1)$                            & \\
$=$ & $((-1)\times(-1)) + 0$                      & \{$+$ identity\} \\
$=$ & $((-1)\times(-1)) + ((-1) + 1)$             & \{$+$ complement\} \\
$=$ & $(((-1)\times(-1)) + (-1)) + 1$             & \{$+$ associative\} \\
$=$ & $(((-1)\times(-1)) + ((-1) \times 1)) + 1$  & \{$\times$ identity\} \\
$=$ & $((-1)\times((-1) + 1)) + 1$                & \{distributive law\} \\
$=$ & $((-1)\times 0) + 1$                        & \{$+$ complement\} \\
$=$ & $0 + 1$                                     & \{$\times$ null\} \\
$=$ & $1 + 0$                                     & \{$+$ commutative\} \\
$=$ & $1$                                         & \{$+$ identity\} \\
\end{tabular}
\end{center}
\index{negative $\times$ negative}
\index{equation!proof}
\index{proof}
\caption{Why $(-1)\times(-1)=1$}
\label{fig-02-02}
\end{figure}

One of the things we hope you will glean from this derivation is that
the equation $(-1)\times(-1) = 1$ does not depend on vague,
philosophical assertions like ``two negatives make a positive.''
Instead, the equation $(-1)\times(-1) = 1$ is a consequence of some
basic arithmetic equations. If you accept the basic equations
and the idea of substituting equals for equals, you must, as a
rational consequence, accept the equation $(-1)\times(-1) = 1$.

Using this same kind of reasoning, we will derive new Boolean equations
from a few, basic ones postulated as axioms.
A Boolean \emph{axiom} is a Boolean equation
that we assume to be true, without proof.
We will also learn that digital circuits are physical
manifestations of logic formulas, and we will be able to
parlay that idea to derive behavioral properties of
computer components.

Likewise, because a computer program is,
literally, a formula, we will be able to derive
properties of software directly from the programs, themselves.
This makes it possible for us to be entirely
certain about some of the behavioral characteristics of
software, and of computer hardware, too,
since a hardware component is a physical embodiment of a formula
in logic.
Our certainty stems from the mechanistic
formalism that we insist on from the beginning,
which can be checked to the last detail with automated computation.

\begin{ExerciseList}
\label{ex:ch02-intro}
\Exercise
Use the equations of Figure~\ref{fig-02-01} (page \pageref{fig-02-01}),
together with the additional equation (1+1)=2, to derive the equation $(x + x) = (2 \times x)$.

\Exercise
Derive the following equation
using using the equations of Figure~\ref{fig-02-01}.
\begin{center}
\begin{tabular}{ll}
$((-1) \times x) + x = 0$    & \{$\times$ negation\}
\end{tabular}
\end{center}

\Exercise
Derive the equation $((x + (((-1) \times (x + y)) + z)) + y) = z$
using using the equations of Figure~\ref{fig-02-01} and,
if you like,
the \{$\times$ negation\} equation from the previous exercise.
\end{ExerciseList}

\section{Boolean equations}
\label{sec:boolean-equations}
Let's start with the Boolean equations in
Figure~\ref{fig-02-03} (page \pageref{fig-02-03}).
These equations, which we will call the Boolean axioms,
are the starting point for our system of reasoning.
The form the basis from which we will derive
a host of other equations.
If these axiomatic equations are new to you and seem strange,
try to view them as ordinary,
algebraic equations, but with a different collection of operators.
A formula in numeric algebra has operations like addition
($+$) and multiplication ($\times$). Boolean formulas employ logic
operations: logical-and ($\wedge$), logical-or ($\vee$),
logical-negation ($\neg$), and implication ($\rightarrow$).
Furthermore, Boolean formulas stand for logic values
($True$, $False$), rather than for numbers (\dots -2, -1, 0, 1, 2 \dots).

\begin{figure}
\begin{center}
\begin{tabular}{ll}
$x \vee False = x$                                   & \{$\vee$ identity\} \\
$x \vee True = True$                                 & \{$\vee$ null\} \\
$x \vee y = y \vee x$                                & \{$\vee$ commutative\} \\
$x \vee (y \vee z) = (x \vee y) \vee z$              & \{$\vee$ associative\} \\
$x \vee (y \wedge z) = (x \vee y) \wedge (x \vee z)$ & \{$\vee$ distributive\} \\
$x \rightarrow y = (\neg x) \vee y$                  & \{implication\} \\
$\neg(x \vee y) = (\neg x) \wedge (\neg y)$          & \{$\vee$ DeMorgan\} \\
$x \vee x = x$                                       & \{$\vee$ idempotent\} \\
$x \rightarrow x = True$                             & \{self-implication\} \\
$\neg(\neg x)  = x$                                  & \{double negation\} \\
\end{tabular}
\end{center}
\index{Boolean!algebra}
\index{algebra, Boolean}
\caption{Boolean Axioms (basic equations)}
\label{fig-02-03}
\end{figure}

When we derive new equations from equations we already know,
we refer to the derived equations as \emph{theorems} to
distinguish them from axioms.
We call the derivation a
\emph{proof} of the theorem.

\begin{figure}
\begin{theorem}[\{$\vee$ truth table\}]
\mbox{}
\begin{itemize}
\item $False \vee False = False$
\item $False \vee True  = True$
\item $True  \vee False = True$
\item $True  \vee True  = True$
\end{itemize}
\end{theorem}

\begin{proof}
\mbox{}\\
\begin{tabular}{lll}
    &$False \vee False$    & \\
$=$ & $False$              & \{$\vee$ identity\}  ~~~---replace $x$ in the axiom with \emph{False}\\
    &  ~                   & \\
    & $False \vee True$    & \\
$=$ & $True$               & \{$\vee$ null\}  ~~~---replace $x$ in the axiom with \emph{False}\\
%    &                      & \dots for practice, prove the other two equations yourself \dots \\
\end{tabular}
\begin{quote}
\dots for practice, prove the other two equations yourself \dots
\end{quote}
\end{proof}
\index{equation!proof}
\index{proof}
\index{truth table}
\caption{Proof of Theorem \{$\vee$ Truth Table\}}
\label{or-truth-table}
\end{figure}

The first equation in the theorem \{$\vee$ truth table\}
(Figure~\ref{or-truth-table}, page \pageref{or-truth-table})
is a special case of the
\{$\vee$ identity\} axiom (Figure~\ref{fig-02-03}),
and the proof of that equation simply amounts making that observation.
That is, the proof just rewrites the \{$\vee$ identity\} axiom
with $False$ in place of $x$.

The proof of the second equation is equally short, but cites
a different axiom.
For practice, try to prove the other two
equations in the \{$\vee$ truth table\} theorem
by citing axioms in a similar way.

We are serious about that. Did you prove the other two equations?
No? Well \dots go back and do it, then. Without participation, there
is no learning.

\smallskip
$\dots$ \emph{We'll wait here}$\dots$
\smallskip

Finished now? Good for you. You cited the \{$\vee$ identity\} axiom in your
proof of the third equation in the theorem and the \{$\vee$ null\}
axiom in your proof of the fourth equation, right? We knew you could do it.

\begin{aside}
A \emph{truth table} for a formula is a list of equations
stating the values the formula represents,
with one equation for every possible combination of values
of the variables in the formula.
If there is only one variable in the formula,
there will be two equations in its truth table,
one for the case when the variable has the value
$True$ and one for the case when the variable has the value $False$.
If there are two variables in the formula,
there will be four equations in the truth table
because for each choice of value for the first variable,
there are two choices for the other.
Three variables lead to eight equations.
The number of equations in the truth table
doubles with each additional variable
in the formula.

A truth table for a logic operator is the truth table for the formula
that has variables in place of the operands.
For example, the truth table for the logical-or operator ($\vee$)
is the truth table for the formula $(x \vee y)$.
That formula has two variables, so the truth table has four equations.
\caption{Truth Tables}
\label{truth-tables}
\end{aside}

Derivations are usually more than one step, of course.
For example, the
\{$\vee$ complement\} theorem
(Figure~\ref{fig:or-complement-thm}, page \pageref{fig:or-complement-thm})
has a two-step proof, citing the \{implication\} axiom
and the \{self-implication\} axiom.
The \{$\vee$ complement\} theorem is often called the
``law of the excluded middle'' because it says that any
logic formula, together with its negation, covers all
of the possibilities.
A formula in logic is either true of false.
There is no middle ground.

\begin{figure}
\begin{theorem}[\{$\vee$ complement\}]
$(\neg x) \vee x = True$
\end{theorem}
\begin{proof}
\mbox{}\\
\begin{tabular}{lll}
    & $(\neg x) \vee x$ & \\
$=$ & $x \rightarrow x$ & \{implication\} \\
$=$ & $True$            & \{self-implication\} \\
\end{tabular}

\end{proof}
\index{equation!proof}
\index{proof}
\index{equation!\{$\vee$ complement\}}
\index{excluded middle}
\index{equation!excluded middle}
\index{law of excluded middle}
\caption{Proof of Theorem \{$\vee$ complement\}}
\label{fig:or-complement-thm}
\end{figure}

All of the logic operators have truth tables,
and we can derive the equations in those truth tables from the axioms.
Figure~\ref{fig:neg-truth-table} (page \pageref{fig:neg-truth-table})
displays the truth table
for the negation operator $(\neg)$.
The figure includes a four-step proof of the first equation in
the table.
To beef up your comprehension of the ideas,
construct your own proof of the second equation in the theorem.

\begin{figure}
\begin{theorem}[\{$\neg$ truth table\}]
\mbox{}\\
\begin{itemize}
\item $\neg True = False$
\item $\neg False = True$
\end{itemize}
\end{theorem}
\begin{proof}
\mbox{} \\
\begin{tabular}{llp{3.15in}}
    & $\neg True$                      & \\
$=$ & $\neg (False \rightarrow False)$ & \{self-implication\} \\
$=$ & $\neg ((\neg False) \vee False)$ & \{implication\}     ---replace $x$ and $y$ in axiom with $False$ \\
$=$ & $\neg (\neg False)$              & \{$\vee$ identity\} ~~---replace $x$ in the axiom with $\neg False$ \\
$=$ & $False$                          & \{double negation\} ~~---replace $x$ in axiom with $False$ \\
\end{tabular}

\bigskip
\noindent
\begin{tabular}{lll}
    & $\neg False$                             & \\
$=$ & \dots you fill in the details here \dots & \\
$=$ & $True$                                   & \\
\end{tabular}

\end{proof}
\index{equation!proof}
\index{proof}
\index{truth table}
\caption{Proof of Theorem \{$\neg$ truth table\}}
\label{fig:neg-truth-table}
\end{figure}

An important facet of these proofs is that they are
entirely syntactic. That is, they apply axioms by
matching the grammar of a formula $f$ (or a sub-formula of $f$) in the proof
with a formula $g$ from one side of an equation in the axioms.
The matching associates the variables in $g$ with corresponding sub-formulas of $f$.
Then, the formula $h$ on the other side of
the axiomatic equation is rewritten,
replacing each of variable in $h$ with the the associated subformula of $f$
that the matching process established.
The rewritten version of $h$
becomes the new, derived formula.
We know that the derived formula stands for the same value
as the original formula because the axiom asserts this equivalence,
and we are assuming that axioms are right.

\begin{aside}
Another way to prove that two formulas stand
for the same value is to build truth tables for both formulas.
A truth table lists all possible combinations of values for the
variables in a formula, and displays the value that the formula
denotes for each of those combinations. (Theorem \{$\vee$ truth table\} provides
the truth table for the logical-or operation, and theorem \{$\neg$ truth table\}
provides the truth table for the logical-negation operation.)
Two truth tables that list identical values of the corresponding
formulas for all combinations of values for
the variables demonstrate that the formulas always stand for the
same value. This proof method works well for formulas with only
a few variables. In that case, there are only a few combinations
of values for the variables, and the comparison can be completed quickly and accurately.

On the other hand, if there are many variables in the formulas,
things get out of hand. With two variables, as in the truth table
for logical-or, there are four combinations of values
(two choices for each variable, $True$ or $False$, so two times two
combinations in all). With three variables, there are eight
($2^3$) combinations, which makes the truth-table method tedious,
but not infeasible. After that, it gets rapidly out of hand.
Ten variables produce 1,024 ($2^{10}$) combinations of values.
That makes it difficult for people, but no real problem for a computer.
Even twenty variables (a little more than a million combinations)
also can be checked quickly by computers.

However, a formula specifying a computing component,
hardware or software, has hundreds of variables.
Our goal is to be able to reason about
computing components, and there is no hope of doing that
with truth tables when the formulas have hundreds of variables.
The number of combinations
of values for the variables in a formula with, say,
100 variables is $2^{100}$, and that number is so large that no computer could
finish checking all the cases before the sun runs out of fuel,
so a straightforward appeal to truth tables is
definitely not feasible for formulas with lots of variables.

There are effective methods
for dealing with at least some large formulas
besides the proofs that make up the core
material of this book.
Hardware and software designers sometimes use
SMT solvers (satisfiability modula theories) or
BDD tools (binary decision diagrams)
to verify properties of circuits and computer programs.
But, reasoning based on grammatical form
makes it possible to deal with formulas with any number of variables
because the formulas can be split into parts small enough
to manage, and those parts can be reintegrated, based on
their grammatical relationships, to produce a full analysis.
Feasible doesn't mean easy, though.
It usually takes a lot of effort,
but it can pay off.
\caption{Truth Tables and Feasibility}
\index{truth table}
\index{feasibility}
\index{infeasibility}
\label{feasibility}
\end{aside}

Let's prove another truth-table theorem, partly to practice
reasoning with equations, but also to discuss a common
point of confusion about logic. The implication operator
($\rightarrow$) is a cornerstone of logic in real-world problems,
but it is common to get tripped up when it comes to
reasoning with implication.

The \{$\rightarrow$ truth table\} theorem
(Figure~\ref{implication-truth-table}, page \pageref{implication-truth-table})
provides the truth table
for the implication operator.
An important aspect of the proof is that it cites
not only axioms from Figure~\ref{fig-02-03} (page \pageref{fig-02-03}),
but also equations from the \{$\neg$ truth table\} theorem.
This is the way mathematics goes. Once we have derived
a new equation from the axioms, we can cite
the new equation to derive still more equations.

\begin{aside}
Citing proven theorems to prove new ones
is similar to an idea known as ``abstraction''
that is a mainstay in engineering design.
At the point where we cite an old theorem to prove a new one,
we could, instead, copy the proof of the old theorem into the new proof.
However, that would make the proof longer, harder to understand,
and more likely to contain errors than it would be if we had
applied the theorem instead of copying its proof.

Computer programs are built from components that are, themselves,
other computer programs. As a project proceeds, more and more
components become available, and they are used to build more complex ones.
Sometimes, a component has almost the right form to be used in a new program,
but not quite.
Maybe the existing component doubles a number where the new program would need
to triple it. It is tempting to make a copy the
old component and change the $2 \times x$ formula to $3 \times x$
at the point where a doubling should be a tripling,
then paste the revised component into the program.

In our experience
copy-and-paste programming is
a common cause of errors in software,
especially in big programs maintained,
over time, by many people, because
when a maintainer finds an error in
a section of code that was copied from elsewhere,
there is nothing to direct the maintainer to fix
the same error in the copied code.
A better choice, most of the time,
is to make a new component
in which the $2$ is replaced by a variable,
say $m$.

This is known as creating an ``abstraction'' of the component
(``abstract'' as opposed to ``specific'' or ``concrete'').
The new component can be used for both doubling and tripling,
simply by specifying $2$ for $m$ in one case and $3$ for $m$ in the other.
That way, if an error is discovered in the component later,
the error can be fixed in one place instead of two
(or maybe ten or a hundred places, depending on how many engineers
copied of the original component to make a change.

Abstraction is one of the most important methods in
all of engineering design. Citing old theorems to prove new ones,
instead of doing copy-and-paste with their proofs,
is part of that tradition.
\caption{Abstraction}
\label{abstraction}
\end{aside}

\begin{figure}
\begin{theorem}[\{$\rightarrow$ truth table\}]
\mbox{}
\begin{itemize}
\item $False \rightarrow False = True$
\item $False \rightarrow True  = True$
\item $True  \rightarrow False = False$
\item $True  \rightarrow True  = True$
\end{itemize}
\end{theorem}

\begin{proof}
\mbox{} \\
\begin{tabular}{llp{3.15in}}
    & $False \rightarrow False$        & \\
$=$ & $(\neg False) \vee False$        & \{implication\} ~~---\emph{put} $False$ \emph{for} $x$ \emph{and for} $y$ \emph{in axiom}\\
$=$ & $\neg False$                     & \{$\vee$ identity\}\\
$=$ & $True$                           & \{$\neg$ truth table\}\\
\end{tabular}

\begin{tabular}{lll}
& \dots for practice, prove the other equations yourself\dots & \\
\end{tabular}

\end{proof}
\caption{Proof of Theorem \{$\rightarrow$ truth table\}}
\index{truth table}
\label{implication-truth-table}
\end{figure}

In day-to-day life outside the sphere of symbolic logic,
the usual interpretation of the logical implication ``$x \rightarrow y$''
is that we can conclude that $y$ is true if we know that
$x$ is true. However, the implication says nothing
about $y$ when $x$ is not true. In particular, it
does not say that $y$ is not true whenever $x$ is not true.
Theorem \{$\rightarrow$ truth table\} shows that the
formula ``$False \rightarrow y$'' has the value $True$ when $y$ is $True$
and also when $y$ is $False$.
In other words, the truth of the formula $x \rightarrow y$ in the case
where the hypothesis, $x$, of the implication is $False$ provides
no information about the conclusion, $y$.

A common mistake in everyday life is to assume that if the
implication ``$x \rightarrow y$'' is true, then the implication
``$(\neg x) \rightarrow (\neg y)$''
is also true. Sometimes this leads to bad
results, even in everyday life. In symbolic logic,
it is worse than that. Such a conclusion puts an
inconsistency into the mathematical system, and that renders the system useless.

Over half of the Boolean axioms in Figure~\ref{fig-02-03} (page \pageref{fig-02-03})
have names associated with the logical-or ($\vee$) operation.
One of them, the
\{$\vee$ DeMorgan\} equation
establishes a connection between logical-or and logical-and.
It converts the negation of a logical-or to the logical-and of two negations:
$\neg(x \vee y) = (\neg x) \wedge (\neg y)$.
We can use this connection to prove some logical-and equations
that are similar to the logical-or axioms.
An example is the null law for logical-and
(Figure~\ref{fig:and-null-thm}, page \pageref{fig:and-null-thm}).

\begin{figure}
\begin{theorem}[\{$\wedge$ null\}]
$x \wedge False = False$
\end{theorem}

\begin{proof}
\mbox{} \\
\begin{tabular}{llp{3.15in}}
    & $x \wedge False$                       & \\
$=$ & $x \wedge (\neg True)$                 & \{$\neg$ truth table\} \\
$=$ & $(\neg (\neg x)) \wedge (\neg True)$   & \{double negation\} \\
$=$ & $\neg ((\neg x) \vee True)$            & \{$\vee$ DeMorgan\} ~~---\emph{put} $(\neg x)$ \emph{for} $x$\emph{,} $True$ \emph{for} $y$ \emph{in axiom}\\
$=$ & $\neg True$                            & \{$\vee$ null\} \\
$=$ & $False$                                & \{$\neg$ truth table\} \\
\end{tabular}

\end{proof}
\index{equation!\{$\wedge$ null\}}
\caption{Proof of Theorem \{$\wedge$ null\}}
\label{fig:and-null-thm}
\end{figure}

This regime of theorem after theorem, proof after proof, is a little tiresome, isn't it?
Nevertheless, let's push through one more.
Then we'll give you a few to work out on your own, and go on to other topics.
We're not abandoning proofs, though.
Just taking a little break from proofs about equations.
It's going to be one proof after another, all the way down the line.

Some equations simplify the target formula when used in one direction,
but make it more complicated when used in the other direction.
For example, applying
the null law for logical-or, \{$\vee$ null\}, from left to right simplifies a logical-or formula to $True$.
When the equation is applied in the other direction, however,
it transforms the simple formula $True$ into something more complicated $(x \vee True)$.
The variable $x$ on the left-hand side
stands for any formula you want to make up (as long as it's grammatically correct).
It can have hundreds of variables and thousands operations.
This may seem perverse, but if that's what it takes to complete the proof, so be it.

The null law for logical-and, \{$\wedge$ null\}, is similarly asymmetric.
It goes from complicated to simple in one direction
and from simple to complicated in the other.
A particularly interesting and important asymmetric equation
is the absorption law for logical-and
(Figure~\ref{and-absorption-thm}, page \pageref{and-absorption-thm}).
It has two variables and two operations on one side, but only one variable and no operations on the other.

\begin{figure}
\begin{theorem}[\{$\wedge$ absorption\}]
$(x \vee y) \wedge y = y$
\end{theorem}

\begin{proof}
\mbox{} \\
\begin{tabular}{llp{3.15in}}
    & $(x \vee y) \wedge y$                & \\
$=$ & $(x \vee y) \wedge (y \vee False)$   & \{$\vee$ identity\} \\
$=$ & $(y \vee x) \wedge (y \vee False)$   & \{$\vee$ commutative\} \\
$=$ & $y \vee (x \wedge False)$            & \{$\vee$ distrubutive\} \\
$=$ & $y \vee False$                       & \{$\wedge$ null\} \\
$=$ & $y$                                  & \{$\vee$ identity\} \\
\end{tabular}

\end{proof}
\index{equation!proof}
\index{proof}
\index{absorption}
\index{equation!absorption}
\index{equation!\{$\wedge$ absorption\}}
\caption{Proof of Theorem \{$\wedge$ absorption\}}
\label{and-absorption-thm}
\end{figure}

We hope the gauntlet of theorems and proofs so far
(which we hope you have managed to get through,
even if it took you to the point of exhaustion)
helps you understand how to derive a new equation from equations you already know.
The technique requires matching a formula to one side of a known equation,
then replacing it by the corresponding formula on the other side
of the equation.
The ``matching'' process is a crucial step.
It involves replacing the variables in the known equation
by constituents of the formula you are trying to match.
This is based in the mechanics of a formal grammar.
Unfortunately, it is surprisingly easy
to have a lapse of concentration and make a mistake
while trying to substitute equals for equals.

Fortunately, it is easy for computers to verify
correct matchings and report erroneous ones.
A computer system that does this is known as a ``mechanized logic.''
After you have enough practice to gain a good understanding of the process,
we will begin to use a mechanized logic to make sure our reasoning is correct.

\begin{ExerciseList}
\Exercise
Use the Boolean axioms (Figure~\ref{fig-02-03}, page \pageref{fig-02-03})
and the $\wedge$-absorption theorem
(Figure~\ref{and-absorption-thm}, page \pageref{and-absorption-thm}),
to derive the $\vee$-absorption equation: $(x \wedge y) \vee y = y$.

\Exercise
Derive the equation
$(((\neg x) \wedge y) \vee (x \wedge (\neg y))) = ((x \vee y) \wedge (\neg(x \wedge y)))$
from the Boolean axioms.

\Exercise
Derive the equation
$(((\neg x) \wedge y) \vee (x \wedge (\neg y))) = (\neg((x \rightarrow y) \wedge (x \rightarrow y)))$
from the Boolean axioms.

\Exercise
Use the Boolean axioms
and the theorems of this section to
derive the truth-table for the following formula $(x \vee ((\neg y) \wedge (\neg z)))$.\\
\emph{Note}: Since there are three variables in the formula, the truth table
will have eight entries, and you will need to prove eight equations.
Each equation will have on the left-hand side
a different combination of values ($True$ or $False$) for the variables $x$, $y$, and $z$,
and on the right-hand side will have the value ($True$ or $False$) of the formula for that combination.
\end{ExerciseList}

\section{Boolean formulas}
\label{sec:boolean-formuas}

We have been doing proofs based on the grammatical elements of formulas,
but instead of taking the time to put together a precise definition of that grammar,
we have been relying on your experience with numeric algebra.
It is better to have a precise definition of the grammar,
starting with the most basic elements,
and working up from there to more complicated ones.

The simplest Boolean formulas are the basic constants ($True$ and $False$)
and variables ($x$, $y$, $\dots$). We normally use ordinary, lower-case letters,
for variables, but sometimes variables are letters with subscripts,
such as $x_3$, $y_i$, or $z_n$.
This gives us sufficient variety for any formula,
but we won't necessarily limit ourselves to lower-case, Roman letters.
We might use Greek letters, or
even make up recognizable squiggles, like Dr Seuss.

So, if you write $True$, $False$, or a letter from the alphabet,
you have composed a grammatically correct Boolean formula.
This is the first rule of Boolean grammar.
Formulas conforming to this rule have no substructure,
so we call them \emph{atomic} formulas.

Boolean operators make it possible to construct more complicated formulas.
We refer to operators that require two operands as \emph{binary operators }
($\wedge$, $\vee$, and $\rightarrow$).
These operators lead to the second rule of Boolean grammar:
If $a$ and $b$ are grammatically correct Boolean formulas,
 and $\circ$ is a binary operator
 (that is, $\circ$ is one of the symbols $\wedge$, $\vee$, or $\rightarrow$),
 then $(a \circ b)$ is also a grammatically correct Boolean formula.

For example, the first rule confirms that $x$ and $True$ are
grammatically correct Boolean formulas. Since $\wedge$ is a binary operator,
$(x \wedge True)$ is a grammatically correct Boolean formula by the
second rule of grammar. Furthermore, since $\rightarrow$ is a binary operator,
and $y$ is a grammatically correct Boolean formula (by the first rule),
$((x \wedge True) \rightarrow y)$ must be a grammatically correct
Boolean formula (by the second rule).

The third rule of Boolean grammar shows how to incorporate the negation operator into formulas.
The rule is that if $x$ is a grammatically correct formula, then so is $(\neg x)$.

These three rules are sufficient to
cover a full range of grammatically correct Boolean formulas,
and, they lead to an infinite variety of grammatically correct formulas.
However, there is a fine point to discuss about parentheses.
Parentheses are important because they make it easy to define
the grammar and to explain the meaning of a formula.
The formulas covered by the three rules are fully parenthesized,
including a top level of parentheses enclosing the entire formula
when an operator is involved.
Top level parentheses are often omitted in informal presentations,
and we have often omitted them.

For example, we have been writing formulas like ``$x \vee y$'',
without the top-level parentheses
the grammar requires.
To conform to the grammar,
we would have to write $(x \vee y)$, with the parentheses.
Because we have often omitted top-level parentheses,
requiring them probably comes as a surprise.
But, allowing non-atomic formulas without top-level parentheses
requires additional rules of grammar,
and we think that the added value of omitting parentheses
fails to compensate for the extra complexity.

Here is a more complex formula with incorrect grammar:
$x \wedge y \vee z$. This formula is missing two levels of parentheses.
Even worse, there are two options for the inner parentheses.
Does $x \wedge y \vee z$ mean $((x \wedge y) \vee z)$ or $(x \wedge (y \vee z))$?
There are ways to deal with formulas that omit parentheses,
but to avoid confusion, we are not going to allow such formulas.
The same problem occurs with formulas in numeric algebra.
We know that $x \times y + z$ means $((x \times y) + z)$ and
not $(x \times (y + z))$ because we know the convention that
gives multiplicative operators a higher precedence than additive operators.
But that takes some getting used to, and we want to
minimize the possibility of misinterpretation,
especially because Boolean formulas may be new to you.

We will sometimes be informal enough to omit
the top level of parentheses around the whole formula,
but we will not omit any interior parentheses.
The grammar does allow redundant parentheses, however.
For example, the formula $(x \vee ((x \wedge y)))$
is grammatically correct and has the same meaning as the formula
$(x \vee (x \wedge y))$.
The first formula has redundant parentheses,
but the second one doesn't.
Allowing redundant parentheses requires a fourth rule of grammar:
If $a$ is a grammatically correct Boolean formula, then so is $(a)$.

\begin{figure}
\begin{center}
\begin{tabular}{llll}
$v$             & \{atomic\}    &~~~~& \\
$(a \circ b)$   & \{bin-op\}    &~~~~& \emph{all grammatically correct formulas} \\
$(\neg a)$      & \{negation\}  &~~~~& \emph{~~~must match one of these templates}  \\
$(a)$           & \{group\}     &~~~~& \\
\end{tabular}

\vspace{2 mm}

\emph{requirements on symbols}

\begin{tabular}{l}
\hline
$\bullet$ ~~ $v$ is a variable or $True$ or $False$ \\
~~~~~(a variable is a letter or a letter with a subscript) \\
$\bullet$ ~~ $a$ and $b$ are grammatically correct Boolean formulas \\
$\bullet$ ~~ $\circ$ is a binary operator \\
\hline
\end{tabular}
\end{center}
\index{grammar, Boolean}
\index{Boolean!grammar}
\index{equation!parentheses}
\index{parentheses}
\index{equation!parentheses}
\index{formula}
\index{Boolean!formula}
\caption{Rules of Grammar for Boolean Formulas}
\label{fig-02-grammar}
\end{figure}

\begin{figure}
\begin{center}
\begin{tabular}{ll}
$(x \vee False) = x$                                     & \{$\vee$ identity\} \\
$(x \vee True) = True$                                   & \{$\vee$ null\} \\
$(x \vee y) = (y \vee x$)                                & \{$\vee$ commutative\} \\
$(x \vee (y \vee z)) = ((x \vee y) \vee z)$              & \{$\vee$ associative\} \\
$(x \vee (y \wedge z)) = ((x \vee y) \wedge (x \vee z))$ & \{$\vee$ distributive\} \\
$(x \rightarrow y) = ((\neg x) \vee y)$                  & \{implication\} \\
$(\neg(x \vee y)) = ((\neg x) \wedge (\neg y))$          & \{$\vee$ DeMorgan\} \\
$(x \vee x) = x$                                         & \{$\vee$ idempotent\} \\
$(x \rightarrow x) = True$                               & \{self-implication\} \\
$(\neg(\neg x))  = x$                                    & \{double negation\} \\
$((x)) = (x)$                                            & \{redundant grouping\} \\
$(v) = v$                                                & \{atomic release\} \\
\end{tabular}

\vspace{2 mm}

\emph{requirements on symbols}

\begin{tabular}{l}
\hline
$\bullet$ ~~ $x$, $y$, and $z$ are grammatically correct Boolean formulas \\
$\bullet$ ~~ $v$ is a variable or $True$ or $False$ \\
~~~~~(a variable is a letter or a letter with a subscript) \\
\hline
\end{tabular}
\end{center}
\index{equation!Boolean algebra}
\index{equation!algebra}
\index{axiom!algebra}
\index{equation!Boolean algebra}
\index{Boolean!algebra}
\index{algebra, Boolean}
\index{equation!\{$\vee$ identity\}}
\index{equation!identity}
\index{equation!\{$\vee$ null\}}
\index{equation!\{$\vee$ commutative\}}
\index{equation!commutative}
\index{commutative}
\index{equation!\{$\vee$ associative\}}
\index{equation!associative}
\index{associative}
\index{equation!\{$\vee$ distributive\}}
\index{equation!distributive}
\index{distributive}
\index{equation!\{implication\}}
\index{equation!\{$\vee$ DeMorgan\}}
\index{equation!DeMorgan}
\index{equation!\{$\vee$ idempotent\}}
\index{equation!idempotent}
\index{idempotent}
\index{equation!\{self-implication\}}
\index{equation!\{double negation\}}
\index{equation!\{atomic release\}}
\index{equation!parentheses}
\index{parentheses}
\caption{Axioms of Boolean Algebra}
\label{fig-02-boolean-axioms}
\end{figure}

With the four rules of
Figure~\ref{fig-02-grammar} (page \pageref{fig-02-grammar}),
we can determine whether or not any given sequence of symbols
is a grammatically correct Boolean formula.
The definition of the grammar is circular,
but in a useful way that shows
how to build more complicated formulas from simpler ones.

To verify that a formula is grammatically correct,
find the rule of grammar that matches it,
then verify that each part of the formula
that matches with a variable in the rule of grammar
is also grammatically correct.
Atomic formulas have no substructure,
so they require no further analysis when checking for grammatical correctness.

For example, consider the formula
$((x \vee (\neg y)) \wedge (x \rightarrow z))$.
It matches with the \{bin-op\} rule.
The variables in the rule match
with the elements of the formula in the following way.
\begin{center}
\begin{tabular}{ll}
\emph{symbol from \{bin-op\} rule}      & \emph{matching element in} $((x \vee (\neg y)) \wedge (x \rightarrow z))$ \\
$a$                                     & $(x \vee (\neg y))$ \\
$\circ$                                 & $\wedge$ \\
$b$                                     & $(x \rightarrow z)$ \\
\end{tabular}
\end{center}

The only other symbols in the rule are the top-level parentheses, and these match identically with the outer parentheses in the target formula. Therefore, the target formula is grammatically correct if the formulas $(x \vee (\neg y))$ and $(x \rightarrow z)$  are grammatically correct. We use the same approach to verify the grammatical correctness of those formulas.

The first one, $(x \vee (\neg y))$,
again matches with the \{bin-op\} rule,
but this time the matchings of the elements
in the target formula with variables in the rule are as follows:
\begin{center}
\begin{tabular}{ll}
\emph{symbol from \{bin-op\} rule}      & \emph{matching element in}  $(x \vee (\neg y))$ \\
$a$                                     & $x$ \\
$\circ$                                 & $\vee$ \\
$b$                                     & $(\neg y)$ \\
\end{tabular}
\end{center}

This reduces the verification of the grammatical correctness of $(x \vee (\neg y))$
to the verification of the two formulas $x$ and $(\neg y)$.
Since $x$ matches with the \{atomic\} rule, it must be grammatically correct.
The $(\neg y)$ element matches with the \{negation\} rule,
with $y$ from the formula matching $a$ in the rule.
So, $(\neg y)$ is grammatically correct if $y$ is,
and $y$ is grammatically correct because it matches with the \{atomic\} rule.
That completes the verification that the $(x \vee (\neg y))$ formula is grammatically correct.

The second element of the original formula,
$(x \rightarrow z)$, is easier to verify.
It matches the \{bin-op\} rule with $x$ corresponding to $a$ in the rule,
$y$ corresponding to $b$, and $\rightarrow$ corresponding to $\circ$ in the rule.
Since $x$ and $z$ match the \{atomic\} rule, they are grammatically correct.
This completes the verification of the grammatical
correctness of the formula $((x \vee (\neg y)) \wedge (x \rightarrow z))$.

Let's look at another example: $(x \vee (\wedge y)$.
This sequence of symbols matches with the \{bin-op\} rule,
with $x$ corresponding to $a$ in the rule,
$\vee$ corresponding to $\circ$,
and $(\wedge y)$ corresponding to $b$.
So, the formula is grammatically correct
if $x$ and $(\wedge y)$ are.
However, there is no rule that matches $(\wedge y)$.
The only place the symbol $\wedge$ could match a rule
in the table is in the \{bin-op\} rule.
In the \{bin-op\} rule, there must be
a grammatically correct formula between
the opening parenthesis and the operator.
Since there is no such element present
between the opening parenthesis
and the $\wedge$ operator in the target formula,
it cannot be grammatically correct.

That covers the grammar of Boolean formulas.
What about meaning?
Every grammatically correct Boolean formula denotes,
when the values of its variables are specified,
either the constant $True$ or the constant $False$.
Each of the binary operators, given specific operands ($True$ or $False$),
delivers a specific result ($True$ or $False$).
We worked out what values the operators deliver
when we derived truth-table theorems for them
(as in Figure~\ref{or-truth-table}, page \pageref{or-truth-table}, for example).

In the process of deriving the truth tables,
we used the Boolean axioms of
Figure~\ref{fig-02-03} (page \pageref{fig-02-03}).
We can use this same method to derive the meaning
of any grammatically correct formula that contains no variables.
However, to deal with parentheses in a completely mechanized way,
we need to add two equations to those of Figure~\ref{fig-02-03}.
The axioms of Figure~\ref{fig-02-boolean-axioms} (page \pageref{fig-02-boolean-axioms})
provides all of the information needed to determine
the value of any grammatically correct formula
that contains no variables.
In fact the equations in the figure have even more general applicability.
They provide all the information needed
to verify not only whether a given formula
has the same meaning as the formula $True$ or the formula $False$,
but also to verify whether or not any two given,
grammatically correct, formulas have the same meaning.

\begin{ExerciseList}

\Exercise Use the rules of grammar for Boolean formulas (Figure~\ref{fig-02-grammar}, page \pageref{fig-02-grammar})
to determine which of the following formulas are grammatically correct.
\begin{center}
\begin{tabular}{l}
$((x \wedge y) \vee y )$ \\
$((x \rightarrow y) \wedge (x \rightarrow (\neg y)))$ \\
$((False \rightarrow (\neg y)) \neg (x \vee True))$ \\
\end{tabular}
\end{center}


\Exercise Derive the truth tables (see page \pageref{truth-tables})
of the formulas from the previous exercise.

\Exercise Use the axioms of Boolean algebra
(Figure~\ref{fig-02-boolean-axioms}, page \pageref{fig-02-boolean-axioms})
to prove the equations in
Figure~\ref{some-boolean-theorems} (page \pageref{some-boolean-theorems}).\\
\emph{Note}: After proving an equation, you may cite it in subsequent proofs.

\end{ExerciseList}

\begin{figure}
\begin{center}
\begin{tabular}{ll}
$(x \rightarrow False) = (\neg x)$                                   & \{$\neg$ as $\rightarrow$\}\label{neg-as-imp} \\
$(\neg(x \wedge y)) = ((\neg x) \vee (\neg y))$                      & \{$\wedge$ DeMorgan\}      \label{and-DeMorgan} \\
$(x \vee (\neg x)) = True$                                           & \{$\vee$ complement\}      \label{or-complement} \\
$(x \wedge (\neg x)) = False$                                        & \{$\wedge$ complement\}    \label{and-complement} \\
$(\neg True) = False$                                                & \{$\neg True$\}            \label{not-True} \\
$(\neg False) = True$                                                & \{$\neg False$\}           \label{not-False} \\
$(True \rightarrow x) = x$                                           & \{$\rightarrow$ identity\} \label{imp-identity} \\
$(x \wedge True) = x$                                                & \{$\wedge$ identity\}      \label{and-identity} \\
$(x \wedge y) = (y \wedge x)$                                        & \{$\wedge$ commutative\}   \label{and-commutative} \\
$(x \wedge (y \wedge z)) = ((x \wedge y) \wedge z)$                  & \{$\wedge$ associative\}   \label{and-associative} \\
$(x \wedge (y \vee z)) = ((x \wedge y) \vee (x \wedge z))$           & \{$\wedge$ distributive\}  \label{and-distributive} \\
$(x \wedge x) = x$                                                   & \{$\wedge$ idempotent\}    \label{and-idempotent} \\
$(x \rightarrow y) = ((\neg y) \rightarrow (\neg x))$                & \{contrapositive\}         \label{contrapositive} \\
$(x \rightarrow (y \rightarrow z)) = ((x \wedge y) \rightarrow z)$   & \{Currying\}               \label{currying} \\
$((x \wedge y) \vee y) = y$                                          & \{$\vee$ absorption\}      \label{or-absorption} \\
$((x \rightarrow y) \wedge (x \rightarrow z)) = (x \rightarrow (y \wedge z))$ & \{$\wedge$ implication\} \label{and-implication} \\
$((x \rightarrow y) \wedge (x \rightarrow z)) = (x \rightarrow (y \wedge z))$ & \{$\wedge$ implication\} \label{and-implication} \\
$(x \rightarrow (\neg x)) = (\neg x)$                                & \{absurd 1\}               \label{absurd-1} \\
$((\neg x) \rightarrow x) = (\neg x)$                                & \{absurd 2\}               \label{absurd-2} \\
$((x \rightarrow y) \wedge (x \rightarrow (\neg y))) = (\neg x)$     & \{absurdity\}              \label{absurdity} \\
$(x \rightarrow (\neg x)) = (\neg x)$                                & \{contradiction\}          \label{boolean-contradiction} \\
\end{tabular}
\end{center}
\index{equation!\{$\neg$ as $\rightarrow$\}}
\index{equation!\{$\wedge$ DeMorgan\}}
\index{equation!DeMorgan}
\index{DeMorgan}
\index{equation!\{$\vee$ complement\} }
\index{equation!\{$\wedge$ complement\}}
\index{equation!\{$\neg True$\}}
\index{equation!\{$\neg False$\}}
\index{equation!\{$\rightarrow$ identity\}}
\index{equation!\{$\wedge$ identity\}}
\index{equation!\{$\wedge$ commutative\}}
\index{equation!commutative}
\index{equation!\{$\wedge$ associative\}}
\index{equation!associative}
\index{equation!\{$\wedge$ distributive\}}
\index{equation!distributive}
\index{equation!\{$\wedge$ idempotent\} }
\index{equation!idempotent}
\index{equation!\{contrapositive\}}
\index{equation!\{Currying\}}
\index{equation!\{$\vee$ absorption\}}
\index{equation!absorption}
\index{equation!\{$\wedge$ implication\}}
\index{equation!\{$\wedge$ implication\}}
\index{equation!\{absurd 1\}}
\index{equation!\{absurd 2\}}
\index{equation!\{absurdity\}}
\index{equation!\{contradiction\}}
\index{equation!absurdity}
\index{absurdity, equation}
\index{contrapositive}
\caption{Some Boolean Theorems}
\label{some-boolean-theorems}
\end{figure}

\section{Digital Circuits}
\label{sec:digital-circuits}

Logic formulas provide a mathematical notation for concepts in symbolic logic.
These same concepts can be materialized as electronic devices.
The basic operators of logic represented in the form of electronic devices
are called ``logic gates''.
There are logic \index{gate}\index{logic gate}gates 
for the logical-and, the logical-or, negation, and
several other operators that we have not yet discussed.

\begin{aside}
One of the operators we have discussed at length, implication
($\rightarrow$), is not among the operators normally represented
in the form of logic gates. This does not restrict the kinds of
operations that can be performed by digital logic because,
as we know from the \{implication\} axiom of Boolean algebra
(Figure~\ref{fig-02-boolean-axioms}, page \pageref{fig-02-boolean-axioms}),
the formula $(x \rightarrow y)$ has the same meaning as the
formula $((\neg x) \vee y)$. So, anything we can do with
the implication operator, we can also with
negation and logical-or.

The lack of a conventional logic gate for the implication operator
is ironic.
George Boole himself, the inventor of Boolean algebra,
called implication the queen of logic operators.
It is one of only a few basic operators
that are \emph{functionally complete} in the sense that,
for any formula in logic, there is an equivalent formula
with no operators other than implication.
That is, given any grammatically correct logic formula,
there is a formula using only
implication operators (no logical-and, logical-or,
negation, or any other operators)
that has the same meaning.
Logical-or and logical-and are not functionally complete.
However, their negations, \index{nor}\emph{nor} and \index{nand}\emph{nand}, are.
For that reason nor gates and nand gates
are called \emph{universal gates}.
Figure~\ref{fig-02-nand-is-all-you-need} (page ~\pageref{fig-02-nand-is-all-you-need})
shows how to write logic formulas using only nand gates.

It is possible that implication gates may
become common in digital circuits in the future
because there is a way to fabricate implication gates that may allow extensive,
three-dimensional stacking of circuits, which up to now has been infeasible.
If that pans out, it could be possible to build
faster circuits with more components in a smaller space.
R. Stanley Williams discusses this
idea in an interesting video on ``memristor chips''
(\url{http://www.youtube.com/watch?v=bKGhvKyjgLY}).
\caption{Implication Gate Is Universal}
\label{no-implication-gate}
\index{universal gate}\index{memristor}
\index{gate!universal}
\end{aside}

A logic \index{gate}gate takes input signals that correspond
to the operands of logic operators and delivers output signals
that correspond to the values delivered by those operators.
A logic gate with two inputs is a physical representation of
a binary operator. The negation operator corresponds to a
logic gate with one input.

Logic operands and values are always either $True$ or $False$.
Similarly, an input line of a logic gate can distinguish between
only two distinct signals
and deliver only two distinct signals on an output line.
Conventionally those signals are written as 1 (for $True$) and 0 (for $False$).
Of course, logic gates are electronic devices,
so 1 and 0 are just labels for the signals.
Any two different symbols could be used to represent them in writing.
The choice of 1 and 0 is more-or-less arbitrary.

There are many ways to handle the electronics,
but we are going to leave the physics to the electrical engineers.
You can imagine representing the signal 1 as
a voltage at a point in a circuit and the signal 0 as
the lack a voltage, which is the way some technologies
deal with logic signals,
but we are going to focus on the logic and trust that
the electronic hardware can faithfully deal with
a signal representing $True$ and a different one representing $False$.

\index{circuit}Circuits can be depicted as \index{wiring}wiring diagrams
in which ``wires'' (represented by lines) carry signals between gates.
Distinctive shapes in the diagrams represent different logic gates.
Circuits can be represented as formulas as well as diagrams, and
the logic formulas we have been using would serve the purpose,
but traditionally the algebraic notation for circuits takes a
different form.
The algebraic notation commonly used by circuit
designers represents the logical-and by the juxtaposition
of the names being used for the input signals (in the same way
that juxtaposition of variables is used to denote multiplication
in numeric algebra). Logical-or is represented by a plus sign (+),
and negation is represented by a bar over the formula being negated
For example, the formula $\overline{ab}$ denotes the negation of the logical-and
of the signals $a$ and $b$.

\begin{figure}
\begin{center}
\includegraphics[scale=0.25]{images/LogicGates.png}
\todo{I did not have Visio with me. Improvised with PowerPoint. Figure will need to be redrawn.}
\end{center}
\index{gate}
\index{circuit}
\caption{Digital Circuits = Logic Formulas}
\label{fig-02-logic-gates}
\end{figure}

Figure~\ref{fig-02-logic-gates} (page \pageref{fig-02-logic-gates})
presents the symbols used for logic gates in circuit diagrams
and annotates them with both
the algebraic notation used by circuit designers
and the logic formulas we have been using.
The important fact to remember is that all three notations
represent the same concepts in logic. Circuit diagrams, logic formulas,
and the algebraic notation used by circuit designers are three
different notations for exactly the same mathematical objects.
In this sense, digital circuits, and, therefore, computers,
are materializations of logic formulas.
Computers are logic in action.

The logic operators that we have been using
($\wedge$, $\vee$, $\neg$, $\rightarrow$)
make it possible to write a formula
the delivers precisely the values in the truth table
for any given formula.
The \{implication\} axiom
(Figure~\ref{fig-02-boolean-axioms}, page \pageref{fig-02-boolean-axioms})
expresses implication in terms of logical-and, logical-or,
and negation, which means we lose no expressive power by
discarding implication from the set of logic operations.

Surprisingly, the reverse is also true.
That is, for any given input/output relationship that can be expressed
in a formula using logical-and, logical-or, and negation,
there is a logic formula using implication as
the only operator that has the same input/output relationship.
The \{$\neg$ as $\rightarrow$\} equation
(Figure~\ref{some-boolean-theorems}, page \pageref{some-boolean-theorems})
provides a start in this direction by showing how to express
negation in terms of the implication operator.
Furthermore, implication is not the only logic operator
that is universal in this sense.
Another one
is the negation of logical-and, which is called ``nand''.
Many digital systems make frequent use of
nand gates because they can run faster and be more reliable
when fabricated with some widely used technologies
for making integrated circuits.

It is interesting to see how to put together digital
circuits for basic operators.
$\wedge$, $\vee$, and $\neg$, using only nand gates.
Consider negation, for example.
Negation has only one input signals, and nand has two.
Feeding the same signal into both
inputs of a nand gate produces the behavior of
the negation operator,
as expressed in the following equation.

\begin{center}
\begin{tabular}{ll}
$(\neg a) = (\neg (a \wedge a))$  & \{$\neg$ as nand\}\label{neg-as-nand}
\end{tabular}
\end{center}

In this way a nand gate can serve in place of a
negation gate (also known as an inverter).
There is a one-step proof of the equation,
citing the \{$\wedge$ idempotent\} theorem
(page \pageref{and-idempotent}).

A nand-only circuit for logical-and can be
\index{gate}\index{logic gate}\index{gate}\index{universal gate}\index{gate}\index{gate!universal}
put together from two nand gates in sequence.
The signal from the first nand gate is inverted
by feeding it into both inputs of a second nand gate.
Algebraically, this circuit corresponds to the following \{$\wedge$ as nand\} equation.
It takes a two-step proof to verify the equation.
The first step converts the outside nand to negation using the
\{$\neg$ as nand\} equation, and the second step cites
the \{double negation\} axiom from Figure~\ref{fig-02-boolean-axioms}
(page \pageref{fig-02-boolean-axioms}).

\begin{center}
\begin{tabular}{ll}
$(a \wedge b) = (\neg ((\neg (a \wedge b)) \wedge (\neg (a \wedge b))))$ & \{$\wedge$ as nand\}\label{and-as-nand}
\end{tabular}
\end{center}

\index{negation}Negation took one nand gate and
logical-and took two.
Logical-or can be implemented with three nand gates,
as shown in the following equation,
which can be verified using
the \{$\neg$ as nand\} equation, DeMorgan's laws,
and double negation.

\begin{center}
\begin{tabular}{ll}
$(a \vee b) = (\neg ((\neg(a \wedge a)) \wedge (\neg(b \wedge b))))$ & \{$\vee$ as nand\}\label{or-as-nand}
\end{tabular}
\end{center}

Figure~\ref{fig-02-nand-is-all-you-need} (page \pageref{fig-02-nand-is-all-you-need})
diagrams the digital circuits
corresponding to the formulas that express logical-and, logical-or, and negation
in terms of nand operations.

\begin{figure}
\begin{center}
\includegraphics[scale=0.27]{images/NandIsAllYouNeed.png}
\todo{I did not have Visio with me. Improvised with PowerPoint. Figure will should be redrawn.}
%% redrew diagram ... still used PowerPoint, but improved the diagram a little 8Aug2017
\end{center}
\index{universal gate}
\index{gate!universal}
\caption{Nand is All You Need}
\label{fig-02-nand-is-all-you-need}
\end{figure}

\begin{ExerciseList}
\Exercise Using a negation-gate and an or-gate, draw a circuit diagram with the input/output behavior of the implication operator.
We refer to this circuit diagram as an ``implication circuit''.\\
\emph{Hint}: Follow the example of the \{implication\} axiom
(Figure~\ref{fig-02-boolean-axioms}, page \pageref{fig-02-boolean-axioms})).
One of the inputs will need to be a constant rather than a variable.

\Exercise For each of the following logic formulas, draw an equivalent circuit diagram.
Since we don't have a symbol for an implication gate,
you can either make up you own symbol or
materialize logic gates where you need them
using the circuit diagram from the previous exercise.
\begin{center}
\begin{tabular}{l}
$((a \vee (b \wedge (\neg a))) \vee (\neg (a \vee b)))$ \\
$(((\neg a) \wedge (\neg b)) \wedge (b \wedge (\neg c)))$ \\
$(a \rightarrow (b \rightarrow c))$ \\
$((a \wedge b) \rightarrow c)$ \\
\end{tabular}
\end{center}

\Exercise Rewrite each of the formulas in the previous exercise
in the algebraic notation used by electrical engineers:
juxtaposition for $\wedge$, + for $\vee$, and $\overline{a}$ for $(\neg a)$.
Use the \{implication\} axiom to represent
implications using negation and logical-or.

\Exercise Draw circuit diagrams with behavior
of the and gate, the or gate, and the negation gate
using implication operators only.
\end{ExerciseList}

\todo{ do we still want to add half-adder and/or full-adder
circuits as examples? problem: they have two outputs, so need to talk about
tapping outputs from subformulas to show correspondence to algebraic form}

\begin{aside}
Reasoning with Boolean equations requires a lot of intellectual effort.
Almost all students struggle when they try to master the concepts 
and apply them to solve problems. 
So, if you're \index{struggling}struggling, you're normal.
If you get discouraged to the point of despair, you're normal.
It gets easier with every successful solution, but it never gets easy.
What you are doing here is real mathematics, and it places the same
kind of burden on the intellect as real \index{engineering}engineering.
Engineering is the application of principles 
of math and science to the design of useful things,
so real engineering and real mathematics share a great deal of common ground.

If it does not appeal to you to struggle through many
failed attempts and beyond them to a solution, only to
go on to the next problem and start the process once again, 
you are going to find engineering to be an unpleasant activity. 
It's \index{frustration}frustration, frustration, frustration
ad nausaum, then a solution, then on to the next problem. 
Finding the solution through all of that fog
brings a lot of satisfaction, and for engineers and mathematicians,
that satisfaction makes it all worthwhile.

So, take heart. Keep trying. 
Hundreds of students have worked their way through the reading
and exercises of this chapter and the ones that follow, 
and almost all of them have succeeded.
To do so, they invested a great deal of energy in solving problems,
reading, again and again, the examples, and applying the ideas.
Sometimes it takes many hours, just to solve one problem.
Don't give up.

\caption{Struggling? Join the Club}
\label{aside:struggling}
\end{aside}

\section{Deduction}
\label{sec:deduction}

We have been reasoning with equations, which means we are reasoning in two directions
at the same time, since equations go both ways. Deductive reasoning is one-directional.
It derives a conclusion from hypotheses using one-directional rules of inference.
A proof shows that the conclusion is true whenever the hypotheses are true, but provides
no information about the conclusion when the truth of one or more of the hypotheses is
unknown.

In the following discussion of proof by deduction,
theorems will be stated using the symbol ``$\vdash$'',
which is called a turnstile, to separate the hypotheses from the conclusions.
Hypotheses go on the left of the turnstile and the conclusion goes on the right.
All of the hypotheses are formulas in logic, as is the conclusion.
A theorem asserts that there is a derivation of the conclusion
from the hypotheses using the rules of inference.
The commutativity law for logical-and, for example,
can be stated as follows.
\begin{center}
Theorem \{$\wedge$ commutes\}: $a \wedge b \vdash b \wedge a$
\end{center}

Later, we will prove this theorem using a formal apparatus
for deductive reasoning known as
\index{natural deduction}\index{deduction!natural}\emph{natural deduction}.\footnote{Natural
deduction is a \index{formalism}formal system of logic pioneered in the 1930s
by the mathematician, \index{Gentzen, Gerhard}Gerhard Gentzen, and refined in the 1960s
by the logician, \index{Prawitz, Dag}Dag Prawitz.}
A deductive proof of a theorem with hypothesis $h$ and conclusion $c$
verifies that the implication $(h \rightarrow c)$ is true:
\begin{center}
$h \vdash c$ ~~ensures that~~ $(h \rightarrow c) = True$
\end{center}

\begin{figure}
\begin{center}
\begin{tabular}{ll}
Prove $a$                                               & Prove $a \vee b$                                  \\
 - - - - - -                                            &  - - - - - - - - - -                              \\
Prove $b$                                               & Prove $a \rightarrow c$                           \\
--------------\{$\wedge$ introduction\}                 &  - - - - - - - - - -                              \\
Infer $a \wedge b$                                      & Prove $b \rightarrow c$                           \\
                                                        & -----------------\{$\vee$ elimination\}           \\
                                                        & Infer $c$                                         \\
Prove $a$                                               &                                                   \\
--------------\{$\vee$ introduction 1\}                 &                                                   \\
Infer $a \vee  b$                                       & Prove $a \wedge b$                                \\
                                                        & ----------------\{$\wedge$ elimination 1\}        \\
                                                        & Infer $a$                                         \\
Prove $b$                                               &                                                   \\
--------------\{$\vee$ introduction 2\}                 &                                                   \\
Infer $a \vee  b$                                       & Prove $a \wedge b$                                \\
                                                        & ----------------\{$\wedge$ elimination 2\}        \\
                                                        & Infer $b$                                         \\
Prove $a \rightarrow False$                             &                                                   \\
-----------------------\{$\neg$ introduction\}          &                                                   \\
Infer $\neg a$                                          & Prove $\neg a$                                    \\
                                                        & ---------------------\{$\neg$ elimination\}       \\
                                                        & Infer $a \rightarrow False$                       \\
Prove $a$                                               &                                                   \\
----------\{identity\}                                  &                                                   \\
Infer $a$                                               & Prove \emph{False}                                \\
                                                        & ---------------\{contradiction\}                  \\
                                                        & Infer $a$                                         \\
Prove $a$                                               &                                                   \\
 - - - - - - - - - -                                    &                                                   \\
Prove $a \rightarrow b$                                 & Prove $(\neg a) \rightarrow$ \emph{False}         \\
-----------------\{modus ponens\}                       & --------------------------\{reductio ad absurdum\}\\
Infer $b$                                               & Infer $a$                                         \\
                                                        &                                                   \\
\end{tabular}
\end{center}
\begin{center}
\begin{tabular}{ll}
Assume $a$                                      & \emph{assumption required to cite} \{$\rightarrow$ introduction\}     \\
--------------\{\emph{r}\}                      & \emph{r is an inference rule or proven theorem}                       \\
Prove $b$                                       & $b$ \emph{has now been derived from assumption} $a$                   \\
-----------------\{$\rightarrow$ introduction\} & \emph{proof above line begins with} ``Assume \emph{left operand''}    \\
Infer $a \rightarrow b$                         & ~~~~\emph{and concludes with right operand, proving} $a \rightarrow b$\\
Discharge $a$                                   & \emph{excludes formula} ``$a$'' \emph{from hypotheses of theorem}     \\
\end{tabular}
\end{center}
\index{rules of inference}
\index{inference rules}
\index{modus ponens}
\index{contradiction}
\index{elimination rules}
\index{identity}
\index{introduction rules}
\index{reductio ad absurdum}
\index{deduction}
\index{natural deduction}
\index{deduction!natural}
\index{discharge}
\index{proof!deduction}
\caption{Rules of Inference for Natural Deduction}
\label{fig-02-deduction-rules}
\end{figure}

Of course the truth of an implication formula doesn't
say anything about the value of the
left-hand operation of the implication operator.
That value could be either $True$ or $False$.
The implication formula just says that
the only combination of values that can make
$(h \rightarrow c)$ have the value $False$
(namely, $h = True$, $c = False$, as verified in
Theorem \{$\rightarrow$ truth table\},
page \pageref{implication-truth-table}) cannot occur.
In the same way, a deductive proof of a theorem
does not provide any information about the hypotheses.
It only says that the conclusion will be true
whenever all of the hypotheses are true.

\begin{figure}
\begin{quote}
Theorem \{Socrates was mortal\}: $man$, $man \rightarrow mortal$ $\vdash$ $mortal$ \\
proof
\end{quote}
\begin{center}
\begin{tabular}{l}
Assume $man$                    \\
 - - - - - - - - - - - - - - - - - -\\
Assume $man \rightarrow mortal$ \\
--------------------------------\{modus ponens\} \\
~~~~~~ $mortal$                 \\
\end{tabular}
\end{center}
\index{Socrates syllogism}\index{syllogism, Socrates}
\caption{Theorem \{Socrates Was Mortal\}: Citing Modus Ponens}
\label{fig:socrates-proof}
\end{figure}

Sometimes a theorem has from several hypotheses.
A proof by deductive reasoning of the theorem
$h_1$, $h_2$ $\vdash$ $c$,
which has two hypotheses,
ensures that
$((h_1 \wedge h_2) \rightarrow c) = True$.
A theorem with no hypotheses at all
would have no formulas on the left-hand side of the turnstile:
$\vdash c$.
A proof of such a theorem would
verify the equation $c = True$.

All of the axioms of Boolean algebra
(Figure~\ref{fig-02-boolean-axioms}, page \pageref{fig-02-boolean-axioms})
can be derived through deductive reasoning.
Many presentations of classical logic begin with deductive reasoning,
but we started with Boolean algebra
because we will be using logic to reason about
digital circuits and software that we
specify with equations.
So, equations play a central role throughout the discussion.
Nevertheless, we will want reason deductively from time to time,
and this introduction is intended to provide a basis for
deductive proofs when we want to use them.\footnote{If
you are interested in a more extensive discussion of the natural deduction
system of logic, an accessible treatment can be found
in a text by O'Donnell, Hall, and Page
(\emph{Discrete Mathematics Using a Computer}, $2^{nd}$ ed., Springer, 2006).}

Figure~\ref{fig-02-deduction-rules} (page \pageref{fig-02-deduction-rules})
provides schematics for rules of inference for \emph{natural deduction}.
We will work through the rules, one by one,
to show how deductive proofs employ
them to derive the logic formula that is the conclusion of the theorem
from one or more hypotheses, which are also logic formulas.

A citation of an inference rule derives a \index{conclusion}conclusion formula
from the results of prior reasoning in a proof.
Each rule citation has three parts:
\begin{quote}
\begin{enumerate}
\item a proof above the line (or multiple proofs, depending on the rule),
\item a line annotated with the name of the cited inference rule, and
\item exactly one logic formula below the line (the conclusion).
\end{enumerate}
\end{quote}

\label{def-deductive-proof}
A \emph{deductive proof} is a sequence of citations of inference rules
in which the final citation has, below the line,
the formula that is the conclusion of the theorem that the proof verifies.
An inference rule can place specific constraints on the formula
that is its conclusion and/or on the formulas that are the
conclusions of the proofs that the rule requires above the line.
For example, the \{$\wedge$ elimination 1\} inference rule
(Figure~\ref{fig-02-deduction-rules}, page \pageref{fig-02-deduction-rules})
requires one \index{proof}proof above the line
and constrains the conclusion of that proof
to be a logical-and formula $(a \wedge b)$.
The \{$\wedge$ introduction\} rule, on the other hand,
requires two proofs above the line and
constrains its conclusion (below the line)
to be a logical-and formula $(a \wedge b)$.
Some rules place constraints on formulas both
above and below the line.
That is, they place constraints on the formulas
that are the conclusions of proofs above the line
and also place constraints
on the formula below the 
\index{line, above/below}\index{above the line}\index{below the line}line.
For example, the \{$\neg$ introduction\} rule is one that
constrains formulas both above and below the line.

When a rule is \index{citation}cited in a deductive proof,
the name of the rule is written just to the right of
the line that separates the proofs that the rule requires above the line
from the conclusion that the citation derives,
which is the formula written below the line.
When an inference rule requires multiple proofs above the line,
dashed lines separate those proofs.
Each of the proofs that the rule requires above the line
is, itself, a proof.
That is, it is also a sequence of citations ending in a conclusion formula,
and that formula must meet any constraints
specified in the rule.

The \index{scope}\index{inference rule!scope}\emph{scope} of a 
\index{citation}\index{rule citation}\index{inference rule!citation}citation of an inference rule
extends upward to the beginning of the first of the proofs
above the line that the rule requires.
The scopes of citations in a proof can overlap,
and when they do, some proofs are nested inside others.
In fact, the scope of the last rule citation in a proof
always extends upward to the beginning of the proof,
so the scopes of all of the other citations are nested
within the scope of the last citation.\footnote{Because
of the nesting in the scopes of rule citations,
proofs by natural deduction
are sometimes written with parentheses,
like algebraic formulas
or displayed as ``tree diagrams'',
with the conclusion of the theorem at the bottom and
the citations spread out, upwards,
in a branching structure
that makes the overlapping (and non-overlapping)
of scopes easy to see.
We have chosen a vertical format with implicit
overlapping because this notation is more compact
than a tree diagram and, in our judgment,
more readable than a parenthesized proof formula.}

Wherever an inference rule requires a proof above the line,
an assumption can take the place of that proof.
That is,
an assumption can always stand in lieu of a proof.
A logic formula that is marked as an assumption
is a hypothesis of the theorem verified by the proof
(unless that assumption is subsequently \emph{discharged},
a special dispensation
that will be discussed later).
So, any proof may begin with a formula
that is marked as an assumption.
However, no proof can have
a formula marked as an assumption after
the first rule citation in the proof.
Assumptions can appear only above the line
of the first citation in the sequence of citations
comprising the proof, but since citations
(and, therefore, proofs) can be nested,
an assumption need not be the first line in
the entire proof.
It may, instead, be the first line
in a proof that is nested inside another proof.

The \index{modus ponens}\{modus ponens\} rule
(Figure \ref{fig-02-deduction-rules}, page \pageref{fig-02-deduction-rules})
is probably the most widely recognized rule of inference because
of the well known ``Socrates was mortal'' application
(Figure \ref{fig:socrates-proof}, page \pageref{fig:socrates-proof})
The rule says that if there is a proof concluding in
the formula $a$ and a proof concluding in the formula ($a \rightarrow b$),
those proofs, together with a citation of modus ponens,
derive the conclusion $b$.\footnote{Deductive
proofs are one-directional,
and so is the theorem about Socrates.
One can conclude mortality from two hypotheses stating certain conditions of life,
but one cannot derive those conditions of life from the mortality of Socrates.
Rabbits, for example, are mortal, but they are not men.}

Proofs by natural deduction follow strictly a prescribed format,
and it is worth going over that format again, in slightly different terms.
The proof of a theorem that has
$n$ hypotheses will have $n$ different
formulas representing those hypotheses
marked as assumptions
at the beginning of one or more of the proofs
required by the inference rules that the proof cites.
That is, each hypothesis, at the point where it is introduced
into the proof, is marked as an assumption.
An assumption, so marked, stands in lieu of the proof
required at that point by whatever inference rule is being cited.
A particular formula in a proof may be marked as an assumption
at more than one point in a proof, but no matter how many places
it appears as an assumption, it is still just
one hypothesis of the theorem being proved.
A proof of a theorem with $n$ hypotheses will have at least $n$
formulas marked as assumptions.
It will have more than $n$ formulas marked as assumptions
if two or more of the assumptions specify the same formula
(or if s formula is discharged).

Assumptions must appear at the beginning of a
a proof, before the citation of an
inference rule in the proof.
Assumptions cannot pop up after the citation
of an inference rule in a proof.
Of course, since \index{dashed line}\index{line!dashed}dashed lines indicate separate proofs,
the \index{assumption}assumption need not be at the beginning of the entire
proof, but could, instead, be at the beginning of
a proof separated from another proof by a dashed line.
The \{Socrates was mortal\} theorem has two hypotheses.
One is marked as an assumption standing in lieu of the first proof
required by a citation of \{modus ponens\},
and the other is marked as an assumption
standing in lieu of the second proof
required by \{modus ponens\}.

Three of the inference rules of natural deduction
(Figure \ref{fig-02-deduction-rules})
involve the $\wedge$ operator:
\{$\wedge$ introduction\},
\{$\wedge$ elimination 1\}, and
\{$\wedge$ elimination 2\}.
Using these rules, we can construct a deductive proof
of the commutativity law for $\wedge$,
and the proof will serve as a reasonably straightforward
example to get started with natural deduction.

\begin{figure}
Theorem \{$\wedge$ commutes\}: $a \wedge b$ $\vdash$ $b \wedge a$ \\
proof
\begin{center}
\begin{tabular}{ll}
Assume $a \wedge b$                             &\emph{hypothesis of theorem}\\
-------------------\{$\wedge$ elimination 2\}   &\\
~~~~~~~~~~$b$                                   &\\
 - - - - - - - - - - - - - - - - - - - - - - - -&\emph{separates 2 proofs required for }\{$\wedge$ introduction\} \emph{citation}\\
Assume $a \wedge b$                             &\emph{hypothesis of theorem (reused)}\\
-------------------\{$\wedge$ elimination 1\}   &\\
~~~~~~~~~~$a$                                   &\\
-------------------\{$\wedge$ introduction\}    &\emph{proved} $b$, \emph{proved} $a$, \emph{conclude} $(b \wedge a)$\emph{; scope extends to top}\\
~~~~~~~~$b \wedge a$                            &\emph{conclusion of theorem}\\
\end{tabular}
\end{center}
\index{proof}
\index{proof!deduction}
\caption{\{$\wedge$ commutes\}: Citing Three Inference Rules Involving $\wedge$}
\label{fig:and-commutes-proof}
\end{figure}

The proof in
Figure \ref{fig:and-commutes-proof} (page \pageref{fig:and-commutes-proof})
cites the \{$\wedge$ introduction\} inference rule,
a rule that requires two proofs above the line.
The first of those proofs, in this example, has the hypothesis
of the theorem above the line, annotated as an assumption.
It then cites the \{$\wedge$ elimination 2\} rule,
which requires the right-hand operand of the $\wedge$
above the line to go under the line as the conclusion.
Then comes the dashed line separating
the two proofs required by \{$\wedge$ introduction\}.
The second of the proofs comes next.
It has the same form as the first proof,
except that it cites \{$\wedge$ elimination 1\} instead of \{$\wedge$ elimination 2\}.
The \{$\wedge$ elimination 1\} rule brings the first operand of the $\wedge$
down below the line.
The \{$\wedge$ introduction\} rule requires the
conclusion of the first proof above line to
become the left-hand operand of the $\wedge$
operation that the rule introduces,
and it requires the conclusion of the second
proof to be the right-hand operand.
The $\wedge$ formula with those two operands
is the conclusion below the line the citation of the \{$\wedge$ introduction\} inference rule.
That final citation completes the proof of the \{$\wedge$ commutes\} theorem.

To recap, the proof of the {\{$\wedge$ commutes\} theorem
consisted of three proofs, in a sense,
one being the whole proof, ending in the citation of
the \{$\wedge$ introduction\} rule,
and the other two being the proofs required by the citation of \{$\wedge$ introduction\}.
Each of the three proofs in this example consisted of exactly one rule citation.
Sometimes there are several rule citations in a proof, sometimes only one,
and sometime none (when the proof is an assumption).

\begin{aside}
As in Boolean algebra, variables in deductive reasoning
stand for arbitrary formulas.
Any grammatically correct formula
can be plugged in for a variable in a theorem,
as long as all of the instances of that variable are
replaced by that same formula.

For example,
Theorem \{$\wedge$ commutes\} ($a \wedge b$ $\vdash$ $b \wedge a$)
has two variables, $a$ and $b$.
Since ($x \vee y$) and ($y \rightarrow z$) are formulas,
the theorem justifies the following, more specialized
version:
\begin{center}
$(x \vee y) \wedge (y \rightarrow z)$ $\vdash$ $(y \rightarrow z) \wedge (x \vee y)$
\end{center}
By the same token, it also justifies the following restatement of the
theorem that uses the formula $b$ in place of $a$ and the formula $a$ in place of $b$.
\begin{center}
$b \wedge a$ $\vdash$ $a \wedge b$
\end{center}

This is not new to you.
Variables are used in this manner throughout the book.
We bring it up again because it is an important
concept to keep in mind when citing inference rules
or theorems.

\caption{Variables Stand for Formulas}
\index{variable}
\index{formula}
\label{variable-stand-for-formulas}
\end{aside}

Two formulas are annotated as assumptions in the
proof of the \{$\wedge$ commutes\} theorem.
This suggests that the theorem has
two hypotheses,
but in this case both assumptions are the same formula.
A particular formula can be used as many times as necessary as
an assumption in a proof, but it only counts as one hypothesis
in the theorem.
The number of hypotheses
of the theorem is the number of distinct
formulas annotated as assumptions in the proof,
less the number of those assumptions that are discharged
by citations of the \{$\rightarrow$ introduction\} inference rule,
which we will discuss shortly.

\begin{figure}
Theorem \{self-implication\}: $\vdash$ $a \rightarrow a$ ~~~~\emph{Note: This theorem has no hypotheses.}\\
proof
\begin{center}
\begin{tabular}{ll}
Assume $a$                  &\emph{assumption discharged later}\\
---------------\{identity\} &\\
~~~~~$a$                    &\\
---------------\{$\rightarrow$ introduction\} &\emph{assumed} $a$\emph{, proved} $a$\emph{, conclude} $a \rightarrow a$\\
~~$a \rightarrow a$         &\emph{conclusion of theorem}\\
~~Discharge $a$             &\emph{discharged by} \{$\rightarrow$ introduction\} \emph{citation}, \emph{as promised}\\
\end{tabular}
\end{center}
\index{proof}
\index{proof!deduction}
\caption{$\vdash$ $a \rightarrow a$: Citing  \{identity\} and \{$\rightarrow$\ introduction\} Inference Rules}
\label{fig:or-self-imp-proof}
\end{figure}

Given a proof, it is straightforward to extract
the theorem it proves.
On the left of the turnstile ($\vdash$) put all of the different
formulas annotated as assumptions in the proof,
except those that are discharged.
After the turnstile, write the formula in the
conclusion at the end of the proof.

Now we come to the issue of \index{discharge}discharging formulas
assumed in proofs.
The inference rule \{$\rightarrow$ introduction\}
has some unique characteristics.
It requires only one proof above the line,
but that proof must begin with a formula
(let's call it $a$)
marked as an assumption.
To repeat, the proof above the line in a citation of
\{$\rightarrow$ introduction\} that
concludes with the formula $(a \rightarrow b)$
below the line
must begin with ``Assume $a$'' and
then continue from there to derive the formula $b$, just above the line.
The scope of the \{$\rightarrow$ introduction\} citation
extends upward to the required assumption.

Normally, any formula assumed at the beginning of a proof
becomes a \index{hypothesis}hypothesis of the theorem that was proved.
However, a \index{discharge}discharged assumption
is not added to the hypotheses of the theorem.
A citation of the \{$\rightarrow$ introduction\} rule
triggers a discharge of the assumed formula that the
rule requires at the beginning of the proof above the line.
(Without that assumption, the citation,
and therefore the proof, is not valid.)
The reason for the discharge is that the truth of an implication
formula doesn't place any constraints on the value of its
left-hand operand.
The implication says that if the left-hand operand
has the value \emph{True}, then so does the right-hand operand,
and the proof confirms that relationship.
Since the citation of the
\{$\rightarrow$ introduction\} rule
simply confirms that the implication formula below the line
is true, the citation places no constraints on the value
of the left-hand operand.
The assumption only applies within the scope
of the citation of the \{$\rightarrow$ introduction\} inference rule
and, therefore, does not become a hypothesis of the theorem being proved
(unless it is assumed elsewhere in the proof and not discharged).

Figure \ref{fig:or-self-imp-proof} (page \pageref{fig:or-self-imp-proof})
displays a proof of the \{self-implication\} theorem,
which says that formulas of the form ($a \rightarrow a$) always have the value \emph{True}.
The proof cites the \{identity\} rule,
which is included among the inference rules to make it
possible for proofs by natural deduction to stay strictly
within the formalism required by the system.
The \{identity\} rule says that a proof of a formula $a$
can be followed by a citation of \{identity\} rule
with that same formula, $a$, as its conclusion below the line.

The application of any rule must \index{match}\index{inference rule!match}\index{rule!match}match 
the template in the specification of the rule,
and the \{identity\} rule is sometimes needed to make it possible to match a template.
That is what happens in the proof of self-implication (Figure \ref{fig:or-self-imp-proof}).
The proof cites the \{$\rightarrow$ introduction\} rule
to derive the formula $(a \rightarrow a)$,
and that citation requires
a proof above the line that begins with the assumption of $a$
and concludes with the formula $a$, just above the line.
The \{identity\} rule makes it possible to satisfy this requirement.
In the proof of self-implication,
the citation of \{$\rightarrow$ introduction\} rule follows
the derivation of $a$ from $a$ and triggers a discharge
of the assumption of $a$ at the beginning of the proof.
There are no other assumed formulas in the proof,
so the theorem proved has no hypotheses.
That is, the \index{proof}proof confirms that the \index{conclusion}conclusion formula
\index{implication}
$(a \rightarrow a)$ has the value $True$, regardless of
the value of the formula $a$.

\begin{figure}
Theorem \{$\vee$ commutes\}: $a \vee b$ $\vdash$ $b \vee a$ \\
proof
\begin{center}
\begin{tabular}{ll}
Assume $a \vee b$          &\emph{hypothesis of theorem}\\
 - - - - - - - - - - - - - - - - - - - - - -&\emph{dashes separate} $1^{st}$ \emph{proof from} $2^{nd}$ \emph{req'd by} \{$\vee$ elimination\} \\
Assume $a$          &\emph{this assumption will be discharged}\\
--------------\{$\vee$ introduction 2\} &\emph{allows arbitrary left-hand operand in conclusion}\\
~~$(b \vee a)$        &\\
-----------------\{$\rightarrow$ introduction\} &\emph{assumed} $a$\emph{, proved} $(b \vee a)$\emph{, conclude} $a \rightarrow (b \vee a)$ \\
~$a \rightarrow (b \vee a)$ &\{$\vee$ elimination\} \emph{, in this case, requires this conclusion here}\\
Discharge $a$              &\emph{discharged by} \{$\rightarrow$ introduction\} \emph{citation, as promised}\\
 - - - - - - - - - - - - - - - - - - - - - -&\emph{dashes separate} $2^{nd}$ \emph{proof from} $3^{rd}$ \emph{req'd by} \{$\vee$ elimination\}\\
Assume $b$          &\emph{this assumption will be discharged}\\
--------------\{$\vee$ introduction 1\} &\emph{allows arbitrary right-hand operand in conclusion}\\
~~$(b \vee a)$        &\\
-----------------\{$\rightarrow$ introduction\} &\emph{assumed} $b$\emph{, proved} $(b \vee a)$\emph{, conclude} $b \rightarrow (b \vee a)$\\
~$b \rightarrow (b \vee a)$ &\{$\vee$ elimination\} \emph{, in this case, requires this conclusion here}\\
Discharge $b$              &\emph{discharged by} \{$\rightarrow$ introduction\} \emph{citation, as promised}\\
---------------\{$\vee$ elimination\}       &\emph{3 proofs req'd above line; scope extends to} ``Assume $(a \vee b)$''\\
~~~~$(b \vee a)$        &\emph{assumed} $(a \vee b)$\emph{, proved} $a \rightarrow (b \vee a)$\emph{, proved} $b \rightarrow (b \vee a)$ \emph{,}\\
       &~~~~\emph{conclude} $(b \vee a)$\emph{, the conclusion of the theorem}\\
\end{tabular}
\end{center}
\index{proof}
\index{proof!deduction}
\caption{\{$\vee$ commutes\}: Citing \{$\vee$ elimination\}}
\label{fig:or-commutes-proof}
\end{figure}

We now take on a theorem whose proof is more complex
than those we have studied so far.
The \{$\wedge$ commutes\} theorem proved earlier
is similar to the \{$\vee$ commutes\} theorem
that we will discuss now, but the proofs are very different.
Figure \ref{fig:or-commutes-proof} (page \pageref{fig:or-commutes-proof}),
which displays the proof of the \{$\vee$ commutes\} theorem,
cites all three of inference rules involving the $\vee$ operator
and affords an example of how the \{$\vee$ elimination\} rule works.

The \{$\vee$ elimination\} rule calls for three proofs above the line.
The first of the three proofs must conclude in a formula
that is a logical-or, $(a \vee b)$, where, of course,
$a$ and $b$ can be any grammatically correct logic formulas.
The second proof must conclude in an implication, $a \rightarrow c$.
In this implication, $a$ is the left-hand operand of the $\vee$ formula
that concluded the first proof above the line,
and $c$ (which of course can be a formula rather than just a variable)
is the conclusion under the line citing the \{$\vee$ elimination\} rule.
The third proof must conclude in an implication, $b \rightarrow c$,
with the same right-hand operand as the implication that concludes
the second proof, but with a left-hand operand that is the same
as the right-hand operand of the logical-or that concludes the
first proof above the line.
The \{$\vee$ elimination\} rule is complicated,
but is surprisingly easy to cite
because the rule places so many constraints on its various parts.

The proof in Figure~\ref{fig:or-commutes-proof} cites both of the
``or introduction'' rules:
\{$\vee$ introduction 1\} and \{$\vee$ introduction 2\}.
These rules allow the introduction of an arbitrary formula
into the proof.
That is, when you cite the rule, you can make up one of the
formulas in the conclusion (namely, the right-hand operand of
the logical-or in the case of \{$\vee$ introduction 1\}
and the left-hand operand in the case of \{$\vee$ introduction 2\}).
The formula you choose can be as complicated or as simple as you like,
whatever is needed to make the proof work.
In the proof at hand,
the made-up formulas are simple ($b$ in one case and $a$ in the other case),
but are exactly what the proof needs.

In addition to citing all three inference rules involving the $\vee$ operator,
the proof cites the \{$\rightarrow$ introduction\} rule twice.
Both of those citations require discharges,
so there's lot of action in the proof.
Figure~\ref{fig:or-commutes-proof}
elucidates some of the details with commentary
intended to help you work through the details
to understand how the citations fit together and
comprise a proof of the \{$\vee$ commutes\} theorem.

Deductive proofs are one-directional,
so it's a little ironic that most
of the theorems we've prove so far using natural deduction
turn out to be bidirectional.
The proofs went in only one direction,
but the theorems were provable in the other direction, too.

The theorem that we turn to now, the implication chain rule
(Figure \ref{fig:impchain-proof}, page \pageref{fig:impchain-proof}),
only goes in one direction.
It derives a conclusion from two hypotheses,
but the two hypotheses cannot be derived from the conclusion.
Again, commentary with the proof is intended
to help you work your way through it.
Pay particular attention to the discharge of the
assumption that is introduced at the top of the proof.

\begin{figure}
Theorem \{$\rightarrow$ chain\}
$(a \rightarrow b)$, $(b \rightarrow c)$ $\vdash$ $a \rightarrow c$ \\
proof
\begin{center}
\begin{tabular}{ll}
Assume $a$                                             &\emph{assumption discharged later}\\
 - - - - - - - - - - - - - - - - - - - - - - - -       &\emph{separates 2 proofs required by} \{modus ponens\} \emph{citation}\\
Assume $a \rightarrow b$                               &\emph{hypothesis of theorem}\\
-----------------------\{modus ponens\}                &\{modus ponens\} \emph{citation} $\dots$\\
~~~~~~~~~~~~$b$                                        &~~~~\emph{scope of citation goes up to} ``Assume $a$''\\
 - - - - - - - - - - - - - - - - - - - - - - - -       &\emph{separates 2 proofs another} \{modus ponens\} \emph{citation reqs}\\
Assume $b \rightarrow c$                               &\emph{hypothesis of theorem}\\
------------------------\{modus ponens\}               &\emph{another citation of} \{modus ponens\} $\dots$\\
~~~~~~~~~~~~$c$                                        &~~~~\emph{scope of extends to top, overlapping other scope}\\
------------------------\{$\rightarrow$ introduction\} &\emph{assumed} $a$\emph{, proved} $c$\emph{, conclude} $(a \rightarrow c)$\\
~~~~~($a \rightarrow c$)                               &\emph{conclusion of theorem} \\
~~~~~Discharge $a$                                     &\emph{discharged by} \{$\rightarrow$ introduction\} \emph{citation}\emph{, as promised}\\
\end{tabular}
\end{center}
\index{proof}
\index{proof!deduction}
\caption{Proving the Implication Chain Rule}
\label{fig:impchain-proof}
\end{figure}

In deductive proofs, previously proven theorems
can be cited as if they were inference rules.
Of course, the proof could always be carried out using inference rules alone
by copying the proof of the cited theorem in place of its citation,
but that leads to very long proofs, just as writing a computer program
without defining and invoking procedures encapsulating common operations
leads to very long programs. Long proofs, like long programs, tend
to be unreliable, maybe because it's so difficult
to analyze such a large mass of
detail without getting confused.
But, even if they weren't unreliable, they would be an eyesore,
not to mention difficult to fix if there were an error.
That's why the ability to cite proven theorems in
deductive proofs is important. It makes them shorter
and easier to comprehend incrementally, one short proof at a time.

\begin{figure}
Theorem \{modus tollens\}: $a \rightarrow b$, $\neg b$ $\vdash$ $\neg a$\\
proof
\begin{center}
\begin{tabular}{ll}
Assume $a \rightarrow b$                      &\emph{hypothesis of theorem}\\
 - - - - - - - - - - - - - - - - - - - -      &\emph{separates proofs of hypotheses of} \{$\rightarrow$ chain\} \emph{theorem}\\
Assume $\neg b$                               &\emph{hypothesis of theorem}\\
---------------\{$\neg$ elimination\}         &\\
$b \rightarrow False$                         &\\
---------------\{$\rightarrow$ chain\}        & \emph{citing theorem with 2 hypotheses; scope extends to top of proof}\\
$a \rightarrow False$                         &\emph{assumed} $a \rightarrow b$, \emph{proved} $b \rightarrow False$, \emph{conclude} $a \rightarrow False$\\
---------------\{$\neg$ introduction\}        &\\
~~~~$\neg a$                                  &\\
\end{tabular}
\end{center}
\index{proof}
\index{proof!deduction}
\index{modus tollens}
\caption{Modus Tollens: Citing a Theorem to Justify an Inference}
\label{fig:modtol-proof}
\end{figure}

A citation of a theorem in a proof must be preceded by proofs of
each of its hypotheses above the line, just as
each inference rule citation must be preceded by a certain number of proofs above the line.
As with inference rules that require multiple proofs above the line,
we use a dashed line to separate the required proofs
when citing a theorem that has more than one hypothesis and therefore
requires more than one proof above the line.
Figure \ref{fig:modtol-proof} (page \pageref{fig:modtol-proof})
displays a proof of the modus tollens theorem\footnote{The
inference rule \{modus ponens\} says that the conclusion of an implication
can be derived from a proof of its hypothesis.
The modus tollens theorem says that the hypothesis
of an implication can be derived from the negation of its conclusion.}
that cites the implication chain rule theorem.
Since that theorem has two hypotheses, there are two proofs above
the line where the theorem is cited, and those proofs conclude in
the implication formulas that are the hypotheses of the implication chain rule.

The \{reductio ad absurdum\} rule supports 
``proof by contradiction''.
It says that if you can prove that the formula
$(\neg a) \rightarrow$ \emph{False} is true
you can conclude that the formula $a$ is true.
The proof in Figure~\ref{fig:dbl-neg-fwd} (page \pageref{fig:dbl-neg-fwd})
cites the \index{reductio ad absurdum}reductio ad absurdum rule 
to prove a theorem about double negation.

\begin{figure}
Theorem \{$\neg \neg$ forward\}: $(\neg(\neg a))$ $\vdash$ $a$\\
proof
\begin{center}
\begin{tabular}{ll}
Assume $(\neg(\neg a))$                       &\emph{hypothesis of theorem}\\
----------------------\{$\neg$ elimination\}  &\\
~~$(\neg a) \rightarrow False$                &\\
----------------------\{reductio ad absurdum\}&\emph{proved} $(\neg a) \rightarrow False$, \emph{conclude} $a$\\
~~~~~~~~~~~~$a$                               &\\
\end{tabular}
\end{center}
\index{proof}
\index{proof!deduction}
\index{proof!contradiction}
\index{contradiction!proof by}
\caption{\{$\neg \neg$ forward\}: Citing Reductio ad Absurdum}
\label{fig:dbl-neg-fwd}
\end{figure}

Citations in the example proofs, so far, have included all of the inference rules
but one. The rule we haven't used yet is \{contradition\}.\footnote{It
is ironic that proofs citing the \{reductio ad absurdum\} rule
are called proofs by contradiction, while proofs citing the
\{contradiction\} rule have no special name.
Nevertheless, that is the custom, maybe because
the \{contradiction\} rule, like the \{identity\} rule,
is needed primarily to facilitate the formal details of
natural deduction.}
The proof of the \{disjunctive syllogism\} theorem displayed in
Figure~{\ref{fig:disjunctive-syllogism-nd} (page \pageref{fig:disjunctive-syllogism-nd})
exhibits a citation of that rule.
The theorem says that if a logical-or is known to be true,
and its left-hand operand is known to be false,
then its right-hand operand must be true.
The strategy employs the \{$\vee$ elimination\} rule,
which calls for three proofs above the line.
In this case, the first of those proofs is simply an assumption of
the logical-or formula that is a hypothesis of the theorem.
The second proof derives $False$ from the other hypothesis
of the theorem and an assumption of the left-hand operand
of the logical-or, and that assumption is discharged when
the proof cites the \{$\rightarrow$ introduction\} rule.
The third proof is similar to the second proof,
but cites the \{identity\} rule
where the second proof cited the \{contradition\} rule.

Creating proofs by \index{natural deduction}natural deduction is hard.
It requires a lot of practice, just to get
a firm grasp of the ideas.
The following exercises provide an opportunity
to get some of that practice.

\begin{figure}
Theorem \{disjunctive syllogism\}: $a \vee b$, $\neg a$ $\vdash$ $b$ \\
proof
\begin{center}
\begin{tabular}{ll}
Assume $(a \vee b)$          &\emph{hypothesis of theorem}\\
 - - - - - - - - - - - - - - - - - - - - - -&\emph{dashes separate} $1^{st}$ \emph{proof from} $2^{nd}$ \emph{req'd by} \{$\vee$ elimination\}\\
Assume $a$          & \emph{this assumption will be discharged}\\
 - - - - - - - - - - - - - - - - - - - - - -& \emph{separates} $1^{st}$ \emph{and} $2^{nd}$ \emph{proofs required by} \{modus ponens\} \\
Assume $(\neg a)$        & \emph{hypothesis of theorem}\\
-------------------\{$\neg$ elimination\} \\
~~$a \rightarrow False$ &\\
-----------------\{modus ponens\} &\emph{2 proofs required above line; scope goes up to} ``Assume $a$''\\
~~~~$False$            &\emph{conclusion} $False$ \emph{required to cite} \{contradiction\} \emph{rule}\\
-----------------\{contradiction\} &<<<< \textbf{\textsc{citing} \{contradiction\} \textsc{rule}}\emph{, justifies any conclusion}\\
~~~~~~~~$b$              &\emph{now we have derived $b$ from assumption $a$}\\
-----------------\{$\rightarrow$ introduction\} & \emph{assumed $a$, proved $b$, conclude $(a \rightarrow b)$}\\
~~~~$a \rightarrow b$ &\emph{conclusion required by citation of} \{$\vee$ elimination\} \\
Discharge $a$    &\emph{discharged by} \{$\rightarrow$ introduction\} \emph{citation, as promised}\\
 - - - - - - - - - - - - - - - - - - - - - -&\emph{dashes separate} $2^{nd}$ \emph{proof from} $3^{rd}$ \emph{req'd by} \{$\vee$ elimination\}\\
Assume $b$          &\emph{this assumption will be discharged}\\
--------------\{identity\} &\\
~~~~~~~~$b$          &\\
-----------------\{$\rightarrow$ introduction\} &\emph{assumed $b$, proved $b$, conclude $(b \rightarrow b)$}\\
~~~~$b \rightarrow b$ &\emph{conclusion required by citation of} \{$\vee$ elimination\}\\
Discharge $b$              & \emph{discharged by} \{$\rightarrow$ introduction\} \emph{citation, as promised}\\
---------------\{$\vee$ elimination\}       &\emph{3 proofs req'd above line; scope extends to} ``Assume $(a \vee b)$''\\
~~~~~~~~$b$        &\emph{assumed} $(a \vee b)$\emph{, proved} $(a \rightarrow b)$\emph{, proved} $(b \rightarrow b)$\emph{, conclude }$b$\\
\end{tabular}
\end{center}
\index{proof}
\index{proof!deduction}
\caption{\{disjunctive syllogism\}: Citing \{contradiction\}}
\label{fig:disjunctive-syllogism-nd}
\end{figure}

\begin{ExerciseList}

\Exercise
\label{thm:and-complement}
Use natural deduction to prove
Theorem \{$\wedge$ complement\}: $a$, $\neg a$ $\vdash$ $False$

\Exercise
Use natural deduction to prove the following theorem:
$a$, $a \rightarrow b$, $b \rightarrow c$ $\vdash$ $c$

\Exercise
Derive the equation
$((a \wedge ((a \rightarrow b) \wedge (b \rightarrow c))) \rightarrow c)$ = $True$
using the axioms of Boolean algebra
(Figure~\ref{fig-02-boolean-axioms}, page \pageref{fig-02-boolean-axioms}).

\Exercise
Explain the connection between the previous two exercises.

\Exercise
Use natural deduction to prove the following theorem:
$\vdash$ $(a \wedge b) \rightarrow a$

\Exercise
Use natural deduction to prove
Theorem \{nor commutes\}: $\neg (a \vee b)$ $\vdash$ $\neg (b \vee a)$\\
\emph{Note}: The \{$\vee$ commutes\} theorem will not help because
$\neg (a \vee b)$ is a negation formula, not a logical-or formula.
It has a logical-or as a subformula, but natural deduction
requires matching the whole formula, not a subformula.

\Exercise
Use natural deduction to prove
Theorem \{nand commutes\}: $\neg (a \wedge b)$ $\vdash$ $\neg (b \wedge a)$\\
\emph{Note}: The \{$\wedge$ commutes\} theorem will not help in this proof
for the same reason that \{$\vee$ commutes\} does not help
in the previous exercise.

\Exercise
Use natural deduction to prove
Theorem \{nor elimination 1\}: $\neg (a \vee b)$ $\vdash$ $\neg a$

\Exercise
Use natural deduction to prove \{DeMorgan $\vee$ forward\}:
$\neg (a \vee b)$ $\vdash$ $(\neg a) \wedge (\neg b)$

\Exercise
Use natural deduction to prove \{DeMorgan $\vee$ backward\}:
$(\neg a) \wedge (\neg b)$ $\vdash$ $\neg (a \vee b)$

\Exercise
Use natural deduction to prove
Theorem \{$\vee$ complement\}: $\vdash$ $a \vee (\neg a)$ \\
\emph{Hint}: Use the \{reductio ad absurdum\} inference rule,
cite the \{nor elimination 1\} and \{$\wedge$ complement\}
theorems from earlier exercises,
and remember that you can assume the hypothesis
of the theorem as many times in the proof as you like.

\end{ExerciseList}


\section{Predicates and Quantifiers}
\label{sec:predicates-and-quantifiers}

\label{proposition-def}
We have been using the term \emph{proposition} to mean a formula that is either true or false.
\label{predicate-def}
\index{predicate}
Any set\footnote{The
term 
\index{set}
``set'' has a checkered history in mathematics.
It is tricky to define in a way that avoids contradictions
like Russell's paradox, which you can read about
in online articles or textbooks.
Instead of dwelling on those issues,
we are going to assume that,
for any of the sets that we talk about,
we have a way of figuring out whether any given
item is an element of the set or not.
Usually, our sets will be familiar ones,
such as the set of natural numbers, which
is the universe of discourse indexing the propositions
in proofs by mathematical induction or
the set of lists that can be constructed
by an ACL2 program.
Occasionally, the universe of discourse will be
the set of all programs that can be expressed in a given
programming language.
In that case
any interpreter for the language
can determine whether or
not a given item is in the set.}
of propositions is called,
when the set is taken as a whole, a \emph{predicate}.
We will specify that a \index{predicate}predicate 
is a collection of propositions
indexed by a set known as the
\label{def-universe-of-discourse}
\index{universe of discourse}\emph{universe of discourse}.
If $P$ is a \index{predicate!universe of discourse}predicate, and $x$ is an element from
the universe of discourse, then $P(x)$ is
the \index{proposition}\index{proposition!vs predicate}\index{predicate!vs proposition}proposition 
selected from the predicate by the index $x$.\footnote{You
can think of the predicate as an
operator that delivers the associated proposition as output
when supplied with the index of the proposition as input,
such as the ACL2 operator natp: (natp $x$) is true if
$x$ is a natural number and false otherwise.
No matter whether you look at it as a set of propositions
indexed by a universe of discourse or an operator that
delivers a true/false value given an element of the universe of discourse,
the predicate is the same mathematical entity.
The indexed-set approach is sometimes called an \index{extensional}``extensional'' view
because it focuses on the externally observable characteristics of the predicate,
while the operator perspective is called an \index{intensional}``intensional'' view 
because it involves the internal workings of a way to produce the true/false value
of a proposition, given its index.
Occasionally, a predicate will not correspond to a computation,
and in that case the operator (intensional) view
isn't valid because there will be no
computation associated with the predicate.
The extensional view is the way
to think about predicates of that kind.}
}

If we write a formula that connects some of the propositions
of the predicate P with AND
$(P(x_1) \wedge P(x_2) \wedge P(x_3) \wedge P(x_4))$,
the formula has the value $True$
because all of the propositions in the formula ($P(x_1)$, $P(x_2)$, $P(x_3)$, $P(x_4)$)
are $True$.
We would like to be able to write a formula
for the AND of all the propositions in the predicate P.
We could do this with an ordinary AND formula,
but this gets bulky when there are a lot of elements
in the universe of discourse,
and it's impossible when the universe of discourse
has an infinite number of elements because the
formula would have an infinite number of symbols in it.

The usual way to write the AND of all the propositions in a predicate
makes use of a symbol that looks like an upside-down letter A ($\forall$)
which is known as the
\label{def:universal-quantifier}
\index{universal quantifier ($\forall$)}\index{quantifier!$\forall$}\index{quantifier!universal}\index{forall ($\forall$)}
``universal quantifier''.
The  formula $(\forall x.P(x))$\footnote{The
formula $(\forall x. P(x))$ reads ``for all $x$, $P(x)$.''}
stands for the AND of all the propositions in the predicate P.
The value of the formula is $True$
if there is no element $x$ from the universe of discourse
for which the proposition $P(x)$ is $False$.

For example, suppose $n$ stands for a natural number
and we take use
$E(n)$ as a shorthand for the proposition ``$2n$ is a non-negative, even number''.
Then \{$E(0)$, $E(1)$,$E(2)$, \dots\}
is a set of propositions indexed by the natural numbers.
For each natural number $n$, there is a corresponding proposition $E(n)$.
This means that E is a predicate with the natural numbers
as its universe of discourse.

If we write a formula that connects some of these propositions with
$(E(5) \wedge E(3) \wedge E(7) \wedge E(1))$,
the formula has the value $True$
because all four of those propositions are $True$.
In fact all of the propositions in the predicate E are $True$.
$E(n)$ is $True$, regardless of which natural number $n$ stands for,
because any number of the form $2n$ is a non-negative, even number
when $n$ is a natural number.
Therefore, there is no element $n$ in the universe of discourse of
the predicate $E$ for which the proposition $E(n)$ is $False$,
which means that the value of the quantified formula $\forall n.E(n)$
is $True$.

A
\label{def:quantifier}
\index{quantifier}quantifier converts a set of propositions (that is, a predicate)
into a single, true/false value (that is, a proposition).
A formula using a quantifier starts with a quantifier symbol followed by
a variable, then a period, and finally a logic formula
representing a proposition. The variable,
which is known as the
\label{def:bound-variable}
\index{bound variable}\index{variable!bound}
``bound variable'' in the formula, stands for an
element of the universe of discourse, and the quantification
ranges over the entire universe of discourse.
The universe of discourse is not specified directly
in the formula, but the formula has no meaning unless
the universe of discourse is understood in the context
of the formula.

\begin{aside}
Let $P$ be a predicate.
The formula $\forall x.P(x)$ is false when there is
at least one index $x$ in the universe of discourse
for which $P(x)$ is false.
Otherwise, the $\forall$ quantification is true.
If the universe of discourse is empty,
there aren't any indexes at all,
let alone one for which the predicate is false.
Therefore, $\forall x.P(x)$ is true
when the universe of discourse is empty.

Using a similar rationale, a $\exists$ 
\index{there exists ($\exists$)}\index{existensial quantifier!$\exists$}quantification
is false when the universe of discourse is empty
because it can only be true if there is
at least one element, $x$, in the universe of discourse
for which $P(x)$ is true.
\caption{Quantifier with Empty Universe}
\index{quantifier!empty universe}
\label{empty-forall}
\end{aside}

In a formula, any variable that is not bound is
called a
\index{bound variable}\index{variable!free}
\label{def:free-variable}
``free variable''.
In the formula $(\forall x.P(x)) \vee y$,
$x$ is a bound variable, and $y$ is a free variable.
This can get a bit tricky, but you have to keep it
straight to understand how quantifiers work.
A tricky case is the formula
$(\forall x.P(x)) \vee x$.
In this formula, $x$ is a bound variable in the
operand on the left-hand side of the $\vee$ operator,
but is a free variable on the right-hand side.

There are many quantifiers in logic, but the only other
quantifier we will use is known as the
\index{quantifier!$\exists$}\index{quantifier!existential}\index{existential quantifier}
\label{def:existential-quantifier}
``existential quantifier''.
It forms the OR of all the propositions in a predicate
and is represented by a symbol that looks like a backwards E.
The  formula $(\exists x.P(x))$\footnote{The
formula for all $(\exists x.P(x))$ reads
``there exists $x$ such that $P(x)$.''}
has the value $True$
if there is an element $x$ from the universe of discourse
for which the proposition $P(x)$ is $True$.

Consider the equation $(n + 7 = 12)$.
Any equation is a proposition because it is either
$True$ or $False$. Let's call that proposition $Q(n)$.
For each natural number $n$,
$Q(n)$ stands for a proposition.
So, we can take the view that $Q$ is a predicate
with the natural numbers as its domain of discourse.
You know from algebra that there is a natural number
$n$ for which equation $(n + 7 = 12)$ holds.
That is, there is a value in the domain
of discourse for which the proposition $Q(n)$ is $True$.
Therefore, according to the definition of the
existential quantifier,
the formula $(\exists n.Q(n))$ is $True$.

The formula $(\forall n.Q(n))$, however, is $False$
because there is a natural number $n$ for which
the proposition $Q(n)$ is $False$.
In fact there are many of them
($Q(n)$ is $False$ for any natural number $n$ other than $5$),
the number of $False$ propositions in the predicate doesn't matter
in a universal quantification. One is enough.
By the definition of
the universal quantifier, the formula $(\forall n.Q(n))$
is $False$ if there is even one element of the
universe of discourse for which the proposition
$Q(n)$ is $False$.

\begin{aside}
The three-line variation of the equals sign
indicates that the term on the left stands
for the formula on the right, \emph{by definition}.
\begin{center}
\begin{tabular}{ll}
$term \equiv \dots \emph{some formula} \dots$ & ~~~~~ \emph{definition of term} \\
$Q(n) \equiv ((n + 7) = 12)$                  & ~~~~~ $Q(n)$ \emph{stands for} $((n + 7) = 12)$ \\
\end{tabular}
\end{center}
\caption{Equal by Definition: $\equiv$}
\label{aside:ch02-three-line-equal}
\end{aside}

Predicates can have more than one index.
For example, the \index{predicate}\index{predicate~multi-index}predicate $R$, 
defined as follows, has two indexes.
\begin{center}
$R(m, n) \equiv ((n + 7) = m)$
\end{center}
In this discussion the domain of discourse
for both indexes will be the natural numbers.\footnote{A
predicate with multiple indexes can
have different domains for different indexes.
One index could come from a set of numbers
and the other from a set of words, for example,
but both the first and second indexes
of the particular predicate $R$ discussed here
are be natural numbers.}
For each pair of natural numbers $(n, m)$,
$R(n, m)$ stands for a proposition (namely the
equation $((n + 7) = m)$, which is either $True$ or $False$).
The formula $(\exists n.R(n,m))$ is a different
proposition for each natural number $m$.
That makes it a set of propositions indexed by the natural numbers,
so it is a predicate with the natural numbers as its domain of discourse.
To keep things straight, let's give this predicate a name.
\begin{center}
$S(m) \equiv (\exists n.R(n,m))$
\end{center}

Let's convert this predicate to a proposition by quantifying it:
$(\forall m.S(m))$. This is a proposition, so
it is either $True$ or $False$, but which is it?
By the definition of the predicate $R$,
$S(m)$ would be $True$ if there were no natural numbers $m$
for which the quantification $(\exists n.((n+7) = m))$ were $False$.
This quantification would be $False$
if there were no natural numbers $n$ such that $((n+7) = m))$.
Suppose $m$ is the natural number zero.
In that case the equation says $((n+7) = 0))$,
and there are certainly no natural numbers $n$ such that
$((n+7) = 0))$ because $n$ would have to be negative,
and all natural numbers are zero or bigger.
Therefore, $S(0)$, which stands for the formula
$(\exists n.((n+7) = 0))$ is $False$.
Therefore, $(\forall m.S(m))$ is $False$.

By the definition of the predicate $S$,
$S(m)$ stands for the formula $(\exists n.R(n,m))$,
so we can put that formula in place of $S(m)$
in $(\forall m.S(m))$. When we do this,
the formula becomes $(\forall m.(\exists n.R(n,m)))$,
in which an existential quantification
is nested inside a universal quantification.
It can go the other way, too, and with any
combination of quantifiers.
All of the following formulas are propositions,
and with your understanding of numbers, you
can figure out which ones are $True$ and
which are $False$.
\begin{center}
$(\exists m.(\forall n.R(n,m)))$ \\
$(\exists m.(\exists n.R(n,m)))$ \\
$(\forall m.(\forall n.R(n,m)))$
\end{center}
Nested quantifications like this are common
when a predicate has multiple indexes.

\begin{ExerciseList}
\Exercise Work out the values of the following formulas,
where $R(m, n) \equiv ((n + 7) = m)$.
\begin{quote}
\begin{enumerate}[label=\alph*]
\item. $(\exists m.(\forall n.R(n,m)))$
\item. $(\exists m.(\exists n.R(n,m)))$
\item. $(\forall m.(\forall n.R(n,m)))$
\end{enumerate}
\end{quote}

\Exercise
Mark the free variables in the following formulas and say how many bound variables
each formula has.
\begin{quote}
\begin{enumerate}[label=\alph*]
\item. $(x \vee (y \rightarrow z))$
\item. $(\forall x.(P(x) \wedge (forall y.Q(y))))$
\item. $(x \rightarrow (\exists y.Q(y)))$
\item. $(\exists x.(P(x) \wedge (\forall y.Q(y))))$
\item. $((\forall x.(P(x) \rightarrow Q(y))) \vee (\forall x.W(x)))$
\item. $(\forall x. (\forall z.R(x, y, z)))$
\end{enumerate}
\end{quote}

\end{ExerciseList}

\section{Reasoning with Quantified Predicates}
\label{sec:quantifier-equations}

Quantifiers provide a way to convert predicates to propositions,
and you have some experience in reasoning about Boolean formulas constructed with
propositions and operators.
This section discusses some new methods and equations to make
the same kind of reasoning possible with formulas containing quantifiers.

Let's start with a predicate $P$ with two indexes.
$P(x,y)$ will denote the proposition in the predicate $P$ that is indexed
by the pair $(x,y)$, where $x$ comes from the universe of discourse for the first index
and $y$ from the universe of discourse for the second index.

In our discussion, we will want to provide some examples
of specific values in the universe of discourse.
We could do this by making up some special symbols for those values,
but to keep things uncomplicated at this point,
let's say that natural numbers are the universe of discourse for both indexes.
That will give us familiar symbols for particular indexes.
$P(5,2)$, $P(0,6)$, and $P(3,7)$ would be specific propositions in the predicate $P$.
$P(x,y)$ would also be a proposition in predicate $P$, but would not be a specific one
unless we knew which natural numbers $x$ and $y$ stood for.
Again, we chose natural numbers as the domain of discourse
only to make it easy to designate specific elements in the domain.
The points we make in the discussion about reasoning with quantified predicates
would be the same for other choices of domain.

Suppose we have already proved that the formula $(\forall x.(P(5, x)))$ is $True$.
How can we use this predicate in another proof?
One way is to observe that $(\forall x.(P(5, x)))$ means that all of the formulas
$P(5, 0)$, $P(5, 1)$, $P(5, 2)$, \dots are $True$,
so we can assert in a proof that, for example,
$P(5, 0) = True$. We could also assert $P(5, 1)$ is $True$, and $P(5, 2)$, and so on.
That is, once we have proved that a universally quantified formula has the value $True$,
we can use that to justify a more specific theorem that
eliminates the quantifier and replaces the bound variable by any specific value
in the universe of discourse.

Not only that, but we could replace the variable by any formula
representing a value in the domain of discourse.
For example, we could assert that if $x$ and $y$ denote natural numbers,
then $(\forall x.(P(5, 2x + y + 4)))$ is $True$.

Another formula to consider is the existentially quantification $(\exists x.(P(5, x)))$.
Suppose we know it has the value $True$ and we want to make use of that fact in a proof.
The meaning of the formula $(\exists x.(P(5, x)))$ is that
there is at least one $x$ from the universe of discourse that makes the expression $True$,
but it doesn't say which one.
It could be that $P(5, 9)$ is $True$, or that $P(5, 3)$ is $True$,
or any other proposition in P whose index is a pair whose first component is the number $5$.
It could be exactly one of them,
or just two or three, or it could even be all of them, but
there must be at least one. That's all we know
from a proof that $(\exists x.(P(5, x)))$ is $True$.

One way to make use of that fact is to use a notational convention
to indicate that what looks like a variable (which could stand for any
value in the universe of discourse our even a formula representing such a value)
is not really a variable, but is, instead, a specific value in the universe of
discourse. This is, the symbol is a constant, not a variable.
One way to do this would be to designate a special symbol, capital $C$ perhaps,
to use when we want to indicate that what looks like a variable is really a constant.
\label{def:skolem-constant}
If we need several different constants in our discussion, we could use different
subscripts: $C_x$, $C_y$, $C_{197}$, $C_{\xi})$, etc.
Another approach is to use subscripts on ordinary variables ($x_0$, $y_8$, etc)
to indicate that the symbols stand for constants, not variables.
The important thing is (1)~to say in the commentary of the proof that the new
symbol stands for a specific value from the universe of discourse and is not a variable
and (2)~to make sure to use a new symbol for each new constant and to not use that
symbol for any other purpose in the proof. In any case, what was a
bound variable (page \pageref{def:bound-variable}) in an existential quantification
becomes a free constant in the formula that represents a particular proposition in the
predicate, and it is a proposition that has the value $True$.

So what about proofs? How can we prove a statement that users quantifiers?
One approach is to systematically
remove the quantifiers, so as to produce a formula that has no quantifiers.
In other words, we
are left with formula without variables, such as $P(5,3)$ or $P(5,x_0)$ where
$x_0$ stands for a particular element in the universe of discourse whose value
we don't know, but which in any case stands for just one value and cannot
be replaced by another variable or formula.
Since there are no variables, this is really just a Boolean formula,
so it can be proved using precisely the same techniques we used for Boolean
formulas earlier.

This approach to reasoning about quantified formulas is a four-step process.

\begin{center}
\begin{tabular} {l}
\emph{Reasoning with Quantifiers: a Four-Step Strategy} \\
~~~~~~1. Rename bound variables \\
~~~~~~2. Migrate quantifiers \\
~~~~~~3. Eliminate quantifiers \\
~~~~~~4. Prove theorem about Boolean formula \\
\end{tabular}
\label{four-step-strategy-quantifiers}
\end{center}

The last step is the already familiar area of reasoning
with Boolean formulas and equations,
but the first three steps involve new ideas.

Renaming bound variables is sometimes necessary to prevent
a quantifier from accidentally referring to a different bound variable
that happens to have the same name.
For example, consider the formula
$(\forall x.Odd(x)) \vee (\forall x.Even(x))$,
where the domain of discourse for both quantifiers is the integers.
\footnote{$Odd(n) \equiv (\exists k.(n = 2k+1))$.
\label{even-number-predicate-Even}
$Even(n) \equiv (\exists k.(n = 2k))$.
The integers are the universe of discourse for the predicates (variable $n$)
and the quantifications (variable $k$).}
This formula has the value $False$ because is it not true
that all natural numbers are even numbers,
and it also not true that all are odd numbers.
There are two bound variables in the formula.
These are different variables even though they both have
the same name $x$.
The formula $(\forall x.(Odd(x) \vee Even(x)))$, on the other hand,
only has one bound variable.
Furthermore, the formula has the value $True$,
so we have to be careful to keep these formulas straight.
They look similar, but they have totally different meanings.

However, the name of a bound variable does not affect the value
of a quantified formula.
The formula $(\forall x.Even(x))$ has the same meaning
as the formula $(\forall y.Even(y))$.
So, to avoid conflating two different bound variables,
we start by choosing names for the bound variables in a formula
so that no two quantifications use the same name for the bound variable.
In the case of the formula
$(\forall x.Odd(x)) \vee (\forall x.Even(x))$,
we could, for example, change the name of the bound variable
in the quantification on the right-hand side of the OR ($\vee$):
$(\forall x.Odd(x)) \vee (\forall y.Even(y))$.
The meaning of the formula remains the same,
but the change of name prevents confusion between two different bound variables.

So suppose we have a formula that contains
a quantifier $(\forall x.(P(\dots x, \dots)))$.
How do we rename the variable $x$ in this quantifier?
First of all, we insist that when we rename $x$ we use a completely new variable name,
that is, one that does
not already appear in the formula.
This is for the same reason as before, namely that we do not want to confuse the variable
$x$ with a different variable that happens to have the same name.
Obviously, choosing a new name for $x$ that is the same as the name
of some other variable would defeat our purpose.
Second, we must ensure that when we rename a bound variable $x$ as, say,
$y$, that we replace all occurrences of that bound variable $x$ with $y$.
However, we must be careful not change to $y$ any occurrence of different bound variable
that happens also to have the name $x$.
For example, recall that there are two different, but identically named,
bound variables in the formula
$(\forall x.Odd(x)) \vee (\forall x.Even(x))$.
We would want to change one of them to a new name, such as $y$.
That would produce either the formula
$(\forall x.Odd(x)) \vee (\forall y.Even(y))$ or the formula
$(\forall y.Odd(y)) \vee (\forall x.Even(x))$.

For example, suppose we are trying to prove that
if P is a predicate with two indexes
that have the same universe of discourse,
then the following formula has the value $True$.
$$(\exists y. (\forall x. P(x, y))) \rightarrow (\forall x. (\exists y. P(x, y)))$$

To prove this theorem using our four-step strategy,
we would first rename the variable $y$ on the left-hand side of the implication.
We could use any variable not already present, such as $v$.
The new formula would be the following.
$$(\exists v. (\forall x. P(x, v))) \rightarrow (\forall x. (\exists y. P(x, y)))$$
Then, we would rename the $x$ to another new variable resulting in the following.
$$(\exists v. (\forall u. P(u, v))) \rightarrow (\forall x. (\exists y. P(x, y)))$$
Now we have four variables in the formula: $u$, $v$, $x$, and $y$.
Each quantifier is associated with a bound variable of a different name,
so we won't mix up the roles of different variables.

The next step is to migrate the quantifiers to the front of the formula.
We want to end up with a formula that looks like
$$(\forall x.(\forall v.(\exists u.(\exists y.( \dots )))))$$
where there are no quantifiers in the innermost formula $( \dots )$.
Figure~\ref{fig-02-quantifiers} (page \pageref{fig-02-quantifiers})
contains some equations for formulas with quantifiers that can help
migrate quantifiers.

\begin{figure}
\begin{center}
\begin{tabular}{ll}
$((\forall x.P(\dots x, \dots)) \wedge Q) = (\forall x.P(\dots x, \dots) \wedge Q)$                 & \{$\forall\wedge$\} \\
$((\exists x.P(\dots x, \dots)) \wedge Q) = (\exists x.P(\dots x, \dots) \wedge Q)$                 & \{$\exists\wedge$\} \\
$((\forall x.P(\dots x, \dots)) \vee Q) = (\forall x.P(\dots x, \dots) \vee Q)$                     & \{$\forall\vee$\} \\
$((\exists x.P(\dots x, \dots)) \vee Q) = (\exists x.P(\dots x, \dots) \vee Q)$                     & \{$\exists\vee$\} \\
$(\neg (\forall x.P(\dots x, \dots))) = (\exists x.(\neg P(\dots x, \dots)))$                       & \{$\neg\forall$\} \\
$(\neg (\exists x.P(\dots x, \dots))) = (\forall x.(\neg P(\dots x, \dots)))$                       & \{$\neg\exists$\} \\
$((\forall x.P(\dots x, \dots)) \rightarrow Q) = (\exists x.P(\dots x, \dots) \rightarrow Q)$       & \{$\forall\rightarrow$\} \\
$((\exists x.P(\dots x, \dots)) \rightarrow Q) = (\forall x.P(\dots x, \dots) \rightarrow Q)$       & \{$\exists\rightarrow$\} \\
$(Q \rightarrow (\forall x.P(\dots x, \dots))) = (\forall x.(Q \rightarrow P(\dots x, \dots)))$     & \{$\rightarrow\forall$\} \\
$(Q \rightarrow (\exists x.P(\dots x, \dots))) = (\exists x.(Q \rightarrow P(\dots x, \dots)))$     & \{$\rightarrow\exists$\} \\
$(\forall x.P(\dots x, \dots)) = (\forall y.P(\dots y, \dots))$                                     & \{R$\forall$\} \\
$(\exists x.P(\dots x, \dots)) = (\exists y.P(\dots y, \dots))$                                     & \{R$\exists$\} \\
~~~~~~~~$x$ \emph{must not be a free variable in} $Q$ \emph{or in} $P(\dots y, \dots)$     & \\
~~~~~~~~$y$ \emph{must not be a free variable in} $P(\dots x, \dots)$                      & \\
\end{tabular}
\end{center}
\index{quantifier}
\index{quantifier!equation}
\index{equation!quantifier}
\index{equation!\{$\forall\wedge$\}}
\index{equation!\{$\exists\wedge$\}}
\index{equation!\{$\forall\vee$\}}
\index{equation!\{$\exists\vee$\}}
\index{equation!\{$\forall\rightarrow$\}}
\index{equation!\{$\exists\rightarrow$\}}
\index{equation!\{$\rightarrow\forall$\}}
\index{equation!\{$\rightarrow\exists$\}}
\index{equation!\{R$\forall$\}}
\index{equation!\{R$\exists$\}}
\index{Skolemization}
\caption{Equations of Quantifier Reasoning}
\label{fig-02-quantifiers}
\end{figure}

The restrictions on names in Figure~\ref{fig-02-quantifiers} are necessary to avoid
accidently converting a free variable to a bound variable.
In the first four equations, the formula $Q$ must not make use of the variable $x$.
If it does, the bound variable $x$ in the quantified formulas of the equation
must be renamed, citing the appropriate renaming equations \{R$\forall$\} and \{R$\exists$\}.
For example,
suppose that $((\exists x.P(\dots x, \dots)) \wedge Q)$ is $True$.
Then $Q$ must be $True$ and there is
some $x$, let's call it $x_0$, such that $P(\dots x_0, \dots)$ is $True$.
But then, $(P(\dots x_0,\dots) \wedge Q)$
is $True$, so $(\exists x.(P(x, \dots) \wedge Q))$ is also $True$.
The key observation is that the choice of a value for $x$
cannot affect the truth value of $Q$ because $x$ does
not occur as a free variable in $Q$.

\label{why-neg-forall}
The rules $\{\neg\forall\}$ and $\{\neg\exists\}$ may appear more mysterious at first,
but they are the quantifier analogs of the DeMorgan equations for $\wedge$ and $\vee$
of Figure~\ref{fig-02-boolean-axioms} (page \pageref{fig-02-boolean-axioms})
and Figure~\ref{some-boolean-theorems} (page \pageref{some-boolean-theorems}).
If we sketch a proof of one of the equations, we think you will be able
to use your experience in reasoning with Boolean equations to fill in the details
and also to prove the other equation.

Suppose that $\neg(\forall x.P(\dots x, \dots))$ is $True$.
Then (by the double-negation equation and the truth table of the negation operator
in Section~\ref{sec:boolean-equations}),  $(\forall x.P(\dots x, \dots))$ is $False$.
Therefore, from the definition of universal quantification
($\forall$, \pageref{def:universal-quantifier}),
we can conclude that there is some value $x_0$ in the universe of discourse for which
$P(\dots x, \dots)$ is $False$. That is, $\neg P(\dots x, \dots)$ is $True$.
Then, from the definition of existential quantification
(\pageref{def:existential-quantifier})
we conclude that $(\exists x.(\neg P(\dots x, \dots)))$ is $True$.

Finally, there are four equations in Figure~\ref{fig-02-quantifiers} that
describe how quantifiers behave with respect to implication ($\rightarrow$).
When the quantifier is on the left-hand side of an implication, it flips from
$\forall$ to $\exists$ and vice versa when it is migrated through the implication,
but it remains the same when it migrates from the right-hand side.
This takes a lot of people by surprise in that same way that
other aspects of implication (such as, for example, that $False \rightarrow False = True$)
surprises some people.
Remember that $(p \rightarrow q) = ((\neg p) \vee q)$
(\{implication\}, Figure~\ref{fig-02-boolean-axioms}),
so if the quantifier appears in the left-hand side of
the implication, the $\neg$ flips it before it can migrate past the implication.
In other words, the quantifier-implication equations can be derived
from from \{implication\}, \{$\neg\forall$\}, and \{$\neg\exists$\}.

Let's consider again the formula
$$((\exists y.(\forall x.P(x, y))) \rightarrow (\forall x.(\exists y.P(x, y))))$$
that we have already converted to
$$((\exists v.(\forall u.P(u, v))) \rightarrow (\forall x.(\exists y.P(x, y))))$$
by renaming the $x$ and $y$ variables on the left-hand side of the $\rightarrow$.
We want to migrate the quantifiers to the left-hand side of the formula,
so we need to choose a quantifier to start with.
We could try to migrate the $\exists v$ or the $\forall x$, for example.
Later we will say something about how to make such a choice,
but for let's just try to migrate the $\forall x$ quantification.
This produces the following formula.
$$(\forall x.((\exists v.(\forall u.(P(u, v)))) \rightarrow (\exists y.(P(x, y))))).$$
Again we have a choice of quantifications to migrate.
This time we choose $v$ and come to the following formula.
$$(\forall x.(\forall v.((\forall u.(P(u, v))) \rightarrow (\exists y.(P(x, y))))))$$
Now we can choose either $\forall u$ or $\exists y$.
As it happens, either choice will work.
Let's start with $u$.
$$(\forall x.(\forall v.(\exists u.(P(u, v) \rightarrow (\exists y.(P(x, y)))))))$$
Finally, we migrate $\exists y$.
$$(\forall x.(\forall v.(\exists u.(\exists y.(P(u, v) \rightarrow P(x, y))))))$$

Now we have completed the first two steps in the
four-step strategy for reasoning about formulas with quantifiers in them:
the renaming step and the migration step.
Next comes quantifier removal.

A universal quantification is true if
the quantified formula is true for any value
chosen from the universe of discourse for the bound variable.
Our procedure is to discard the $\forall$ quantifier,
replace its bound variable by a constant symbol, then
prove that regardless of which value from the universe of discourse
the constant symbol stands for, the formula has the value $True$.
Following this procedure, we remove the $\forall$ quantifier
at the beginning of the formula and replace the bound variable $x$
by the constant symbol $x_0$.
We do the same for the second $\forall$, replacing its bound variable
$v$ by the constant symbol $v_0$.
As we discussed earlier, it is vital that $x_0$ and $v_0$ are different
from every other symbol in the formula $(P(u, v) \rightarrow P(x, y))$
That gets us to the following formula.
$$(\exists u.(\exists y.(P(u, v_0) \rightarrow P(x_0, y))))$$

If we can prove that it is true regardless of what values
$x_0$ and $v_0$ stand for, we will have established that the
original formula has the value $True$.
By definition an existential quantification is true if
there is a value from the universe of discourse that
makes the quantified formula true when it is put in place of
the bound variable.
Therefore, if we can find such values for both existential
quantifiers, our proof will be complete.

A hypothesis of the theorem we are trying to prove
is that both indexes of the predicate have the same universe of discourse.
Therefore, we can, if we want to,
choose the value $x_0$ for the bound variable $u$
that is associated with the first $\exists$
and the value $v_0$ for the bound variable $y$
that is associated with the second $\exists$.
If we choose those values and put them in the
quantified formula, it comes to the following.
$$(P(x_0, v_0) \rightarrow P(x_0, v_0))$$

There are no variables left in the formula, just constants.
So, the formula is an ordinary proposition in Boolean algebra.
We can cite the \{self-implication\} axiom
(Figure~\ref{fig-02-boolean-axioms}, page \pageref{fig-02-boolean-axioms})
to conclude that the formula $(P(x_0, v_0) \rightarrow P(x_0, v_0))$
has the value $True$, which proves the theorem.

This example illustrates a rationale for migrating
$\forall x$, then $\exists v$, and finally $\forall u$ and $\exists y$.
We were motivated by the desire to wait as long as possible before having to make
a choice. That means that whenever we have a choice, we want to migrate a quantifier
that will become a ``for all'' before we migrate one that will become a ``there exists.''
For example, when we were migrating quantifiers on the following formula, we considered
migrating $\exists v$ and we also considered migrating $\forall x$.
$$((\exists v.(\forall u.P(u, v))) \rightarrow (\forall x.(\exists y.P(x, y))))$$

Migrating the variable $\forall x$ (citing \{$\rightarrow\forall$\})
or $\exists v$ (citing \{$\exists\rightarrow$\}).
Both lead to a $\forall$ quantifier in the front,
so neither has an advantage.
We chose to migrate the $\forall x$, but let's try migrating
the $\exists v$ this time, and see how it goes.
$$(\forall v.((\forall u.(P(u, v))) \rightarrow (\forall x.(\exists y.(P(x, y))))))$$

Now, there is a choice of migrating the $\forall u$ (citing \{$\exists\rightarrow$\})
or $\forall x$ (citing \{$\rightarrow\forall$\}).
This time it \emph{does} matter.
If we migrate the $\forall x$ first, we get $\forall$ quantifier at the front,
but if we migrate the $\forall u$, we get $\exists$ at the front.
We prefer to have universal quantifiers at the beginning of the formula
because it delays the choice of specific values from the universe of discourse
that removing an existential quantifier requires.
\index{Skolemization}We want to leave the choice open as long as possible, to give ourselves
the best chance of making a choice that will help the proof.
Therefore, we're better off migrating the $\forall x$ quantifier first.
$$(\forall v.((\forall x.((\forall u.P(u, v)) \rightarrow (\exists y.P(x, y))))))$$

It is essential to delay the choice of a universally quantified variable
as long as possible.
For example, take the following statement, which is $True$
when the domain of discourse is the integers.
$$(\forall x.((\exists y.(x < y))))$$
To prove this theorem, we would first remove the universal quantifier ($\forall$),
leaving the formula $(\exists y.(x_0 < y))$.
Now it is easy to find a suitable value of $y$, namely $x_0+1$, ending up with
$x_0 < x_0 + 1$.

On the other hand, suppose we were trying to prove the following statement, which
is \emph{actually false}:
$(\exists y.((\forall x.(x < y))))$.
We are forced to remove the quantifier for the variable $y$, but that means we have
to choose the right value of $y$, and we cannot possibly know what value that would be
until we know the value of $x$.
Now, you may think that we can replace $y$ with the expression $x+1$, but this would
not be allowed. The reason is that $x+1$ is not a constant, and we can
only replace a variable with a constant. And in case you think this is an arbitrary
rule, remember that the statement $(\exists y.((\forall x.(x < y))))$ is \emph{not}
$True$. It is not true that there exists a \emph{single} value of $y$ that is larger
than all possible values of $x$.

So in general, the order in which quantifiers are migrated to the front \emph{is}
important. And that's why we always migrate the quantifiers so that, as far as
possible, ``for all'' quantifiers appear before ``there exists'' quantifiers.

The four-step strategy is only one of many ways to prove theorems about
formulas with quantifiers. It is related to the way
the mechanized logic of ACL2 can be used to reason about quantified formulas.
Natural deduction provides another approach, but additional rules of inference
are needed.
The equations of Figure~\ref{fig-02-quantifiers} (page \pageref{fig-02-quantifiers})
form the basis of yet another method.
Generally, the methods we will employ involve the use of equations
like those of Figure~\ref{fig-02-quantifiers}, as in the examples
of this section.

\begin{ExerciseList}
\Exercise Prove that $(\forall x.P(x)) \rightarrow (\exists x.P(x))$.
\Exercise What goes wrong when you attempt to prove that $(\exists x.(P(x))) \rightarrow (\forall x.(P(x)))$?
Explain why this is different than the previous exercise.
\Exercise Prove that $((\forall x.(P(x) \rightarrow Q(x))) \wedge (\forall x.(Q(x) \rightarrow R(x)))) \rightarrow (\forall x.(P(x) \rightarrow R(x)))$.
\Exercise Derive the four quantifier-implication equations (Figure~\ref{fig-02-quantifiers})
from other axioms and theorems.
\Exercise Supply the details of the proof of the \{$\neg\exists$\} equation sketched in this section
(page \pageref{why-neg-forall}).
\Exercise Derive the \{$\neg\exists$\} equation from the \{$\neg\forall$\} equation
(Figure~\ref{fig-02-quantifiers}) and
other previously proven axioms and theorems.

\end{ExerciseList}


\section{Boolean Models}
\label{sec:boolean-models}

A Boolean \index{variable}\index{variable!Boolean}\index{Boolean!variable}variable $x$ 
stands for a proposition, such as ``Socrates is a man.''
Within the domain of logic, this represents a true/false value,
and Boolean formulas and equations provide a way to carry out
a consistent analysis of relationships between propositions.
However, stating the proposition in the form ``Socrates is a man''
suggests that expect proposition to have a meaning in a real-world domain.
If the variable $x$ stands for the statement ``Socrates is a man,''
we expect $x$ to be $True$ if the statement is consistent with a fact
in the real world, $False$ if it is inconsistent with the facts.
Even if we don't know the facts, we expect $x$ to be either $True$ or $False$,
not both and not something else,
according to the actual state of underlying conditions unknown to us.

In other words we intend the proposition $x$ 
to mean something the \index{logic!real world}real world,
and we use logic to analyze relationships between this proposition and other
assertions about the real world stated as true/false propositions.
In logic mode, we apply the mathematical axioms and rules of inference,
and in the end we interpret our conclusions, which are statements in logic,
as statements about the real world.
This makes sense only so far as the propositions we started with
accurately model the real-world domain we want them to represent.
In the domains of software and digital circuits,
the correspondence is extremely reliable.
It is rare for a digital circuit to go haywire or an interpreter of
a programming language to go awry.

Accurate \index{model}modeling of other domains by propositions in logic can be problematic,
but we want to expand the horizon a bit with a discussion
of the game of \index{Nim}\emph{Nim}.
There are many variants of this game, and we will consider a simple one.
The game starts with a pile of ten stones. Two players (Alice and Bob in this discussion)
take turns removing one, two, or three stones from the pile.
The player who picks up the last stone loses.
The chart in
Figure~\ref{fig:example-nim-game} (page \pageref{fig:example-nim-game})
summarizes a game that Alice won.

\begin{figure}
\begin{center}
%\begin{flushleft}
\begin{tabular}{l|l|l|l}
Move & Alice     & Bob      & Stones \\
\hline
0    &           &          & 10     \\
1    & Remove 2  &          & 8      \\
2    &           & Remove 3 & 5      \\
3    & Remove 1  &          & 4      \\
4    &           & Remove 2 & 2      \\
5    & Remove 1  &          & 1      \\
6    &           & Remove 1 & 0      \\
\end{tabular}
%\end{flushleft}
\end{center}
\caption{A Game of Nim}
\label{fig:example-nim-game}
\end{figure}

We will try simulate the play of the game of Nim using propositional logic.
We will use Boolean variables to represent the pile of stones.
For example, we could use the variable $x$ to mean ``there are 10 stones in the pile''
and $y$ to mean ``there are 9 stones in the pile.''
If we continue with this scheme, we will have a lot of names with
no easily-recalled connection to their meanings.

Another approach is to let $x10$ mean ``there are 10 stone in the pile,''
$x9$ that ``there are 9 stones in the pile,'' and so on
down to $x0$ for an empty board.
The collection of these 11 Boolean variables can describe any pile,
but they could just as well describe an impossible situation.
For example, both if $x1$ and $x5$ were $True$,
the pile would consist of one stone and also consist of five stones,
and this cannot be correct.
To make our model in logic correspond to a real game of Nim,
we need constraints on the relationships between the variables.

The game restricts of the number
of stones in a pile to between zero and ten.
We can account for this restriction by requiring
the following formula to have the value $True$.\footnote{To
save space, part of the formula has
been elided, but we think you can fill in the missing parts.
Many of the formulas in our model of Nim will be abbreviated in this way.}
$$x0 \vee x1 \vee x2 \vee \cdots \vee x10$$

This rule would avoid some impossible situations in a real game of Nim.
Another restriction is that there cannot be both zero stones in the pile
and one stone in the pile, nor both zero stones and two stones, and so on.
We can account for this restriction by asserting that the following formula
has the value $True$.
$$(\neg(x0 \wedge x1)) \wedge (\neg(x0 \wedge x2)) \wedge \cdots \wedge (\neg(x0 \wedge x10))$$

Of course,
we also need to eliminate the possibility of having
both one stone and two, one stone and three, and so on.
$$(\neg(x1 \wedge x2)) \wedge (\neg(x1 \wedge x3)) \wedge \cdots \wedge (\neg(x1 \wedge x10))$$
This new rule could have also included the $(\neg(x0 \wedge x1))$ formula,
but we are going to require all our rules to hold, so we don't need to
repeat a restriction already made by the first rule.

We could carry on in this vein,
but to capture the play of an entire game of Nim,
we would need to be able to deal with changes in the pile of stones
as the game progresses.
Our considerations so far have been limited to an unchanging pile of stones.
We need to add a time component to the model.
To do that, we will need to have many more variables,
and it will help if we name them in a way that helps
us remember what they mean in the game.

%%% superscript = move
%%% subscript = stones

Our new scheme will use the variable $x_{10}^{3}$ to mean
``there are 10 stones in the pile after 3 moves.''
The variable $x_{5}^{2}$ would have the value $True$
for the game summarized in
Figure~\ref{fig:example-nim-game} (page \pageref{fig:example-nim-game})
because there are five stones remaining after Bob makes the
second move of the game.
It is important to recognize that a Boolean variable like $x_{10}^{3}$
is no different, except in name, from Boolean variables such as $y$ or $z$.
Both the subscript and the superscript are just part of the name.
It is tempting to believe that since we have a variable called $x_{10}^{3}$,
we have variables called $x_{12}^{7}$ and $x_{3}^{26}$.
However, there are no such variables in our model because there cannot be twelve stones
in the pile, nor can there be a move number twenty-six.

The superscript part of the name stands for the number of stones remaining,
so it must be between zero and ten, and the subscript stands for the
move number, so it also must be between zero and ten because,
since each move removes at least one stone, no game can have more than ten moves.
The numbered portions of the name tell us at
a glance how many stones are in the pile
and how many moves have been made.
There are a lot of things to keep straight.
We need 121 variables in all: 11 pile sizes (zero stones through 10 stones)
times 11 moves numbers (move 0 through move 10,
but no move 11 because at least one stone is removed in each move).
Our naming scheme makes the model easier to comprehend.

Initially, there are ten stones in the pile,
so the variable  $x_{10}^{0}$ has the value $True$
and the variables $x_{0}^{0}$, $x_{1}^{0}$, $x_{2}^{0}$, \dots $x_{9}^{0}$
all have the value $False$.
This is the ``initial condition'' for the game of Nim,
expressed in terms of the Boolean variables we are using
in our model.

Another constraint is that after move number six,
the number of stones remaining will still be between zero and ten.
That is, the following formula has the value $True$.\footnote{Actually,
the formula could be more restrictive because
after move six there cannot be more than four stones remaining.
We will account for this constraint later, and in a more general way.}
$$x_{0}^{6} \vee x_{1}^{6} \vee x_{2}^{6} \vee \cdots \vee x_{10}^{6}.$$

Our model has ten formulas like this,
When we combine all of them with AND,
we get a formula that constrains the number of stones
in the pile at each stage in the game.
The formula will have the value $True$ for any properly played game of Nim.

Another kind of constraint in a properly played game is one
we discussed before we added variables to the model to account for the move number.
At every stage, there is only one number of stones remaining in the pile.
After move 3, for example, there cannot be both three stones remaining
and five stones remaining.
So we need some rules like the following after six moves.
$$(\neg(x_{0}^{6}) \wedge (x_{1}^{6})) \wedge (\neg(x_{0}^{6} \wedge x_{2}^{6})) \wedge \cdots \wedge (\neg(x_{0}^{6} \wedge x_{10}^{6}))$$
This formula disallows piles having both zero and five stones or zero and seven stones,
but as before we need nine additional
formulas to disallow piles with both one and two stones, one and three stones, and so on.
$$(\neg(x_{1}^{6} \wedge x_{2}^{6})) \wedge (\neg(x_{1}^{6} \wedge x_{3}^{6})) \wedge \cdots \wedge (\neg(x_{1}^{6} \wedge x_{10}^{6}))$$
That is a total of ten formulas that must be combined using AND
to rule out impossible combinations after move six.
And, that's just move six.
We need a group of rules like this to describe the pile after zero moves,
one move, two moves, and so on, up to ten moves.
These 11 groups of rules should also be combined using AND,
making 11 times 10, or 110, separate rules combined with AND.

What about the rules for removing stones from a pile?
For example, if the pile has five stones after move three,
then it must have four, three, or two stones after four,
since the player removes either one, two, or three stones in step four.
This can
be captured with the following rule:
$$x_{5}^{3} \rightarrow (x_{4}^{4} \vee x_{3}^{4} \vee x_{2}^{4}).$$
We need only be careful when we get down to piles with fewer than three stones. For example, for the case when there are only
two stones left in the pile, we need a rule like the following:
$$x_{2}^{3} \rightarrow (x_{1}^{4} \vee x_{0}^{4}).$$
And what do we do when we run out out of stones?
One way to proceed is to continue the pattern
and just ensure that there are no stones at the next turn:
$$x_{0}^{3} \rightarrow x_{0}^{4}.$$
Of course, many such rules will be needed,
one rule for each possible combination of stones left and number of moves made.

Now consider a single formula combining all the constraints.
\begin{quote}
\begin{center}
\emph{Nim-constraints (a formula that is $True$ for all Nim games)}
\end{center}
\begin{enumerate}
\item the initial pile containing ten stones, AND
\item the possible legal descriptions of piles at all times, AND
\item the legal ways in which a pile transform from one move to the next, AND
\end{enumerate}
\end{quote}

The Nim-constraints formula has the value $True$ for all properly played games of Nim.
Every Nim game corresponds to a particular combination of values of
the Boolean variables in the model.
The combination must ensure that the Nim-constraints formula is $True$, and
the Nim game corresponding to that combination can be reconstructed
from an inspection of the values of the Boolean variables.
One combination will correspond to the game in which the Alice removes two stones,
then Bob removes three, then Alice one more, and so on.
If the value of the Alice-wins formula it $True$
for that combination values of the variables,
then Alice won the game. If it is $False$, Bob won.

But, how do we know who wins?
Since Alice moves first, the move number for each of her moves is a odd number (1, 3, 5, \dots),
and Bob's move numbers are even (2, 4, 6, \dots).
According to the rules, the person who picks up the last stone loses.
So, we can characterize a win by one player or the other by
the following formulas.
\begin{center}
\label{alice-wins-formula}
\begin{tabular} {ll}
\emph{Alice-wins}: & $x_{0}^{2} \vee x_{0}^{4} \vee x_{0}^{6} \vee x_{0}^{8} \vee x_{0}^{10}$ \\
\emph{Bob-wins}:   & $x_{0}^{1} \vee x_{0}^{3} \vee x_{0}^{5} \vee x_{0}^{7} \vee x_{0}^{9}$  \\
\end{tabular}
\end{center}

If we were to AND the Nim-constraints formula with the Alice-wins formula
and find it to have the value $True$, then we could conclude that Alice always wins the game.
If it were $False$, we could conclude that Alice never wins.
But, there is a third possibility.
It may be that for some values of the Boolean variables,
the Alice wins formula is $True$
and for other values it is $False$.
Each possible combination of the Boolean variables
corresponds to a single game of Nim.
Furthermore, for any combination of value of the variables that makes the
Nim-constraints formula true, the values of the individual Boolean variables
show how to reconstruct the game.
One combination will correspond to the game in which the Alice removes two stones,
then Bob removes three, then Alice one more, and so on.
If the value of the ``Alice wins'' formula is $True$ for that
combination values of the variables, then Alice won the game.
If it is $False$, Bob won.
So, this collection of Boolean formulas provides a model of the game of Nim
that can be used to analyze the play and figure out which player won.

Now here is something that may surprise you.
It is one of the central themes of computer science
that models of computer programs can take a form
similar to the \index{model!Boolean}model we discussed for the game of Nim,
but only if we have an \emph{upper bound on the number of
steps in the computation the program represents}.
To do this on the scale of a computer program,
a formula is required that combines
\begin{quote}
\begin{enumerate}
\item the initial configuration of the computer, AND
\item the possible legal configurations of the computer at all times, AND
\item the legal transitions of the computer from one step to the next, AND
\item the formula that ``the program is finished.''
\end{enumerate}
\end{quote}

Since digital computers store everything as a sequence of ones and zeros,
the initial configuration is simply the initial values of those bits.
The legal configurations rule out the possibility that a given bit is both a
one and a zero at the same time.
The legal transitions correspond to the actual program and how it manipulates information
over time. And, a traditional way to specify that the program is finished
is to choose a specific bit in the model, to include in the initial conditions
that the chosen bit is zero, and to insist that
the bit remains as a zero until, as its last act,
program sets the bit to the value one.

So there you have it.
If you know that a given program will execute in, say, 10 million or fewer steps,
then (in principle) you can
write down a Boolean formula that completely captures the computation
that the program represents.
In this sense, Boolean formulas are sufficient to
represent any computer program,
as long as you can state ahead of time how long it will run.
Generally speaking, this kind of analysis isn't feasible
because the formulas have way too many variables.
However, for small components,
specifications of this kind are feasible, and they can be combined
to analyze larger systems. The key is modularity: keeping the
components small and manageable and combining them in
ways that limit a sudden explosion of complexity.

\begin{ExerciseList}
\Exercise
Did you notice the mistake in the way we described the game of Nim?
Suppose that Alice wins in step 5, so that $x_{0}^{6}$ is true.
According to our rules, that means that $x_{0}^{7}$ must also be true,
but then from the description of ``Bob wins,''
you would conclude that both Alice and Bob won.
That is not at all what we meant! Modify the formula that says ``Alice wins''
to take care of this complication.

\Exercise
There are many variants of the game of Nim.
In another variant, there are three piles of stones, and each player can remove
one or more stones from any single pile. T
he player who removes the last stone loses the game.
Describe this game using Boolean variables and formulas.

\end{ExerciseList}

\section{More General Models with Predicates and Quantifiers}
\label{sec:predicates}

You now know that Boolean formulas and equations can be used
to describe and analyze complicated, real world artifacts.
The Boolean domain has more scope than is apparent at first glance,
but using it can be cumbersome to the point of \index{infeasibility}infeasibility.
Hundreds, thousands, or millions of Boolean variables are needed,
and they are difficult to organize in an understandable fashion.

The Boolean \index{model!Boolean}\index{Boolean!model}model of the game of Nim in Section~\ref{sec:boolean-models}
defined 121 variables to deal with various aspects of the game.
The variable $x_s^t$
was $True$ if after move $t$ there were $s$ stones left in the pile.
Let's see how this model would work out if we used a predicate X
instead of 121 individual variables.
The predicate will have two indexes: (1)~an integer $s$ between 0 and 10
representing the number of stones in the pile
and (2)~an integer $t$ between 0 and 10 indicating the move number.
The universe of discourse for the first index is the same as that
for the second index, namely the set of integers between 0 and 10.

The proposition $X(s,t)$ in predicate X has the same meaning as the variable
$x_s^t$ in the propositional model.
Since the variables are organized in a predicate,
we can use quantifiers to make assertions with compact and understandable formulas.
The formula  $(\exists t.X(0,t))$
is $True$ because a game of Nim always ends with no
stones in the pile.
The formula means that the game of Nim always ends in ten or fewer moves.
The Alice-wins formula
from the Nim model (page \pageref{alice-wins-formula})
would be $\exists t.(Even(t) \wedge X(0,t))$,
where
$Even(t)$ is the predicate that detects even numbers
(page \pageref{even-number-predicate-Even}).
The formula $\forall s.((s < 10) \rightarrow (\neg X(s,0)))$
is $True$ because there are 10 stones in the pile at move 0.

In the propositional \index{model!propositional}model we specified that the pile after six moves
cannot have both no stones and one stone, nor zero stones and two, etc.
$$(\neg(x_{0}^{6} \wedge x_{1}^{6})) \wedge (\neg(x_{0}^{6} \wedge x_{2}^{6})) \wedge \cdots \wedge (\neg(x_{0}^{6} \wedge x_{10}^{6}))$$
Using quantifiers, we can write this more succinctly.
$$(\forall s.((s \neq 0) \rightarrow (\neg(X(0, 6) \wedge X(s, 6))))$$

Using propositions, we needed to consider ten
different cases, one for each possible number of stones other than zero. With the
universal quantifier, we need only one formula to describe all of those
possibilities. In fact, we can cover more ground.
The propositional model also described the fact
that no pile can have both one and two stones at the same time, or one and three
stones, etc.  All of those expressions had to be combined using AND.
Using universal quantification ($\forall$),
we can cover all possible combinations
for move number 6 with a single formula.
$$(\forall s_1.(\forall s_2.((s_1 \ne s_2 ) \rightarrow ((\neg(X(s_1, 6) \wedge X(s_2, 6)))))))$$

To specify this constraint for the entire game, not just move number 6,
we need ten more similar formulas combined with AND.
This can be expressed with a universal quantification spanning the move numbers ($\forall t \dots$).
$$(\forall s_1.(\forall s_2.(\forall t.((s_1 \ne s_2) \rightarrow (\neg(X(s_1, t) \wedge X(s_2, t)))))))$$
This single formula is equivalent to over 500 formulas that were
necessary we were building the model without using predicates and quantifiers.

In the game of Nim, the propositional formula specifying that the pile must contain between zero and
ten stones after six moves was written as follows.
$$(x_{0}^{6} \vee x_{1}^{6} \vee x_{2}^{6} \vee \cdots \vee x_{10}^{6}).$$
An existential quantification makes it more succinct: $(\exists s.X(s, 6))$.
As before, we can use universal quantification to extend this requirement
across all the moves:
$(\forall t.(\exists s.(X(s, t))))$.
The order of the quantifiers matters. This expression says that at any given
time, there is a specific number of stones in the pile. If the quantifiers were reversed,
the statement would indicate that the pile has some fixed number of stones
at all possible points in time, which is false because the size of the pile
changes with every move.

\begin{aside}
``For all'' and ``there exists'' are not the only possible logical quantifiers.
For example, you may imagine a context
in which ``for most'' is a perfectly sensible quantifier.
In some branches of mathematics, it is common to use the
quantifiers ``almost everywhere'' and ``almost nowhere''
which have precise mathematical definitions even though
sound fuzzy in an informal description.
\end{aside}

Quantifiers are the device that makes formulas using predicates more compact than
formulas that stay in the domain of propositions.
We saw in the previous section that it
is possible to characterize the game of Nim using just Boolean variables, with a formula that looks like this:
\begin{quote}
\begin{enumerate}
\item the initial pile containing ten stones, AND
\item the possible legal descriptions of piles at all times, AND
\item the legal ways in which a pile transform from one step to the next, AND
\item the formula that ``Alice wins.''
\end{enumerate}
\end{quote}

The formulas in this section specify the same model, but in a more understandable
way and in much less space.
Predicate logic can do more than simplify the formulas.
It can express bigger ideas.
Consider the formula with meaning ``Alice wins.''
In the propositional model this was built by taking together the more specialized formulas
``Alice wins at time 2,'' ``Alice wins at time 4,'' \dots, ``Alice wins at time 10''
and joining them all with OR.
Using \index{model!predicate}predicates and quantifiers, the formula $(\exists t.(AliceWinsAtTime(t)))$ expresses
the same idea.

This is not just a simple syntactic change.
We have gained much more than the ability to
collect all possible ``Alice wins at time \dots'' phrases into a single statement.
The variable $t$ can potentially stand not just for the numbers zero through ten,
but for any possible number of moves, so
this same approach applies to open-ended games like chess.
Using propositions, we could (in principle)
completely describe the game of chess, but only if we limit chess games to, say, 200 moves.
With predicates, there is no such limitation.
We can refer to an arbitrary time at which black wins because the domain of discourse
can be infinite.

The same is true for models of computer programs.
Before, to build a model we had to limit the number of computational steps to a fixed upper bound,
such as a million steps.
Then (in principle)
a Boolean formula could be constructed that was $True$
if and only if the program produced a given answer.
With predicates, we can do away with the upper bound on computational steps.
The computation can be open-ended because the domain of discourse for computational steps
can have an infinite number of elements. It could be the set of natural numbers, for example.
It is possible, in principle, to describe \emph{all} possible computer programs
using formulas in predicate logic.

\todo{DONE Sep2017 Not sure whether we need a section on one-directional reasoning or not ...
seems like we do, but a full-fledged Gentzen-style treatment gets tedious ...
how do we keep it lively, but still provide the necessary apparatus? ...
Maybe better to introduce inference rules when we introduce induction? ...
how many rules do we need? Would modus ponens and or-elim (plus induction) be enough? How about reductio-ad-absurdum?
law of excluded middle?
Just the rules we will be using in doing inductive proofs about software and circuits}

\todo{DONE Sep2017
after writing this, I'm not sure it does any good.
I'm especially not sure the proof notation I've used is clearly explained.
I went through all the lectures, homeworks, and exams in the existing applied logic course, and did not find any theorems proved by deductive reasoning that were not more easily handled by stating them as implications and proving them as equations of the form $(a \rightarrow b) = True$.
I guess we could leave this stuff in, but give it short shrift, and refer back to it if necessary.
We will use deduction when we come to induction, which is a deductive inference rule, but
I'm not sure we need to make a big deal out of it
 IN THE END, ALL INFERENCE RULES WERE COVERED
 NAT DED FORMAT USED IS COMPACT, BUT SORT OF READABLE.
 INTRODUCED NEGATION-INTRO and NEGATION-ELIM TO AVOID CONFUSION ABOUT A -> FALSE,
 AND THIS TURNED OUT TO HAVE THE BENEFIT OF LIMITING DISCHARGES TO IMPLICATION-INTRO RULE
 SO, NATURAL DEDUCTION IS WELL COVERED,
 BUT IN THE CHART SHOWING PATHS THROUGH THE BOOK, WE MIGHT BE ABLE
 TO SUGGEST THAT THIS SECTION ON NATURAL DEDUCTION COULD BE SKIPPED
 BECAUSE WE DON'T MAKE MUCH USE OF DEDUCTION EXCEPT IN KIND OF A SUPERFICIAL WAY
 IN THE EXPLANATION OF INDUCTION AS AN INFERENCE RULE}

\todo{
Maybe change \theorem definition to remove theorem numbers and parens around theorem names.
Could not use the \theorem command with natural deduction because
I could not get it to work with the tabular format I needed to use in those proofs.
Also, I used theorem names in all the references in Ch 2 anyway, instead of theorem numbers.
This would change the look of theorems:
   Theorem 4 ({--> truth table}). blah blah...    OLD FORMAT
   Theorem {--> truth table}: blah blah...        NEW FORMAT, if we make the change proposed here
}

\todo{DONE Sep2017
Check to make sure predicates and quantifiers are covered somewhere.
Show how to convert between forall and exists.
put halting problem where forall is introduced;
   cite (x -> not x) = (not x) {contradiction} \label{boolean-contradiction}
}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "book"
%%% End:
