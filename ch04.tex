\chapter{Mathematical Induction}
\label{ch:mathematical-induction}

\section{Lists as Mathematical Objects}
\label{sec:lists-as-obj}
A \index{sequence}\index{list}sequence
is an ordered list of elements.
In fact, for our purposes, the terms ``list'' and ``sequence'' are synonyms.
Many things that computers do come down to keeping track of lists,
so lists are an important class of mathematical objects.
We will need a formal notation, including an algebra of formulas,
to discuss lists with the level of mathematical precision
required in specifications of computer hardware and software.

Formally, we will write lists as sequences of their elements, separated by spaces,
with square brackets marking the beginning and end of the list.
For example, [8 3 7] denotes the list with first element 8,
second element 3, and third element 7, and
[9 8 3 7] denotes a list with the same elements,
plus an additional element 9 at the beginning.
\label{nil-def}
\index{nil}\index{empty list (nil)}
We use the symbol ``nil'' for the empty list
(that is, the list with no elements).
\label{square-brackets}
We use \index{square brackets}\index{brackets!square}\index{list!square bracket notation}square brackets
rather than round ones in formulas
specifying lists, to avoid confusion with formulas that invoke operators.
For example, [4 7 9] denotes a three-element \index{list}list,
while (+ 7 9) is a numeric formula representing the value 16.
However, ACL2 does not employ this square-bracket notation.
When it displays the list [4 7 9],
it uses \index{parentheses}\index{brackets!round}round brackets: (4 7 9).
The square-bracket notation helps avoid confusions
and keeps the written discussion compact.

\begin{aside}
Most of the time, we will use square bracket
\index{list!square bracket notation}notation for lists
to distinguish them from computational formulas.
However, ACL2 does not display lists with square brackets.
It uses round parentheses both for lists and for computational formulas.
\caption{Square Bracket Notation for Lists: Pencil-and-Paper Only}
\label{square-bracket-notation}
\end{aside}

The algebra of lists includes some basic operators.
One of them, the
\index{list!cons (\emph{see also} operator)}list construction
\index{operator, by name!cons (insert at front)}operator ``cons''
inserts a new element at the beginning of a list.
Formulas using cons, like all formulas in
the mathematical notation we have been using to discuss software concepts,
are written in prefix form.
So, the formula (cons $x$ $xs$) denotes the list
with the same elements as the list $xs$,
but with an additional element $x$ inserted at the beginning.
If $x$ stands for the number 9,
and $xs$ stands for the list [8 3 7],
then (cons $x$ $xs$) constructs the list [9 8 3 7].

\begin{figure}
\begin{center}
[$x_1$ $x_2$ \dots $x_n$] $=$
(list $x_1$ $x_2$ \dots $x_n$) $=$ (cons $x_1$ (cons $x_2$ \dots (cons $x_n$ nil) \dots))\\
\vspace{2mm}
\begin{tabular}{lclcl}
{[$1$ $2$]}             &$=$ &(list $1$ $2$)            &$=$ &(cons $1$ (cons $2$ nil))\\
{[$16$ ~$256$ ~$4096$]} &$=$ &(list $16$ ~$256$ ~$4096$)&$=$ &(cons $16$ (cons $256$ (cons $4096$ nil)))\\
{[$1$ $9$ $4$ $7$]}     &$=$ &(list $1$ $9$ $4$ $7$)    &$=$ &(cons $1$ (cons $9$ (cons $4$ (cons $7$ nil))))
\end{tabular}
\end{center}
\caption{Shorthand for Nested Cons: list}
\label{fig:list-nested-cons}
\end{figure}

Any list can be constructed by starting from the \index{empty list (nil)}empty list
and using the construction operator to insert the elements of the list, one by one.
The empty list, \index{nil}nil, which is intrinsic in ACL2, needs no construction.
Non-empty \index{list!non-empty}lists are constructed using the cons operator.
The formula [8 3 7] is our shorthand for (cons 8 (cons 3 (cons 7 nil))).
ACL2 also has a shorthand, briefly introduced earlier
(Chapter~\ref{ch:software-testing-prefix-notation}, page \pageref{list-op-informal}),
for nested cons operations: (list 8 3 7) is another way to write the formula
(cons 8 (cons 3 (cons 7 nil))).

\begin{aside}
The
\index{equation!defining ($\equiv$)}\index{definition!equation ($\equiv$)}\index{equivalence!by definition ($\equiv$)}\index{three-line equal ($\equiv$)}\index{equal, three-line ($\equiv$)}three-line
variation of the equals sign
indicates that the term on the left stands
for the formula on the right, \emph{by definition}.
\begin{center}
\begin{tabular}{ll}
$term \equiv \dots \emph{some formula} \dots$    &\emph{definition of term} \\
$P(xs, y, ys) \equiv (xs$ $=$ (cons $y$ $ys$)$)$ &$P(xs, y, ys)$ \emph{means} $($xs $=$ (cons $y$ $ys$)$)$  \\
\end{tabular}
\end{center}
\caption{Equal by Definition: $\equiv$}
\label{three-line-equal}
%%note: this aside mostly repeats an aside in ch02 predicates section, on purpose in case they skip that section
\end{aside}

Suppose we take $P(xs, y, ys)$ as shorthand
for the equation $xs$ $=$ (cons $y$ $ys$).
\begin{center}
$P(xs, y, ys) \equiv (xs$ $=$ (cons $y$ $ys$)$)$
\end{center}

Given a particular list $xs$ together with a value $y$,
we can view the equation $P(xs, y, ys)$ as a set of propositions
indexed by the variable $ys$, whose universe of discourse is the set of
lists that can be constructed by ACL2.
In this set of propositions, the one corresponding to
the list $ys$ is the equation that $P(xs, y, ys)$ stands for:
$($xs $=$ (cons $y$ $ys$)$)$
If that equation holds, the value of the proposition $P(xs, y, ys)$ is true.
Otherwise, it's false.
For example, if $xs$ denotes the list [1 2 3]
and $y$ denotes the natural number 1,
then $P(xs, y, ys)$ is $P($[1 2 3], 1, $ys)$
which stands for an equation involving the variable $ys$.
There is one such equation for each different list $ys$.
Taken all together those equations comprise a predicate
whose universe of discourse is ACL2 lists.

The operator \index{operator, by name!consp (predicate)}\seeonlyindex{consp}{predicate}
\index{predicate, by name!consp (non-empty list)}``consp''
checks for non-empty lists.
That is, the formula (consp $xs$) delivers true
if $xs$ is a non-empty list and false otherwise.
The \{\emph{consp}\} axiom
(Figure~\ref{consp-axiom}, page \pageref{consp-axiom})
is formally asserts that all non-empty lists
are constructed with the cons operator.

The formula
$(\exists ys.P($[1 2 3], 1, $ys))$ is true
because [1 2 3] = (cons 1 [2 3]), so there is a value
of $ys$, namely $ys =$ [2 3] for which $P($[1 2 3], 1, $ys)$ is true.
If there were no list that made the equation valid,
the formula $(\exists ys.P($[1 2 3], 1, $ys))$
would be false.

If, on the other hand, $xs$ were the list [1 2 3]
and $y$ were the number 2, there would be no list
$ys$ that would make the equation [1 2 3] $=$ (cons $2$ $ys$) valid
because the list on the left-hand side of the equation
starts with 1 and the list on the right-hand side starts with 2.
So, the formula $(\exists ys.P($[1 2 3], 2, $ys))$
is false.

\begin{figure}
\begin{center}
Axiom \{\emph{consp}\} \\
(consp $xs$) $=$  $(\exists y.(\exists ys.(xs =$ (cons $y$ $ys$)$)))))$
\end{center}
\index{axiom, by name!\{consp\}}
\index{operator, by name!consp (\emph{see} predicate)}
\seeonlyindex{consp}{predicate}\index{predicate, by name!consp}
\caption{Non-Empty List Predicate: consp}
\label{consp-axiom}
\end{figure}

Now, let's take a step back.
We can view the formula
($\exists ys.$ ($xs$ $=$ (cons $y$ $ys$)))
as a set of propositions,
one for each object $y$ that ACL2 can represent.
The formula
$(\exists ys.P(xs, y, ys))$ is one way to represent that
set of propositions.
Since any set of propositions is a predicate,
we can view $(\exists ys.P(xs, y, ys))$ as a predicate indexed
by the set of objects $y$ representable in ACL2.

\begin{figure}
\begin{center}
Axiom \{\emph{nlst}\}

[$x_{m}$  $x_{m+1}$ \dots $x_{n}$]  \emph{denotes a list with $n - m + 1$ elements} \{\emph{nlst}\} \\
\emph{Note: Denotes nil, the empty list, if $m > n$}
\end{center}
\index{numbered list notation}\index{list!numbered}\index{list!ellipsis}
\index{axiom, by name!\{nlst\}}
\caption{Numbered List Notation}
\label{numbered-list-interpretation}
\end{figure}

We can convert the predicate $(\exists ys.P(xs, y, ys))$
into a true/false value (that is, convert it to a proposition)
by applying the $\exists$ quantifier again,
but this time with $y$ as the bound variable:
$(\exists y.(\exists ys.P(xs, y, ys)))$.
When $xs$ is a list for which this formula has the value true,
then (consp $xs$) is true.
That is, consp is the ACL2 name for the predicate $(\exists y.(\exists ys.P(xs, y, ys)))$.
The universe of discourse for the predicate consp is the set of lists that ACL2 can represent.
That specification of consp is expressed in the consp axiom
(Figure~\ref{consp-axiom}, page \pageref{consp-axiom}).
So, (consp $xs$) is a way to write the formula
$(\exists y.(\exists ys.(xs$ $=$ (cons $y$ $ys$)$)))$ in ACL2.

When we know that a list $ys$ is non-empty,
we can cite the \{\emph{consp}\} axiom
to rewrite $ys$ in the form (cons $x$ $xs$)
When we do this, we choose the symbols $x$ and $xs$ carefully
to avoid conflicts with other symbols that appear in the context of the discussion.
The \{\emph{consp}\} axiom refers to cons, so we will need a \{\emph{cons}\} axiom.
Since cons cannot construct an empty list,
the cons axiom will specify that the list cons delivers is not empty,
using the notation [$x_1$ $x_2$ \dots $x_{n+1}$],
where $n$ stands for a natural number.
Because that list has $n+1$ elements, and $n+1$
is at least one when $n$ is a natural number,
the list cannot be empty.
Therefore, the list can be constructed by cons.

The construction operator, cons, cannot be the whole story, of course.
To compute with lists, we  need to be able to construct them,
but we also need to be able to take them apart.
There are two basic operators for taking lists apart: ``first'' and ``rest''.
We express the relationship between these operators and
the construction operator in the form of equations,
\{\emph{fst}\} and \{\emph{rst}\}, that we take as axioms
(Figure~\ref{first-rest-cons}, page \pageref{first-rest-cons}).

\begin{figure}
\begin{center}
 Axioms \{\emph{cons}\}, \{\emph{first}\}, and \{\emph{rest}\} \\
\begin{tabular}{ll}
 [$x_1$ $x_2$ \dots $x_{n+1}$] = (cons $x_1$ [$x_2$ \dots $x_{n+1}$]) & \{\emph{cons}\} \\
 (first (cons $x$ $xs$)) = $x$                                        & \{\emph{fst}\}\\
 (rest (cons $x$ $xs$))  = $xs$                                       & \{\emph{rst}\} \\
 (first nil) = nil                                                    & \{\emph{fst0}\}\\
 (rest nil) = nil                                                     & \{\emph{rst0}\}
\end{tabular}
\end{center}
\index{operator, by name!first (extract first element)}
\index{operator, by name!rest (drop first element)}
\index{operator, by name!cons (insert at front)}
\seeonlyindex{first}{operator}\seeonlyindex{rest}{operator}\seeonlyindex{cons}{operator}
\index{list!cons (\emph{see also} operator)}
\index{list!first (\emph{see also} operator)}\index{list!rest (\emph{see also} operator)}
\index{axiom!axiom, by name\{fst0\}, \{fst\}}
\index{axiom, by name!\{rst0\}, \{rst\}}\index{axiom, by name!\{cons\}}
\index{equation, by name!\{fst0\}, \{fst\}}\index{equation, by name!\{rst0\}, \{rst\}}\index{equation, by name!\{cons\}}
\caption{List Constructor and Deconstructors: cons, first, rest}
\label{first-rest-cons}
\end{figure}

The \{\emph{fst}\} axiom is a formal statement of the fact that
the operator ``first'' delivers the first element from non-empty list.
The \{\emph{rst}\} axiom states that the operator ``rest'' delivers
a list like its operand, but without the first element.
Note that the lists to which the operators first and rest
are applied in the axioms have at least one element
because those lists are constructed by the cons operator.
The axioms
\{\emph{fst0}\} and \{\emph{rst0}\}
provide an interpretation of the formulas (first nil) and (rest nil),
when the operand is a list with no elements.

We will use equations like the ones in these axioms in the
same way we used the logic equations in Figure~\ref{fig-02-02}
(page \pageref{fig-02-02}) and the arithmetic equations of
Figure~\ref{fig-02-01} (page \pageref{fig-02-01}).
That is, whenever we see a formula like (first (cons $x$ $xs$)),
no matter what formulas $x$ and $xs$ stand for,
we will be able to cite equation \{\emph{fst}\} to replace
(first (cons $x$ $xs$)) by the simpler formula $x$.
Equations go both ways, so we can also cite equation \{\emph{fst}\}
to replace any formula $x$ by the more complicated formula
(first (cons $x$ $xs$)), where $xs$ stands for any formula
we care to make up, as long as it is grammatically correct.

Similarly, we can cite the equation \{\emph{rst}\} to justify
replacing the formula (rest (cons $x$ $xs$)) by $xs$
and vice versa, regardless of what formulas the symbols $x$ and $xs$ stand for.
In other words, these are ordinary algebraic equations.
The only new factors are
(1)~the kind of mathematical object they denote, and
(2)~the syntactic quirk of prefix notation, instead of the more familiar infix notation.

All \index{property!of lists}\index{list!properties}properties of lists,
as mathematical objects,
derive from the \{cons\}, \{fst\}, and \{rst\} axioms.
For example, there is an operator called ``len''
that delivers the number of elements in a list.\footnote{The
len operator was discussed informally in Chapter~\ref{ch:software-testing-prefix-notation}
(page \pageref{len-op-informal}).}
We can use check-expect to test len in some specific cases.

\begin{Verbatim}
(check-expect (len (cons 8 (cons 3 (cons 7 nil)))) 3)
(check-expect (len nil) 0)
\end{Verbatim}

We can use the doublecheck facility for more general tests.
For example, we would expect that the number of elements
in a list constructed by the cons operation to be
one more than the number of elements in its second operand.
The following property tests this expectation.

\begin{Verbatim}
(defproperty len-cons-test
  (x  :value (random-natural)
   xs :value (random-list-of (random-natural)))
  (= (len (cons x xs))
     (+ 1 (len xs))))
\end{Verbatim}

By the same token, we expect that a list would
have one more element than it would with
its first element removed: (len $xs$) $=$ $1 +$ (len (rest $xs$)).
However, that is true only if the list $xs$
has some elements. It would not be true if $xs$ were nil.
What we want to test is an implication:
(consp $xs$) $\rightarrow$ ((len $xs$) $=$ $1 +$ (len (rest $xs$))).
The ACL2 name for the implication operator is ``implies'',
and we can use that operator to specify a test that
will check the length of (rest $xs$).

\begin{Verbatim}
(defproperty len-rest-test
  (xs :value (random-list-of (random-natural)))
  (implies (consp xs)
           (= (len xs)
              (+ 1 (len (rest xs))))))
\end{Verbatim}

The equation in the len-rest-test can serve
as an axiom for the len operator in the case
when its operand is a non-empty list.
The axiom for the empty case is simpler.
Figure~\ref{fig:len-axioms} states these two axioms for
the len operator. Axiom \{\emph{len1}\} applies when
the operand is non-empty, and the other axiom
applies in all other circumstances.\footnote{Normally
the operand of len will be either a non-empty list or nil, the empty list.
That is a good way to think of it for now,
but the operand may not be a list at all,
and according to axiom \{\emph{len0}\} its value is zero in that case.
So, (len nil) $= 0$, but (len $3$) $= 0$, too, since
$3$ is not a list. Later, we will say more about this kind of axiom.}

\begin{figure}
\begin{center}
Axioms \{\emph{len}\} \\
\begin{tabular}{ll}
(len (cons $x$ $xs$)) = (+ 1 (len $xs$)) & \{\emph{len1}\} \\
(len $e$) = 0                            & \{\emph{len0}\} \\
~~~~\emph{Note: Cite \{\emph{len0}\} only if \{\emph{len1}\} doesn't match.}&\\
\end{tabular}
\end{center}
\caption{Length of List: len}
\label{len-equations}
\label{fig:len-axioms}
\end{figure}

We expect the len operator to deliver a natural number,
regardless of the value of its operand.
For the record, we state this property as a theorem.
Later, you will have an opportunity to derive
this theorem from the \{\emph{len}\} axioms.
The theorem refers to the natp operator,
which you have seen before (page \pageref{natp-op}).
It delivers true if its operand is a natural number and false otherwise.
\begin{samepage}
\label{len-nat-thm}
\begin{center}
Theorem \{\emph{len-nat}\} $\forall xs.$(natp (len $xs$))
\end{center}
\end{samepage}

A related fact is that the length of a non-empty list is strictly positive.
One way to state that fact is to observe that the formula (consp $xs$) is true
if ($>$ (len $xs$) 0) and vice-versa. %(\verb+>+ (len $xs$) 0). %\textit{using math mode instead of \verb}
%In the notation from Chapter~\ref{ch:Boolean-Formulas}:  %\textit{never covered the equiv op}
%(consp $xs$)$\leftrightarrow$(\verb+>+ (len $xs$) 0).
This theorem, too, can be derived from the axioms for
len, consp, and cons. For the moment,
we state the theorem without proof.
\begin{samepage}
\label{consp-len-thm}
\index{theorem, by name!\{consp $= (len > 0)$\}}
\begin{center}
Theorem \{\emph{consp} $= (len > 0)$\} $\forall xs.($(consp $xs$) $=$ ($>$ (len $xs$) 0)$)$
\end{center}
\end{samepage}

\begin{aside}
If we want to specify the list [1 2 3 4] in an ACL2 formula,
rather than in a paper-and-pencil formula,
we can, of course, use the cons operator to construct it,
(cons 1 (cons 2 (cons 3 (cons 4 nil)))),
or we can use the list operator (page \pageref{list-op-informal}) to write it more compactly,
(list 1 2 3 4).
However, the single-quote trick provides a less bulky ACL2 formula for lists
whose elements are numbers (or literals denoting other ACL2 constants).
The formula
'(1 2 3 4) has the same meaning as (list 1 2 3 4).
Normally, ACL2 interprets the first symbol after a left-parenthesis
as the name of an operator.
However, the single-quote mark suppresses that interpretation and
delivers a list made up of the elements in the parentheses.
Without the single-quote mark,
the formula would make no sense because 1 is not the name of an operator.
\index{single-quote mark}\index{quote mark, single}
\index{square brackets}\index{brackets!square}\index{list!square bracket notation}
\caption{Single-quote Shorthand for Lists}
\label{acl2-single-quote}
\end{aside}

\begin{ExerciseList}
\Exercise \label{rst1}
Prove \{\emph{rst1}\}: (rest [\emph{x}]) = nil.\\
Hint: Cite some equations from Figure~\ref{first-rest-cons} (page \pageref{first-rest-cons}).
\end{ExerciseList}

\section{Mathematical Induction}
\label{sec:induction}
The cons, first, and rest operators form the basis for computing with lists,
but there are lots of other operators for lists.
The operator ``append'', previously described informally with check-expect tests
(page \pageref{append-op-informal}), concatenates two lists, as illustrated
in the following check-expect tests,
which use the single-quote notation (Aside~\ref{acl2-single-quote}, page \pageref{acl2-single-quote})
to make them more compact.

\begin{Verbatim}
(check-expect (append '(1 2 3 4) '(5 6 7)) '(1 2 3 4 5 6 7))
(check-expect (append '(1 2 3 4 5) nil) '(1 2 3 4 5))
\end{Verbatim}

One way to provide a more formal definition of append is
to use a schematic for lists
that labels the elements of the list as subscripted variables.
The number of subscripts in the sequence implicitly reveals the number of elements in the list.
\label{list-schematic} In the following list schematics,
the $x$ list has $m$ elements, the $y$ list has $n$ elements,
and the concatenated list has $m+n$ elements.
\begin{samepage}
\begin{center}
(append [$x_1$ $x_2$ \dots $x_m$] [$y_1$ $y_2$ \dots $y_n$]) = [$x_1$ $x_2$ \dots $x_m$ $y_1$ $y_2$ \dots $y_n$]
\end{center}
\end{samepage}

We can use doublecheck to test some properties of append.
If we concatenate the empty list nil and a list $ys$,
we expect to get $ys$ as a result: (append nil $ys$) = $ys$.
If we concatenate a non-empty list $xs$ with a list $ys$,
we expect the first element of the result to be the same as
the first element of $xs$.
Furthermore, we expect the rest of the elements to be
the elements of the list that is the concatenation of
a list made up of all the elements of $xs$ beyond its first element
(that is, (rest $xs$)) and $ys$.

We would like to express this idea formally,
and to do so it will be helpful to use a special ACL2 operator
called ``if''
that selects one of two formulas based on a true/false
value specified in its first operand.
Its second operand is the formula it selects if
its first operand is true (that is, not nil).
If its first operand is false (that is, nil),
it selects its third operand.

\begin{figure}
\begin{center}
Axioms \{\emph{if}\} \\
\begin{tabular}{ll}
(if $p$ $x$ $y$) = $x$, \emph{if} $p$ $\neq$ nil  & \{\emph{if-true}\}  \\
(if $p$ $x$ $y$) = $y$, \emph{if} $p$ $=$ nil     & \{\emph{if-false}\} \\
\end{tabular}
\end{center}
\index{axiom!\{if-true\}, \{if-false\}}
\index{equation, by name!\{if-true\}, \{if-false\}}
\index{operator, by name!if (select formula)}\seeonlyindex{if}{operator}
\caption{Formula Selector: if}
\label{fig:if-axioms}
\end{figure}

Consider the value of (append $xs$ $ys$).
If the first operand is not nil (that is, if (consp $xs$) is true),
that value is (append (rest $xs$) $ys$).
However, ff $xs$ is nil, the value of append
is simply its second operand.
So, there are two formulas for append.
A doublecheck test in Figure~\ref{fig:append-test} (page \pageref{fig:append-test})
uses the consp and IF operators to select between them.

\begin{figure}
\begin{Verbatim}
(defproperty append-test
  (xs :value (random-list-of (random-natural))
   ys :value (random-list-of (random-natural)))
  (equal (append xs ys)
         (if (consp xs)
             (cons (first xs)
                   (append (rest xs) ys))
             ys)))
\end{Verbatim}
\caption{Doublecheck Test of Append}
\label{fig:append-test}
\end{figure}

\begin{aside}
Why does the property say (equal (append $xs$ $ys$) \dots)
instead of (= (append $xs$ $ys$) \dots)?
The ``='' operator
is restricted to numbers. The operator ``equal'' can check
for equality between other kinds of objects.
You can always use the operator equal,
but you can only use the operator ``='' when both operands are numbers.
Why bother with ``='', when its use is so limited?
We might say it makes the formula look more like an equation,
but that's not really much of an excuse,
since we have already had to conform to prefix notation
instead of the more familiar infix notation.
Feel free to use the ``equal'' operator all the time if you want to.
%We will be using ``='' when we can and hope it doesn't put too much of an extra burden on you.
\index{equal, vs =}\seeonlyindex{equal}{predicate}
\index{operator, by name!equal (\emph{see} predicate)}\index{predicate, by name!equal}
\index{operator!numeric order ($<$, $<=$, $=$, $>=$, $>$)}
\index{predicate!numeric order ($<$, $<=$, $=$, $>=$, $>$)}
\index{order!numeric ($<$, $<=$, $=$, $>=$, $>$)}
\index{number!order ($<$, $<=$, $=$, $>=$, $>$)}
\index{compare!numbers ($<$, $<=$, $=$, $>=$, $>$)}
\index{predicate!numeric order ($<$, $<=$, $=$, $>=$, $>$)}
\index{compare!ACL2 values (equal)}
\caption{``equal'' vs ``=''}
\label{equal}
\end{aside}

The append-test property might not be the first test you would think of,
but if the test failed to pass,
you would for sure know something was wrong with the append operator.
The append-test property is so plainly correct that
we are going to state it in the form of equations that we accept as axioms
(Figure~\ref{append-equations}, page \pageref{append-equations}).
As in the \{\emph{len}\} theorem, there are two \{\emph{append}\} equations,
and they specify the meaning of the append operation in different situations.
One of them specifies the meaning when the first operand is a non-empty list,
the other when specifies the meaning under all other circumstances.

\begin{figure}
\begin{center}
Axioms: \{\emph{append}\} \\
\begin{tabular}{ll}
(append (cons $x$ $xs$) $ys$) = (cons $x$ (append $xs$ $ys$)) & \{\emph{app1}\} \\
(append nil $ys$) =  $ys$                                     & \{\emph{app0}\} \\
\end{tabular}
\end{center}
\index{axiom!append}\index{equation!append}
\index{operator, by name!append}\index{append!operator}\index{concatenate}
\index{equation, by name!\{app0\}, \{app1\}}\index{axiom, by name!\{app0\}, \{app1\}}
\caption{List Concatenation: append}
\label{append-equations}
\end{figure}
\todo{Note 12/10/17, see also fig: Defining Concatenation
      Not sure what to do here. Had the following for app0 axiom, with note:
(append ~$e$~ $ys$) =  $ys$                                   & \{\emph{app0}\} \\
~~~~\emph{Note: Cite \{\emph{app0}\} only if \{\emph{app1}\} doesn't match.}&\\
      However, the ACL2 documentation requires first operand of append to be a truelist,
      even though ACL2 with guards off allows it to violate that constraint.
      For now (and it's late in the game), going back to the constraint.
      Before reverting, the following comment stood here:
      These axioms allow non-true-lists as first operand. However, when guards are in effect,
      ACL2 chokes if first operand isn't a true list.
      When guards are disabled (append 1 (list 2 3)) = (list 2 3)
      I don't want to say anything about guards, but students may see error messages
      that talk about guards. Not sure how to handle this.
      }

These equations about the append operation are simple enough,
but it turns out that lots of other properties of the
append operation can be derived from them.
For example, we can prove that the length of
the concatenation of two lists is the sum of the lengths of the lists,
as tested by a doublecheck property in
Chapter~\ref{ch:software-testing-prefix-notation} (page \pageref{additive-lengths-test}).
We call this theorem the \emph{additive law of concatenation}.
Let's see how a proof of this law could be carried out.

First, let's break it down into a some special cases.
We will use L($n$) as shorthand for the proposition that
(len (append ($x_1$ $x_2$ \dots $x_n$) $ys$))
is the sum of (len ($x_1$ $x_2$ \dots $x_n$)) and (len $ys$).
That makes L a predicate whose universe of discourse is
the natural numbers.

\label{additive-concat-law-predicate}
\begin{center}
% old prefix notation: \begin{tabbing}
% old prefix notation: L($n$) $\equiv$ (= \=(len (append [$x_1$ $x_2$ \dots $x_n$] $ys$))  \\
% old prefix notation:                   \>(+ (len [$x_1$ $x_2$ \dots $x_n$]) (len $ys$)))
% old prefix notation: \end{tabbing}
L($n$) $\equiv$ (len (append [$x_1$ $x_2$ \dots $x_n$] $ys$)) $=$ (+ (len [$x_1$ $x_2$ \dots $x_n$]) (len $ys$))
\end{center}

For the first few values of $n$, L($n$) would stand for the following equations.
\begin{quote}
L(0) $\equiv$ (len (append nil $ys$)) $=$ (+ (len nil) (len $ys$)) \\
L(1) $\equiv$ (len (append [$x_1$] $ys$)) $=$ (+ (len [$x_1$]) (len $ys$)) \\
L(2) $\equiv$ (len (append [$x_1$ $x_2$] $ys$)) $=$ (+ (len [$x_1$ $x_2$]) (len $ys$)) \\
L(3) $\equiv$ (len (append [$x_1$ $x_2$ $x_3$] $ys$)) $=$ (+ (len [$x_1$ $x_2$ $x_3$]) (len $ys$)) \\
L(4) $\equiv$ (len (append [$x_1$ $x_2$ $x_3$ $x_4$] $ys$)) $=$ (+ (len [$x_1$ $x_2$ $x_3$ $x_4$]) (len $ys$))
\end{quote}

\todo{COMMENT ONLY, NO TODO
in case we want to go back to the prefix =
\begin{center}
\begin{tabular}{llll}
L(0) & $\equiv$ & (= &(len (append nil $ys$)) \\
     &          &    &(+ (len nil) (len $ys$))) \\
L(1) & $\equiv$ & (= &(len (append [$x_1$] $ys$)) \\
     &          &    &(+ (len [$x_1$]) (len $ys$))) \\
L(2) & $\equiv$ & (= &(len (append [$x_1$ $x_2$] $ys$))\\
	 &          &    &(+ (len [$x_1$ $x_2$]) (len $ys$))) \\
L(3) & $\equiv$ & (= &(len (append [$x_1$ $x_2$ $x_3$] $ys$)) \\
     &          &    &(+ (len [$x_1$ $x_2$ $x_3$]) (len $ys$))) \\
L(4) & $\equiv$ & (= &(len (append [$x_1$ $x_2$ $x_3$ $x_4$] $ys$)) \\
     &          &    &(+ (len [$x_1$ $x_2$ $x_3$ $x_4$]) (len $ys$)))
\end{tabular}
\end{center}
END OF TODO COMMENT}

We can derive L(0) from the \{\emph{append}\} and \{\emph{len}\} axioms as follows.
We start from the left-hand side of the equation that L(0) stands for,
cite some axioms about append, len, and some axioms from numeric algebra,
one by one, and end up with the right-hand side of the L(0) equation.

\begin{center}
\emph{Proof of L(0), citing axioms} \\
\begin{tabular}{lll}
    & (len (append nil $ys$))  &                                                \\
$=$ & (len $ys$)               & \{\emph{app0}\}     (page \pageref{append-equations})\\
$=$ & (+ (len $ys$) 0)         & \{$+$ identity\}    (page \pageref{fig-02-01}) \\
$=$ & (+ 0 (len $ys$))         & \{$+$ commutative\} (page \pageref{fig-02-01}) \\
$=$ & (+ (len nil) (len $ys$)) & \{\emph{len0}\}     (page \pageref{len-equations})
\end{tabular}
\end{center}

That takes care of L(0). How about L(1)?

\begin{center}
\emph{Proof of L(1), citing axioms and proven equations} \\
\begin{tabular}{lll}
    & (len (append [$x_1$] $ys$))           &                     \\
$=$ & (len (append (cons $x_1$ nil) $ys$)   & \{\emph{cons}\} (page \pageref{first-rest-cons}) \\
$=$ & (len (cons $x_1$ (append nil $ys$)))  & \{\emph{app1}\}     \\
$=$ & (+ 1 (len (append nil $ys$)))         & \{\emph{len1}\}     \\
$=$ & (+ 1 (+ (len nil) (len $ys$)))        & \{L(0)\} ~~~~\emph{Note: L(0) already proved}\\
$=$ & (+ (+ 1 (len nil)) (len $ys$))        & \{$+$ associative\} (page \pageref{fig-02-01}) \\
$=$ & (+ (len (cons $x_1$ nil)) (len $ys$)) & \{\emph{len1}\}     \\
$=$ & (+ (len [$x_1$] (len $ys$))           & \{\emph{cons}\}     \\
\end{tabular}
\end{center}

That was a little harder. Will proving L(2) be still harder? Let's try it.

\begin{center}
\emph{Proof of L(2), citing axioms and proven equations}\\
\begin{tabular}{lll}
    & (len (append [$x_1$ $x_2$] $ys$))         &                     \\
$=$ & (len (append (cons $x_1$ [$x_2$]) $ys$))  & \{\emph{cons}\}     \\
$=$ & (len (cons $x_1$ (append [$x_2$] $ys$)))  & \{\emph{app1}\}     \\
$=$ & (+ 1 (len (append [$x_2$] $ys$)))         & \{\emph{len1}\}     \\
$=$ & (+ 1 (+ (len [$x_2$]) (len $ys$)))        & \{L(1)\} ~~~~\emph{Note: L(1) already proved}\\
$=$ & (+ (+ 1 (len [$x_2$])) (len $ys$))        & \{$+$ associative\} \\
$=$ & (+ (len (cons $x_1$ [$x_2$])) (len $ys$)) & \{\emph{len1}\}     \\
$=$ & (+ (len [$x_1$ $x_2$]) (len $ys$))        & \{\emph{cons}\}     \\
\end{tabular}
\end{center}

Fortunately, proving L(2) was no harder than proving L(1).
In fact the two proofs cite exactly the same equations all the way through,
except in one place.
Where the proof of L(1) cited the equation L(0),
the proof of L(2) cited the equation L(1).
Maybe the proof of L(3) will work the same way.

\begin{center}
\emph{Proof of L(3), citing axioms and proven equations}\\
\begin{tabular}{lll}
    & (len (append [$x_1$ $x_2$ $x_3$] $ys$))         &                     \\
$=$ & (len (append (cons $x_1$ [$x_2$ $x_3$]) $ys$))  & \{\emph{cons}\}     \\
$=$ & (len (cons $x_1$ (append [$x_2$ $x_3$] $ys$)))  & \{\emph{app1}\}     \\
$=$ & (+ 1 (len (append [$x_2$ $x_3$] $ys$)))         & \{\emph{len1}\}     \\
$=$ & (+ 1 (+ (len [$x_2$ $x_3$]) (len $ys$)))        & \{L(2)\} ~~~~\emph{Note: L(2) already proved}\\
$=$ & (+ (+ 1 (len [$x_2$ $x_3$])) (len $ys$))        & \{$+$ associative\} \\
$=$ & (+ (len (cons $x_1$ [$x_2$ $x_3$])) (len $ys$)) & \{\emph{len1}\}     \\
$=$ & (+ (len [$x_1$ $x_2$ $x_3$]) (len $ys$))        & \{\emph{cons}\}     \\
\end{tabular}
\end{center}

\label{induction-rationale}\index{induction!rationale}\index{induction!proof by}
By now, it's easy to see how to derive L(4) from L(3),
then L(5) from L(4), and so on.
If you had the time and patience, you could prove L(100), L(1000), or even L(1000000)
by following the established pattern.
It would not be hard to write a program to print out the proof of L($n$),
given any natural number $n$.
Since we know how to prove L($n$) for any natural number $n$,
it seems fair to say that we know all those equations are true.
That is, we think we know that the formula ($\forall$$n$.L($n$)) is true.
However, to prove that formula in a formal sense,
we need a rule of inference that allows us to make conclusions
from patterns like those we observed in proving L(1), L(2), and so on.
That rule of inference is known as \emph{mathematical induction}.

\seeonlyindex{mathematical induction}{induction}\index{induction!proof by}
Mathematical induction provides a way to prove that
formulas like ($\forall$$n$.P($n$)) are true
when P is a predicate whose universe of discourse is the natural numbers.
If for each natural number $n$, P($n$) stands for a proposition,
then mathematical induction is an inference rule that may be useful
in a proof that ($\forall$$n$.P($n$)) true.
That is not to say that such a proof can always be constructed.
It's just that mathematical induction might provide some help in the process.
The inverse is also true: mathematical induction cannot help
if the universe of discourse is not the natural numbers.\footnote{Mathematical
induction is not the only form
of proof by induction, but all the other forms
(other than transfinite induction, which is a different animal)
can be contorted into proofs by mathematical induction.
We will stick with classical, mathematical induction
and leave the variations for another time.
They are easy to learn for people who know mathematical induction well.}

The rule goes as follows. Infer the truth of ($\forall$$n$.P($n$)),
citing \{induction\} as a rule of inference,
from proofs of two propositions:
P(0) and ($\forall n.$P($n$) $\rightarrow$ P($n+1$)).

\begin{center}
\begin{tabular}{lll}
\emph{Prove:} & P($0$)                                      &     \emph{base case}\\
\emph{Prove:} & ($\forall$$n$.(P($n$)$\rightarrow$P($n+1$)))&\emph{inductive case}\\
              &---------------------------------------------& \\
\emph{Infer:} & ($\forall$$n$.P($n$))                    & \emph{citing} \{induction\}\\
\end{tabular}
\end{center}

It's a very good deal if you think about it.
A direct proof of ($\forall$$n$.P($n$)) would require a proof of proposition P($n$)
for each value of $n$ ($0$, $1$, $2$, \dots).
But, in a \index{proof!by induction}proof by \index{induction!proof by}induction,
the only proposition that needs to be proved on its own is P($0$).
To justify any step in the proof of proposition P($n+1$)
(that is, any proposition in the predicate P with a non-zero index:
P($1$), P($2$), P($3$), \dots),
you are allowed to cite P($n$) as if it were a known theorem.
The proof of P$0$) is known as the base case in the proof by induction,
and the proof of (P($n$) $\rightarrow$ P($n+1$)) is known as the inductive case.

The reason you can assume that P($n$) is true in the proof of P($n+1$)
(that is, in the inductive case)
is because the goal, according part two of the inference rule
for induction, is to prove that the implication
P($n$)$\rightarrow$P($n+1$) is true.
When P($n$) is false, we know already from the truth table
of the implication operator (page \pageref{implication-truth-table})
that the implication P($n$)$\rightarrow$P($n+1$) is true.
There is no need to prove that again.
Therefore, in the proof of P($n+1$), we can assume P($n$) is true.
The assumption of P($n$) is known as the
\index{hypothesis!induction}\index{induction!hypothesis}\emph{induction hypothesis}.
It gives you a leg up in the proof of P($n+1$).

Figure~\ref{induction-rule} states the \{induction\} inference rule
in the form of natural deduction, a formal method of logic discussed
in Section~\ref{sec:deduction}. You don't need to have studied that
section to understand inductive proofs, but in case you did study
natural deduction, Figure~\ref{induction-rule} puts proof by
induction in that context.

\begin{figure}
\begin{center}
\begin{tabular}{ll}
Prove P(0)                                         &\emph{base case}\\
 - - - - - - - - - - - - - - - - - - - - -         &\\
Prove ($\forall$$n$.(P($n$)$\rightarrow$P($n+1$))) &\emph{inductive case}\\
-------------------------------------\{induction\} &\\
Infer ($\forall$$n$.P($n$))                        &\\
\end{tabular}
\end{center}
\index{induction!proof by}\index{proof!by induction}
\index{inference rule, by name!\{induction\}}
\caption{Mathematical Induction: a Rule of Inference}
\label{fig-04-01}
\label{induction-rule}
\end{figure}

\label{induction-hyp-def}Now,
let's apply mathematical induction to prove
the additive law of concatenation.
Here, the predicate that we will apply the method to is L
(page \pageref{additive-concat-law-predicate}).
\label{len-additive-thm}We
have already proved L(0), so we have already completed one of the
two proofs required to cite the mathematical induction inference rule.
All that is left is to prove ($\forall$$n$.(L($n$)$\rightarrow$L($n+1$))).
That is, we have to derive L($n+1$) from L($n$) for an arbitrary natural number $n$.
Fortunately, we know how to do this. Just copy the derivation of,
say L(3) from L(2), but start with an append formula in which the first operand
is a list with $n+1$ elements, and cite L($n$) where we would have cited L(2).

\begin{center}
\emph{Proof of L(n+1), citing axioms, proven equations, and L(n): L(n) $\rightarrow$ L(n+1)}\\
\begin{tabular}{lll}
    & (len (append [$x_1$ $x_2$ \dots $x_{n+1}$] $ys$))         &                     \\
$=$ & (len (append (cons $x_1$ [$x_2$ \dots $x_{n+1}$]) $ys$))  & \{\emph{cons}\}     \\
$=$ & (len (cons $x_1$ (append [$x_2$ \dots $x_{n+1}$] $ys$)))  & \{\emph{app1}\}     \\
$=$ & (+ 1 (len (append [$x_2$ \dots $x_{n+1}$] $ys$)))         & \{\emph{len1}\}     \\
$=$ & (+ 1 (+ (len [$x_2$ \dots $x_{n+1}$]) (len $ys$)))        & \{L($n$)\}          \\
$=$ & (+ (+ 1 (len [$x_2$ \dots $x_{n+1}$])) (len $ys$))        & \{$+$ associative\} \\
$=$ & (+ (len (cons $x_1$ [$x_2$ \dots $x_{n+1}$])) (len $ys$)) & \{\emph{len1}\}     \\
$=$ & (+ (len [$x_1$ $x_2$ \dots $x_{n+1}$]) (len $ys$))        & \{\emph{cons}\}     \\
\end{tabular}
\end{center}

This completes the mathematical induction proving the
additive law of concatenation.
\begin{samepage}
\begin{center}
\index{append!additive law}
\index{theorem, by name!\{additive law of concatenation\}}\index{additive law of concatenation}\index{concatenate!additive law}
\label{additive-law-concatenation}
Theorem \{\emph{additive law of concatenation}\} \\
$\forall$$n$.((len (append [$x_1$ $x_2$ \dots $x_n$] $ys$))
= (+ (len [$x_1$ $x_2$ \dots $x_n$]) (len $ys$)))
\end{center}
\end{samepage}

An important point to notice in this proof is that
we could not cite the \{\emph{cons}\} equation to replace [$x_2$ \dots $x_{n+1}$]
with (cons $x_2$ [$x_3$ \dots $x_{n+1}$]).
The reason we could not do this is that we are trying to derive
L($n+1$) from L($n$) without making any assumptions about $n$
other than the fact that it is a natural number.
Since zero is a natural number, the list [$x_2$ \dots $x_{n+1}$]
could be empty, and the cons operation cannot deliver an empty list as its value.

In the next section, we will prove some properties of append
that confirm some of its properties with respect to other operators.
These properties, and in fact all properties of the append operator,
can be derived from the append axioms (Figure~\ref{append-equations}, page \pageref{append-equations}).
Those axioms state properties of the append operation in two separate cases:
(1)~when the first operand is the empty list (the \{\emph{app0}\} equation), and
(2)~when the first operand is a non-empty list (the \{\emph{app1}\} equation).
When the first operand is the empty list,
the result must be the second operand, no matter what.
When the first operand is not empty, it must have a first element.
That element must also be the first element of the concatenation.
The other elements of the concatenation are the ones you would get
if you appended the rest of the first operand and the second operand.

Both of these properties are so straightforward and easy to believe
that we would probably be willing to accept them as axioms with no proof at all,
so it might come as a surprise that all of the other properties
of the append operation can be derived from
the two simple properties \{\emph{app0}\} and \{\emph{app1}\}.
That is the power of mathematical induction.
The two equations of the append axioms
amount to an inductive definition of the append operator.

An inductive definition is circular in the sense
that some of the equations in the definition refer
to the operator on both sides of the equation.
Most of the time, we think circular definitions are not useful,
so it may seem surprising that they can be useful in mathematics.
Some aren't, but some are, and you will
gradually learn how to recognize and create useful,
circular (that is, inductive) definitions.

\begin{figure}
\begin{center}
\begin{tabular}{lp{3.5in}}
\emph{Complete} & All possible combinations of operands are covered by at least one equation in the definition. \\
\emph{Consistent} & Combinations of operands covered by two or more equations define the same value for the operation. \\
\emph{Computational} &
\begin{enumerate}
\item \emph{Non-Inductive Equation}: In at least one equation,
the operator being defined appears only on left-hand side.
\item \emph{Reduced Computation}: On the right-hand side of an inductive equation,
each invocation of the operator being defined has operands that
are closer to the operands on the left-hand side of a non-inductive equation
than to those on the left-hand side of the inductive equation.
\end{enumerate}
\end{tabular}
\end{center}
\index{three C's}\index{definition!inductive (circular)}
\caption{The Three C's: a Guide to Inductive Definitions}
\label{fig:inductive-def-keys}
\end{figure}

It turns out that all operators that can be defined in
\index{software!as equations}\index{equation!software}software
have inductive definitions in the manner of the equations
of the append axioms (Figure~\ref{append-equations}, page \pageref{append-equations}).
The keys to an inductive definition of an operator are  listed in
Figure~\ref{fig:inductive-def-keys} (page \pageref{fig:inductive-def-keys}).
All of the software we will discuss will take the form of a collection
of inductive definitions of operators.
That makes it possible to use mathematical induction as
a fundamental tool in verifying, to a logical certainty,
properties of that software.

This is of course not the only way to write software.
In fact, most software is not written in terms of inductive equations.
But, proving properties of software written using conventional methods
is clumsy, at best, especially in the framework of classical logic.
So, in terms of understanding what computers do and how they do it,
inductive definitions provide solid footing.
That is why we base our discussion on software written
in the form of inductive equations rather than conventional methods.

\begin{ExerciseList}

\Exercise Prove $\forall xs.$(natp (len $xs$)).
You may cite
\index{equation, by name!\{natp0\}, \{natp1\}}\index{axiom, by name!\{natp0\}, \{natp1\}}\{natp0\} and \{natp1\},
defined as follows. (\emph{Note}: This definition will be adequate for this exercise but is not the full definition of natp.)
\begin{center}
\begin{tabular}{ll}
(natp $0$)                                            & \{natp0\}\\
$\forall x.$((natp $x$) $\rightarrow$ (natp (+ x 1))) & \{natp1\}\\
\end{tabular}
\end{center}

\Exercise Assume the following axioms \{\emph{expt0}\} and \{\emph{expt1}\} are true.
\begin{samepage}
\label{expt-equations}
\begin{center}
Axioms \{\emph{expt}\} \\
\begin{tabular}{ll}
(expt $x$ 0) = 1                                & \{\emph{expt0}\} \\
(expt $x$ (+ $n$ 1)) = ($*$ $x$ (expt $x$ $n$)) & \{\emph{expt1}\} \\
\hline
\end{tabular}
\\ $x$ \emph{is a number}
\\ $n$ \emph{is a natural number}
\\ ($*$ $x$ $y$) = $x \times y$
\end{center}
\end{samepage}
Prove the following theorem \{\emph{expt}\}, where $n$ is a natural number and $x$ is a number.
\begin{samepage}
\label{expt-thm}
\index{theorem, by name!\{expt\}}\index{axiom!exponent}\index{operator, by name!expt ($x^n$)}\seeonlyindex{expt}{operator}
\index{axiom, by name!\{expt0\}, \{expt1\}}\index{equation, by name!\{expt0\}, \{expt1\}}
\begin{center}
Theorem \{\emph{expt}\} \\
(expt $x$ $n$) = $x^n$
\end{center}
\end{samepage}

\end{ExerciseList}

\section{Defun: Defining Operators in ACL2}
\label{sec:defun}

Now, we are going to let you in on a little secret.
The axioms we wrote for the append operator are very
close to a specification of that operator in ACL2
(and most other programming languages, too, although
it is rarely done this way).
The ACL2 system gives us not just a programming language,
but also a mechanized logic to help in verifying properties of
that software to a logical certainty,
and Proof Pad has a partially automated testing system to
check out properties before we try to prove them.
So, ACL2 provides some important advantages in the study of logic.

Operators are defined in ACL2 with a defun command,
which has four parts.
\begin{quote}
\index{defun}\index{definition!defun}\index{definition!operator}
(defun $f$ ($x_1$ $x_2$ \dots $x_n$) \emph{\dots ACL2-formula \dots})

\begin{enumerate}
\item the keyword ``defun''
\item a name for the operator being defined ($f$)
\item a list enclosed in parentheses of names designating operands ($x_1$ $x_2$ \dots $x_n$)
\item an ACL2 formula specifying the value the operator will deliver
\end{enumerate}
\end{quote}

Most of the time, the formula for the value the operator delivers
will have subformulas specifying alternative values for different cases.
Formulas interpreted as predicates select one of
the subformulas to produce the value corresponding to the operands.

In Section \ref{sec:induction} (Figure~\ref{append-equations}, page \pageref{append-equations})
we defined the append operator with two equations,
one for the case when the first operand was a non-empty list,
and the other for all other possibilities.
The ACL2 definition, following that pattern, has two subformulas,
one for each case.
It uses the IF operator
(Figure~\ref{fig:if-axioms}, page \pageref{fig:if-axioms})
to select the appropriate formula.

Figure~\ref{fig:append-defun} (page \pageref{fig:append-defun})
repeats the axioms for the append operator from
Figure~\ref{append-equations} (page \pageref{append-equations})
and also displays an ACL2 definition of append using defun,
which expresses the axioms in ACL2 notation.
As it happens, the append operator is an ACL2 intrinsic.
It is defined by the ACL2 system, so the definition
in Figure~\ref{fig:append-defun} is redundant,
and the ACL2 system will tell you that if you try to define it.
Shortly, we will begin to define operators that are not
intrinsic, so they need definitions,
but we will use one or two familiar examples, like this one,
as a starting point to put us on the right track.

\begin{figure}
\begin{center}
Axioms: \{\emph{append}\} \\
\begin{tabular}{ll}
(append (cons $x$ $xs$) $ys$) = (cons $x$ (append $xs$ $ys$)) & \{\emph{app1}\} \\
(append nil $ys$) =  $ys$                                     & \{\emph{app0}\} \\
\end{tabular}
\begin{Verbatim}
(defun append (xs ys)    ; intrinsic operator, so defun is redundant
  (if (consp xs)                              ; select formula
      (cons (first xs) (append (rest xs) ys)) ; {app1}, xs not empty
      ys))                                    ; {app0}, xs is empty
\end{Verbatim}
\end{center}
%Reverting to 2nd axiom requiring first arg to be truelist, as req'd in acl2 docuemtation.
%Was as follows:
%(append $a$ $ys$) =  $ys$                                     & \{\emph{app0}\} \\
%~~~~\emph{Note: Cite \{\emph{app0}\} only if \{\emph{app1}\} doesn't match.}&\\
\index{axiom!append}\index{append!operator}\index{operator, by name!append}
\index{axiom, by name!\{app0\}, \{app1\}}\index{equation, by name!\{app0\}, \{app1\}}
\caption{Defining Concatenation: append}
\label{fig:append-defun}
\end{figure}

So, now you know. We've been writing
\index{software!as axioms}\index{programs, as axioms}
\index{axiom!software}\index{equation!software}programs
on the sly, passing them off as axioms.
Why? Because that's how we want you to think of them.
A program is a collection of axioms, expressed as equations
that specify properties that you want operators to have.
You can reason from those equations using the same methods
you have used in reasoning about Boolean equations or numeric equations.
The program is written in the syntax of a programming language,
which makes it look a bit stilted.
That is always the case in programming languages because
they have their own syntax, and you have to conform to it.
It pays off, though.
If you stick with the program, you can get the computer to carry out
the computations you want done.

Since definitions must use the \index{equation!ACL2}\index{ACL2!equation}ACL2 syntax,
they don't look much like equations,
but if they are complete, consistent, and computational
(Figure~\ref{fig:inductive-def-keys}, page \pageref{fig:inductive-def-keys}),
the values they deliver will have the properties you derive
from the equations.
They may not have all the properties you expected.
They may have bugs.
But, you'll have a good chance of fixing them with
automated testing (defproperty)
and the reasoning assistance of the ACL2 mechanized logic.

Going forward, we will define operators that aren't
intrinsic in ACL2 (and, therefore, need definitions)
both in the form of an ACL2 defun
and in the form of equations for paper-and-pencil reasoning.
The ACL2 definitions produce operators with matching axioms and
make it possible to apply automated testing and mechanized logic
to confirm some of the properties of those computations.
When the operators we are discussing are intrinsic,
we will usually not include defun forms for them,
just axioms for paper-and-pencil reasoning.
Automated testing and mechanized logic will make use
of their intrinsic definitions in the ACL2 system.

\section{Concatenation, Prefixes, and Suffixes}
\label{sec:append-prefix-suffix}
%%% in this section, prove the correctness of append
%%% with respect to a (prefix n xs) operator and (nthcdr n xs).

If you concatenate two lists, $xs$ and $ys$,
you would expect to be able to retrieve the elements
of $ys$ by dropping some of the elements of the list
produced by the concatenation.
How many elements would you need to drop?
That depends on the number of elements in $xs$.
If there are $n$ elements in $xs$ and you drop $n$ elements
from (append $xs$ $ys$), you expect the result to be identical
to the list $ys$. To express that expectation, we can use
an intrinsic operator in ACL2 with the arcane name ``nthcdr''.
The nthcdr operator has two operands: a natural number and a list.
The formula (nthcdr $n$ $xs$) delivers a list like $xs$,
but without its first $n$ elements.
If $xs$ has fewer than $n$ elements,
then the formula delivers the empty list.
In any case, nthcdr delivers a suffix of the list
supplied as its second operand.

If the first operand (the number of elements to be dropped) is zero,
you would expect
nthcdr to deliver the entire list, having dropped no elements.
If the second operand has no elements,
you would expect
nthcdr to deliver a list just like that
(that is, a list with no elements).
Combining these two observations, we find that
$xs$ would be a suitable value for (nthcdr $n$ $xs$)
if either $n$ is zero or $xs$ has no elements.

\begin{aside}
The predicate ``posp'' is used to test for non-zero values
in the domain of natural numbers.
In the ACL2 logic, the formula (posp $n$) has the value true if $n$ is
a non-zero, natural number (that is, a strictly positive natural number).
The value of (posp $n$) is false if $n$ is not a natural number
or if $n$ is zero.
That makes posp especially useful
in definitions that are inductive on the natural numbers.
You might think that (> $n$ 0) would
work the same way, but it doesn't because that formula
does not constrain $n$ to the natural numbers,
and many inductive definitions rely on that constraint.

The predicate ``zp'' imposes the same constraint to natural numbers,
but is true when its operand is zero and false otherwise.
Both zp and posp are useful for inductive definitions that
rely on the domain of natural numbers to ensure that the
defined operator terminates.
\index{operator, by name!posp (\emph{see} predicate)}
\index{predicate, by name!posp (positive integer)}\seeonlyindex{posp}{predicate}
\index{operator, by name!zp (\emph{see} predicate)}
\index{predicate, by name!zp (natural number zero)}\seeonlyindex{zp}{predicate}
\caption{Natural Number Tests: Zero (zp) and Non-Zero (posp)}
\label{zp-def}
\end{aside}

The other possibility is that $n$ is not zero and $xs$ has some elements.
Since the first operand is a natural number,
being non-zero is the same as being one or more.
In that case you would expect (nthcdr $n$ $xs$) to deliver
the same list that it would deliver
if you dropped the first element of $xs$
and then, in addition, dropped $(n - 1)$ more elements.
Together, these two actions would drop $n$ elements.
The axioms in Figure~\ref{fig:nthcdr-defun} (page \pageref{fig:nthcdr-defun})
express these observations as equations.

The figure also contains an ACL2 definition of nthcdr, which
is of course redundant because nthcdr if intrinsic in ACL2.\footnote{If
you submit a definition of nthcdr,
the system will inform you of the redundancy.}
The definition uses the predicate consp
(Figure~\ref{consp-axiom}, page \pageref{consp-axiom})
to find out whether the list contains some elements and
uses the predicate
\label{posp-def} posp
to determine whether
the number of elements to be dropped is one or more.
It combines these predicates with the ``and'' operator,
which is the ACL2 notation for the $\wedge$ operator in logic.
\label{and-op=informal}
The value (and $a$ $b$) false (nil)
if either $a$ or $b$ is false and true otherwise.
So, the ACL2 definition matches the axioms.

\begin{figure}
\begin{center}
Axioms \{\emph{nthcdr}\} \\
\begin{tabular}{ll}
(nthcdr $(n+1)$ (cons $x$ $xs$) = (nthcdr $n$ $xs$) & \{\emph{sfx1}\} \\
(nthcdr $n$ $xs$) = $xs$                            & \{\emph{sfx0}\}   \\
~~~~\emph{Note 1: Cite \{\emph{sfx0}\} only if \{\emph{sfx1}\} doesn't match.}&\\
~~~~\emph{Note 2: $n$ is a natural number.}
\end{tabular}
\begin{Verbatim}
(defun nthcdr (n xs)    ; intrinsic operator, so defun is redundant
  (if (and (posp n) (consp xs))   ; select formula
      (nthcdr (- n 1) (rest xs))  ; {sfx1}
      xs))                        ; {sf0}
\end{Verbatim}
\end{center}
\seeonlyindex{nthcdr}{operator}\index{operator, by name!nthcdr (suffix of list)}
\index{equation, by name!\{sfx0\}, \{sfx1\}}
\caption{Defining List Suffix Extractor: nthcdr}
\label{fig:nthcdr-defun}
% old label for nthcdr axioms: \label{nthcdr-equations}
\end{figure}

% NEW COMMENT 12-10-17 Not sure what the problem was before
%                      so maybe Ruben should look at it to make sure it's not wrong.
% FIXED NOW, REX THINKS as of 5SEP2017
% Rex: sfx1 isn't true, right?
% I'm not sure we want to introduce it as an axiom, if later we'll have to explain it isn't really true.
% Ruben: left as is for now, with (natp n) implicit, but inserted a comment about the type of n
% Updte (Rex 5Sep 2017: I think it's fixed, now.

The equations in Figure~\ref{fig:nthcdr-defun} cover all combinations
of values that the operands of nthcdr can have
The first operand is a natural number,
so it's either zero or bigger than zero.
The second operand, a list, either has some elements or it doesn't.
So the definition is complete, having covered all the cases.
The cases do not overlap, so we don't need to worry about
consistency between the axioms.

\begin{aside}
There is a subtlety in the axioms for nthcdr (Figure~\ref{fig:nthcdr-defun})
that needs to be discussed.
The operand prototypes in the
\{sfx1\} axiom match whenever the first operand is a non-zero natural number
($n+1$ cannot be zero when $n$ is a natural number)
and the second operand is a non-empty list.
However, the operand prototypes in the \{sfx0\} axiom match anything.
There is a note restricting
citations of the second axiom to cases
where the first axiom does not apply.
The definition of the len operator
had a fall-through axiom like this, too
(Figure~\ref{fig:len-axioms}, page \pageref{fig:len-axioms}).

Usually we state axioms with operand prototypes that constrain
the operands to specific forms,
but in the case of nthcdr, Note 2 conforms to the meaning
of the (if $p$ $a$ $b$) formula, which chooses formula $b$
only if $p$ has the value nil (representing false).
Since \{\emph{sfx0}\} only applies if the operand prototypes in
\{\emph{sfx0}\} don't match the operands in a formula that refers to nthcdr,
the two axioms do not share any combination of operands, so they cannot
cause an inconsistency in the specified results.
\caption{Fall-Through Axioms}
\label{fig:fall-through-axioms}
\end{aside}

That covers two of the three C's guidelines for inductive definitions of operators
(Figure~\ref{fig:inductive-def-keys}, page \pageref{fig:inductive-def-keys}).
The equations are complete and consistent.
The third guideline (computational) has two parts, one of which is
a requirement that at least one axiom must be non-inductive.
The \{sfx0\} equation is not inductive because the nthcdr operator
is not invoked on the right-hand side of the equation.
In that case, nthcdr just delivers its second operand, as is.
So, the axioms pass muster on that part of the computational guideline.
With regard to the inductive axiom \{sfx1\},
the operands on the right-hand side of the equation are
smaller and shorter than the operands on the left-hand side,
which makes them closer to the non-inductive case,
since that axiom, \{sfx0\}, will apply if either the first
operand is zero or the second one doesn't have any elements.
Therefor, the equations conform to the three C's guidelines,
and we can conclude that they define an operator.

At this point, we are in a position to verify the relationship
between the append and nthcdr operators that started this discussion.
Namely, we want to prove that if the lists $xs$ and $ys$ are concatenated,
and then (len $xs$) elements are dropped from the beginning of the
concatenation, the result will be the list $ys$.
We will use S($n$) as a shorthand for this property
when $xs$ has $n$ elements.

\begin{samepage}
\begin{center}
\label{append-prefix-thm-predicate}
S($n$) $\equiv$ (nthcdr (len [$x_1$ $x_2$ \dots $x_n$]) (append [$x_1$ $x_2$ \dots $x_n$] $ys$)) $=$ $ys$
\end{center}
\end{samepage}

\todo{COMMENT ONLY, NO TODO
Just in case we decide to go back to ACL2 syntax for the def'n of S
S($n$) $\equiv$ (equal & (nthcdr & (len [$x_1$ $x_2$ \dots $x_n$])          \\
                       &         & (append [$x_1$ $x_2$ \dots $x_n$] $ys$)) \\
                       & $ys$)   &                                          \\
}

\label{append-suffix-thm-pencil-proof} \todo{COMMENT ONLY, NO TODO label added 16Sep2017}
S is a predicate indexed by the natural numbers,
so the formula $\forall n.$S$(n)$ is a candidate for proof by induction.
According to the rule of inference for mathematical induction
(Figure~\ref{induction-rule}, page \pageref{induction-rule}),
we are obliged to prove two things:
(1)~the formula S(0) is true and
(2)~the formula S($n+1$) is true under the assumption that S($n$) is true,
regardless of what natural number $n$ stands for. Let's do those two proofs.

First, we prove S(0).
When $n$ is zero, the list [$x_1$ $x_2$ \dots $x_n$] is empty:
[$x_1$ $x_2$ \dots $x_0$] $=$ nil, according to the \{nlst\} axiom
(Figure~\ref{numbered-list-interpretation}, page \pageref{numbered-list-interpretation}).
So, S(0) stands for the following equation.

\begin{samepage}
\begin{center}
S(0) $\equiv$ (nthcdr (len nil) (append nil $ys$)) $=$ $ys$
\end{center}
\end{samepage}

\todo{COMMENT ONLY, NO TODO
Just in case we decide to go back to ACL2 syntax for the def'n of S
\begin{samepage}
\begin{center}
\begin{tabular}{ll}
S(0) $\equiv$ (equal & (nthcdr (len nil) (append nil $ys$)) \\
                     & $ys$)                                \\
\end{tabular}
\end{center}
\end{samepage}
END OF COMMENT ONLY, NO TODO}

As is our usual practice when proving an equation,
we start with the formula on one side and use known
equations to gradually transform that formula
into the one on the other side of the equation.

\begin{center}
\begin{tabular}{lll}
    & (nthcdr (len nil) (append nil $ys$))  &                                                  \\
$=$ & (nthcdr (len nil) $ys$)               & \{\emph{app0}\} (page \pageref{fig:append-defun})\\
$=$ & (nthcdr 0 $ys$)                       & \{\emph{len0}\} (page \pageref{len-equations})   \\
$=$ & $ys$                                  & \{\emph{sfx0}\} (page \pageref{fig:nthcdr-defun})\\
\end{tabular}
\end{center}

That takes care of S(0). Next, we prove S($n+1$), assuming that
the induction hypothesis S($n$) is true.

\begin{samepage}
\index{theorem, by name!\{append-suffix\}}\index{append!suffix theorem}
\begin{center}
%\begin{tabular}{lll}
S($n+1$) $\equiv$ (nthcdr (len [$x_1$ $x_2$ \dots $x_{n+1}$]) (append [$x_1$ $x_2$ \dots $x_{n+1}$] $ys$)) $=$ $ys$
%\end{tabular}
\end{center}
\end{samepage}

\begin{center}
\begin{tabular}{llll}
    & (nthcdr & (len [$x_1$ $x_2$ \dots $x_{n+1}$])                 & \\
    &         & (append [$x_1$ $x_2$ \dots $x_{n+1}$] $ys$))        & \\
$=$ & (nthcdr & (len (cons $x_1$ [$x_2$ \dots $x_{n+1}$])))         & \{\emph{cons}\} (page \pageref{first-rest-cons}) \\
    &         & (append (cons $x_1$ [$x_2$ \dots $x_{n+1}$]) $ys$)) & \{\emph{cons}\}                                \\
$=$ & (nthcdr & (+ 1 (len [$x_2$ \dots $x_{n+1}$]))                 & \{\emph{len1}\} (page \pageref{len-equations})       \\
    &         & (cons $x_1$ (append [$x_2$ \dots $x_{n+1}$]) $ys$)) & \{\emph{app1}\} (Figure \ref{fig:append-defun}, page \pageref{fig:append-defun})\\
$=$ & (nthcdr & (+ (len [$x_2$ \dots $x_{n+1}$]) 1)                 & \{\emph{+ commutative}\} (page \pageref{fig-02-01})  \\
    &         & (cons $x_1$ (append [$x_2$ \dots $x_{n+1}$]) $ys$)) &                                                      \\
$=$ & (nthcdr & (len [$x_2$ \dots $x_{n+1}$])                       & \{\emph{sfx1}\}                                      \\
    &         & (append [$x_2$ \dots $x_{n+1}$] $ys$))              &                                                      \\
$=$ & $ys$    &                                                     & \{S($n$)\} (induction hypothesis)\\
\end{tabular}
\end{center}

The last step in the proof is justified by citing S($n$).
This is a little tricky because the formula that S($n$)
stands for is not exactly the same as the formula in the next-to-last step of the proof.
We interpret the formula [$x_1$ $x_2$ \dots $x_n$] in the definition of S($n$)
to stand for any list with $n$ elements.
The elements in the list [$x_2$ \dots $x_{n+1}$] are numbered 2 through $n+1$,
which means there must be exactly $n$ of them
(\{\emph{nlst}\}, Figure~\ref{numbered-list-interpretation}, page \pageref{numbered-list-interpretation}).

With this interpretation, the formula in the next-to-last step
matches the formula in the definition of S($n$),
which makes it legitimate to cite S($n$) to justify
the transformation to $ys$ in the last step of the proof.
We will cite axiom \{\emph{nlst}\}, the numbered-list interpretation,
frequently in proofs about lists.

At this point, we know that (append $xs$ $ys$) delivers
a list that has the right elements at the end.
How about the beginning?
We expect the concatenation to start with the elements of the list $xs$,
so if we extract the first $n$ elements of (append $xs$ $ys$), where $n$ is (len $xs$),
we would expect to get a list identical to $xs$.
To express this expectation formally, we need a operator that,
given a number $n$ and a list $xs$, delivers the first $n$ elements of $xs$.
Let's call that operator ``prefix'' and think about properties it would have to satisfy.

Of course, if $n$ is zero, or if $xs$ is empty,
(prefix $n$ $xs$) must be the empty list.
If $n$ is non-zero natural number and $xs$ is not empty,
then the first element of (prefix $n$ $xs$) must be the first element of $xs$,
and the other elements must be the first $n-1$ elements of (rest $xs$).
Figure~\ref{prefix-equations} (page \pageref{prefix-equations}) displays
equations that define the prefix operator.
We can derive the prefix property of the append operator
from those equations and the axioms of the append operator
(Figure~\ref{fig:append-defun}, page \pageref{fig:append-defun}).
We will prove $\forall n.$P($n$) by induction,
where the predicate P is defined as follows.

\begin{samepage}
\begin{center}
P($n$) $\equiv$ (prefix (len [$x_1$ $x_2$ \dots $x_n$]) (append [$x_1$ $x_2$ \dots $x_n$] $ys$))
                $=$ [$x_1$ $x_2$ \dots $x_n$])
\end{center}
\end{samepage}

As the \{induction\} rule of inference requires, we will prove that P(0) is true
and also that P($n+1$) is true whenever P($n$) is true.
Those two proofs will allow us to conclude that
$\forall n.$P($n$) is true by \{induction\}.

\begin{figure}
\begin{center}
Axioms \{\emph{prefix}\}                                           \\
\begin{tabular}{ll}
(prefix $(n + 1)$ (cons $x$ $xs$)) = (cons $x$ (prefix $n$ $x$s)) & \{\emph{pfx1}\} \\
(prefix $n$ $xs$) =  nil                                          & \{\emph{pfx0}\} \\
~~~~\emph{Note 1: Cite \{\emph{pfx0}\} only if \{\emph{pfx1}\} doesn't match.}&\\
~~~~\emph{Note 2: $n$ is a natural number.}
\end{tabular}
\begin{Verbatim}
(defun prefix (n xs)
  (if (and (posp n) (consp xs))
      (cons (first xs) (prefix (- n 1) (rest xs)))  ; {pfx1}
      xs))                                          ; {pfx0}
\end{Verbatim}
\end{center}
\seeonlyindex{prefix, of list}{operator}\index{operator, by name!prefix (of list)}\index{equation, by name!\{pfx0\}, \{pfx1\}}
\caption{Defining List Prefix Extractor: prefix}
\label{prefix-equations}
\end{figure}

\begin{center}
P($0$) $\equiv$ (prefix (len nil) (append nil $ys$)) $=$ nil
\end{center}

As in the proof of the append suffix theorem, we start
with the formula on one side of the P(0) equation
and use known equations to gradually transform
that formula to the one on the other side of the equation.

\begin{center}
\begin{tabular}{lll}
    & (prefix (len nil) (append nil $ys$))  &                                                  \\
$=$ & (prefix 0 (append nil $ys$))          & \{\emph{len0}\} (page \pageref{len-equations})   \\
$=$ & nil                                   & \{\emph{pfx0}\}                                  \\
\end{tabular}
\end{center}

That takes care of P(0). Figure~\ref{pfx-induc} (page \pageref{pfx-induc}) displays a proof of P($n$) $\rightarrow$ P($n+1$).

\begin{figure}
\begin{center}
\addtolength{\tabcolsep}{-5pt}
%\setlength{\tabcolsep}{1pt}
\begin{tabular}{llll}
~~~~(prefix &(len    &[$x_1$ $x_2$ \dots $x_{n+1}$])             &\\
            &(append &[$x_1$ $x_2$ \dots $x_{n+1}$] $ys$))       &\\
$=$ (prefix &(len    &(cons $x_1$ [$x_2$ $x_3$ \dots $x_{n+1}$]))&\{\emph{cons}\} (page \pageref{first-rest-cons})\\
            &(append &(cons $x_1$ [$x_2$ $x_3$ \dots $x_{n+1}$]) $ys$))&\\
$=$	(prefix &(+ 1    &(len [$x_2$ $x_3$ \dots $x_{n+1}$]))       &\{\emph{len1}\} (page \pageref{len-equations})\\
            &(cons   &$x_1$ (append [$x_2$ $x_3$ \dots $x_{n+1}$] $ys$)))&\{\emph{app1}\} (page \pageref{append-equations})\\
$=$ (cons   &(first  &(cons $x_1$ [$x_2$ $x_3$ \dots $x_{n+1}$]))&\\
            &(prefix &(- (+ 1 (len [$x_2$ $x_3$ \dots $x_{n+1}$])) 1)&\{\emph{pfx1}\}\\
            &        &(rest (cons $x_1$ (append [$x_2$ $x_3$ \dots $x_{n+1}$] $ys$)))))&\\
$=$ (cons   &$x_1$   &                                           &\{\emph{fst}\} (page \pageref{first-rest-cons})\\
            &(prefix &(len [$x_2$ $x_3$ \dots $x_{n+1}$])        &\{\emph{arithmetic}\}\\
            &        &(append [$x_2$ $x_3$ \dots $x_{n+1}$] $ys$)))& \{\emph{rst}\} (page \pageref{first-rest-cons})\\
$=$ (cons   &$x_1$   &                                           &\\
            &[$x_2$ ~ $x_3$ &\dots ~~ $x_{n+1}$] )               &\{P($n$)\} \\
$=$ [$x_1$ $x_2$ & \dots~$x_{n+1}$]                             &&\{\emph{cons}\} (page \pageref{first-rest-cons}) \\
\end{tabular}
\addtolength{\tabcolsep}{5pt}
~~\\
\vspace{2mm}
P($n+1$) $\equiv$ (prefix (len [$x_1$ $x_2$ \dots $x_{n+1}$]) (append [$x_1$ $x_2$ \dots $x_{n+1}$] $ys$)) $=$ [$x_1$ $x_2$ \dots $x_{n+1}$]
\end{center}
\caption{Proof: $\forall n.$ P($n$) $\rightarrow$ P($n+1$)}
\label{pfx-induc}
\end{figure}

%  COMMENT 12-10-17 trying to fix it to look like the others
%  Rex: This following indentation isn't perfect, but it's close.  I haven't figured out how to remove the vertical space before the tabbing, though I can probably hack it....
%      COMMENT BY REX: Looks too strung out in print, better to put citations on same line as new formula, I think.
%                      but I'm afraid to tamper with it.
%OLD WAY FOLLOWS
%\begin{center}
%	\setlength{\topsep}{0pt}
%	\setlength{\partopsep}{0pt}
%\begin{tabular} {lp{3in}p{1.5in}}
%    & \begin{tabbing}
%			(prefix \=(len [$x_1$ $x_2$ \dots $x_{n+1}$]) \\
%         	        \>(append [$x_1$ $x_2$ \dots $x_{n+1}$] $ys$))
%		\end{tabbing}
%	& \\
%$=$ & \begin{tabbing}
%		(prefix \=(len (cons $x_1$ [$x_2$ \dots $x_{n+1}$])) \\
%                \>(append (cons $x_1$ [$x_2$ \dots $x_{n+1}$]) $ys$))
%		\end{tabbing}
%	& \{\emph{cons}\} (page \pageref{first-rest-cons}) \\
%$=$ & \begin{tabbing}
%			(prefix \=(+ 1 (len [$x_2$ \dots $x_{n+1}$])) \\
%                    \>(cons $x_1$ (append [$x_2$ \dots $x_{n+1}$] $ys$)))
%		\end{tabbing}
%    & \{\emph{len1}\} (page \pageref{len-equations}) \hfill\break
%      \{\emph{app1}\} (page \pageref{append-equations})    \\
%
%$=$ & \begin{tabbing}
%		(cons \=(first (cons $x_1$ [$x_2$ \dots $x_{n+1}$])) \\
%			  \>(prefix \=(- (+ 1 (len [$x_2$ \dots $x_{n+1}$])) 1) \\
%			  \>        \>(rest (cons $x_1$ (append [$x_2$ \dots $x_{n+1}$] $ys$)))))
%		\end{tabbing}
%	& \{\emph{pfx1}\} \\
%$=$ & \begin{tabbing}
%		(cons \=$x_1$ \\
%			  \>(prefix \=(len [$x_2$ \dots $x_{n+1}$]) \\
%			  \>        \>(append [$x_2$ \dots $x_{n+1}$] $ys$)))
%		\end{tabbing}
%	& \{\emph{fst}\} (page \pageref{first-rest-cons}) \hfill\break
%	  \{\emph{arithmetic}\} \hfill\break
%	  \{\emph{rst}\} (page \pageref{first-rest-cons}) \\
%$=$ & \begin{tabbing}
%		(cons \=$x_1$ \\
%			  \>[$x_2$ \dots $x_{n+1}$] )
%		\end{tabbing}
%	& \{P($n$)\} \\
%$=$ & [$x_1$ $x_2$ \dots $x_{n+1}$] & \{\emph{cons}\} (page \pageref{first-rest-cons}) \\
%\end{tabular}
%\end{center}
%\caption{Proof: $\forall n.$ P($n$) $\rightarrow$ P($n+1$)}
%\label{pfx-induc}
%\end{figure}

At this point we know three important facts about the append operator:
\begin{quote}
\begin{itemize}
\item additive length theorem: (len (append $xs$ $ys$)) = (+ (len $xs$) (len $ys$))
\index{theorem, by name!\{append-suffix\}}
\index{theorem, by name!\{append-prefix\}}\index{append!prefix theorem}
\label{app-pfx-thm}
\item append-prefix theorem: (prefix (len $xs$) (append $xs$ $ys$)) = $xs$
\item append-suffix theorem: (nthcdr (len $xs$) (append $xs$ $ys$)) = $ys$
\end{itemize}
\end{quote}

Together, these theorems provide some assurance that append does what we
would expect for a concatenation operator.
We could think of them as
\index{property!correctness}\index{correctness property}correctness properties
for append.
Of course the append operator has
an infinite variety of other properties, too.
Their relative importance depends on how we are using the operation.
A property that is sometimes important to know is that concatenation is associative,
like addition and multiplication in numeric algebra
(Figure~\ref{fig-02-01}, page \pageref{fig-02-01}).
That is, if there are three lists to be concatenated,
you could concatenate the first list with the concatenation of the last two.
Or, you could concatenate the first two, then append the third list at the end.

\begin{samepage}
\index{theorem, by name!\{app-assoc\}}
\label{app-assoc}
\begin{center}
Theorem \{\emph{app-assoc}\} (append $xs$ (append $ys$ $zs$)) = (append (append $xs$ $ys$) $zs$)
\end{center}
\end{samepage}

The associative property of append can be proved by mathematical induction,
starting from the following predicate with the natural numbers as its
universe of discourse.
Then the goal would be to prove that the formula $\forall$$n$.A($n$)) is true.
We leave the proof as an exercise.

\begin{samepage}
\begin{center}
A($n$) $\equiv$ (append [$x_1$ $x_2$ \dots $x_n$] (append $ys$ $zs$)) $=$ (append (append [$x_1$ $x_2$ \dots $x_n$] $ys$) $zs$)
\end{center}
\end{samepage}

\begin{ExerciseList}

\Exercise Prove the \{\emph{app-assoc}\} theorem (page \pageref{app-assoc}).

\Exercise Prove $\forall n.$((cdr [$x_1$ $x_2$ \dots $x_n$] ) $=$ (nthcdr 1 [$x_1$ $x_2$ \dots $x_n$])).

%\todo{COMMENT ONLY, NO TODO
%Reviewer 2 points out that Ch4 talks about ACL2 programs and even about
%defun (in the following exercise), but does not provide a proper explanation.
%Ch5 then more-or-less assumes the reader already knows about defun.
%Also, Ch3 is already talking about testing ACL2 programs, and
%has a test of the reciprocals program, r, without a defun for r.
%This needs to be fixed.
%One way to handle it would be to add a section to Ch3 to explain defun.
%The intro material can be moved from Ch5,
%and this exercise or something like it could
%provide an example in this chapter (Ch4) for reasoning by induction
%with a defined, rather than intrinsic, operator.
%Update (Rex 10Sep2017): added the defun section and replace r(n).
%Plan to move and expand mechanized logic section and halting problem to chapter after ch04 (ch04a.tex, I guess)
%UPDATE 12/10/17: Halting problem is last section of ch04mechlogic.
%}
\Exercise Suppose the operator rep is defined as follows.
\index{operator, by name!rep (list of duplicates)}
\seeonlyindex{rep}{operator}
\index{equation, by name!\{rep0\}, \{rep1\}}
\label{rep-equations}
\begin{Verbatim}
(defun rep (n x)
  (if (posp n)
      (cons x (rep (- n 1) x))   ; {rep1}
      nil))                      ; {rep0}
\end{Verbatim}
Prove the following theorem \{\emph{rep-len}\}.
In the theorem, $n$ can be any natural number and $x$ can be any entity.
\begin{samepage}
\label{rep-len}
\index{theorem, by name!\{rep-len\}}
\begin{center}
Theorem \{\emph{rep-len}\} \\
(len (rep n x)) = n
\end{center}
\end{samepage}

\Exercise Assume the following axioms \{\emph{mem0}\} and \{\emph{mem1}\} are true.
\begin{samepage}
\label{member-equal-equations}\index{axiom!member-equal}\index{equation!member-equal}
\seeonlyindex{member-equal}{predicate}\index{operator, by name!member-equal (\emph{see} predicate)}
\index{predicate, by name!member-equal (element of list)}
\index{axiom, by name!\{mem0\}, \{mem1\}}\index{equation, by name!\{mem0\}, \{mem1\}}
\begin{center}
Axioms \{\emph{member-equal}\} \\
\begin{tabular}{ll}
(member-equal y (cons $x$ $xs$)) = (equal $y$ $x$) $\vee$ (member-equal $y$ $xs$)) & \{\emph{mem1}\} \\
(member-equal y nil) = nil                                                         & \{\emph{mem0}\} \\
\end{tabular}
\end{center}
\end{samepage}
Prove the following theorem \{\emph{rep-mem}\}.
\begin{samepage}
\label{rep-mem}
\index{theorem, by name!\{rep-mem\}}
\begin{center}
Theorem \{\emph{rep-mem}\} \\
(member-equal $y$ (rep $n$ $x$)) $\rightarrow$ (member-equal y (cons $x$ nil))
\end{center}
\end{samepage}

\Exercise \index{theorem, by name!\{app-nil\}}
Prove Theorem \{app-nil\}: $\forall n.$([$x_1$ $x_2$ \dots $x_{n}$] = (append [$x_1$ $x_2$ \dots $x_{n}$] nil))

\Exercise Prove $\forall n.$((nthcdr (len [$x_1$ $x_2$ \dots $x_n$] ) (append [$x_1$ $x_2$ \dots $x_n$]  nil)) $=$ nil).

\end{ExerciseList}

\todo{COMMENT ONLY, NO TODO
next section will introduce defthm and proofs using the ACL2 mechanized logic
by replaying all of the theorems of this section in ACL2 notation}

%% All references to Dracula taken out (30Aug2017 - rlp)
%% I think we should use Proof Pad for all doublecheck and other interface-to-ACL2 issues.
%% We can explain in an aside, when we first mention Proof Pad,
%%    that ACL2s and emacs are other interfaces,
%%    that ACL2s has its own, extensive, random-test facility,
%%    that it is perfectly reasonable for students to use another interface to ACL2,
%%    that if they use another interface, they will need to interpret our doublecheck examples in, say, ACL2 fashion.
%%\end{comment}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "book"
%%% End:
