\chapter{Mathematical Induction}
\label{ch:mathematical-induction}

\section{Lists as Mathematical Objects}
\label{sec:lists-as-obj}
A \emph{sequence} is an ordered list of elements.
In fact, for our purposes, the terms ``list'' and ``sequence'' are synonyms.
Many things that computers do come down to keeping track of lists,
so lists an important class of mathematical objects.
We will need a formal notation, including an algebra of formulas,
to discuss lists with the level of mathematical precision
required in specifications of computer hardware and software.

Formally, we will write lists as sequences of their elements, separated by spaces,
with square brackets marking the beginning and end of the list.
For example, [8 3 7] denotes the list with first element 8,
second element 3, and third element 7, and
[9 8 3 7] denotes a list with the same elements,
plus an additional element 9 at the beginning.
\label{nil-def}
We use the symbol ``nil'' for the empty list
(that is, the list with no elements).
\label{square-brackets}
We use square brackets rather than round ones in formulas
specifying lists, to avoid confusion with formulas that invoke operators.
For example, [4 7 9] denotes a three-element list,
while (+ 7 9) is a numeric formula representing the value 16.
However, ACL2 does not employ this square-bracket notation.
When it displays the list [4 7 9],
it uses round brackets: (4 7 9).

\begin{aside}
Most of the time, our pencil-and-paper notation for lists
will use square brackets to distinguish lists from computational formulas.
However, ACL2 does not display lists with square brackets.
It uses round parentheses both for lists and for computational formulas.
\caption{Square Bracket Notation for Lists: Pencil-and-Paper Only}
\label{square-bracket-notation}
\end{aside}

The algebra of lists includes some basic operators.
One of them, the list construction operator ``cons''
inserts a new element at the beginning of a list.
Formulas using cons, like all formulas in
the mathematical notation we have been using to discuss software concepts,
are written in prefix form.
So, the formula (cons $x$ $xs$) denotes the list
with the same elements as the list $xs$,
but with an additional element $x$ inserted at the beginning.
If $x$ stands for the number 9,
and $xs$ stands for the list [8 3 7],
then (cons $x$ $xs$) constructs the list [9 8 3 7].

Any list can be constructed by starting from the empty list
and using the construction operator to insert the elements of the list, one by one.
The empty list, nil, comes with the system, no construction needed.
Non-empty lists are constructed using the cons operator.
The formula [8 3 7] is our pencil-and-paper shorthand for (cons 8 (cons 3 (cons 7 nil))).
ACL2 also has a shorthand for nested cons operations.
It was introduced briefly in
Chapter~\ref{ch:software-testing-prefix-notation} (page \pageref{list-op-informal}):
(list 8 3 7) is an ACL2 shorthand for (cons 8 (cons 3 (cons 7 nil))).

\begin{aside}
The three-line variation of the equals sign
indicates that the term on the left stands
for the formula on the right, \emph{by definition}.
\begin{center}
\begin{tabular}{ll}
$term \equiv \dots \emph{some formula} \dots$    &\emph{definition of term} \\
$P(xs, y, ys) \equiv (xs$ $=$ (cons $y$ $ys$)$)$ &$P(xs, y, ys)$ \emph{means} $($xs $=$ (cons $y$ $ys$)$)$  \\
\end{tabular}
\end{center}
\caption{Equal by Definition: $\equiv$}
\label{three-line-equal}
%%note: this aside mostly repeats an aside in ch02 predicates section, on purpose in case they skip that section
\end{aside}

Suppose we take $P(xs, y, ys)$ as shorthand
for the equation $xs$ $=$ (cons $y$ $ys$).
\begin{center}
$P(xs, y, ys) \equiv (xs$ $=$ (cons $y$ $ys$)$)$
\end{center}

Given a particular list $xs$ together with a value $y$,
we can view the equation $P(xs, y, ys)$ as a set of propositions
indexed by the variable $ys$, whose universe of discourse is the set of
lists that can be constructed by ACL2.
In this set of propositions, the one corresponding to
the list $ys$ is the equation that $P(xs, y, ys)$ stands for.
If that equation holds, the value of the proposition $P(xs, y, ys)$ is true.
Otherwise, it's false.
For example, if $xs$ denotes the list [1 2 3]
and $y$ denotes the natural number 1,
then $P(xs, y, ys)$ is $P($[1 2 3], 1, $ys)$
which stands for an equation involving the variable $ys$.
There is one such equation for each different list $ys$.
Taken all together those equations comprise a predicate
whose universe of discourse is ACL2 lists.

The operator ``consp'' checks for non-empty lists.
That is, the formula (consp $xs$) delivers true
if $xs$ is a non-empty list and false otherwise.
The \{\emph{consp}\} axiom
(Figure~\ref{consp-axiom}, page \pageref{consp-axiom})
is formally asserts that all non-empty lists
are constructed with the cons operator.

The formula
$(\exists ys.P($[1 2 3], 1, $ys))$ denotes true
if $ys$ stands for the list [2 3] because that value makes
the equation [1 2 3] $=$ (cons 1 $ys$) valid.
If there were no list that made the equation valid,
the formula $(\exists ys.P($[1 2 3], 1, $ys))$
would denote false.
In this case, $(\exists ys.P($[1 2 3], 1, $ys))$ denotes true
because [2 3] is a list in the universe of discourse
for which the equation holds.

If, on the other hand, $xs$ were the list [1 2 3]
and $y$ were the number 2, there would be no list
$ys$ that would make the equation [1 2 3] $=$ (cons $2$ $ys$) valid
because the list on the left-hand side of the equation
starts with 1 the the one on the right-hand side starts with 2.
So, the formula $(\exists ys.P($[1 2 3], 2, $ys))$
is false.

\begin{figure}
\begin{center}
Axiom \{\emph{consp}\} \\
(consp $xs$) $=$  $(\exists y.(\exists ys.(xs =$ (cons $y$ $ys$)$)))))$
\end{center}
\caption{Non-Empty List Predicate: consp}
\label{consp-axiom}
\end{figure}

Now, let's take a step back.
We can view the formula
($\exists ys.$ ($xs$ $=$ (cons $y$ $ys$)))
as a set of propositions,
one for each object $y$ that ACL2 can represent.
The formula
$(\exists ys.P(xs, y, ys))$ is one way to represent that
set of propositions.
Since any set of propositions is a predicate,
we can view $(\exists ys.P(xs, y, ys))$ as a predicate indexed
by the set of objects $y$ representable in ACL2.

\begin{figure}
\begin{center}
Axiom \{\emph{nlst}\}

[$x_{m}$ \dots $x_{n}$]  \emph{denotes a list with $n - m + 1$ elements} \{\emph{nlst}\} \\
\emph{Note: Denotes the empty list (nil) if $m > n$}
\end{center}
\caption{Numbered List Notation}
\label{numbered-list-interpretation}
\end{figure}

We can convert the predicate $(\exists ys.P(xs, y, ys))$
into a true/false value (that is, convert it to a proposition)
by applying the $\exists$ quantifier again,
but this time with $y$ as the bound variable:
$(\exists y.(\exists ys.P(xs, y, ys)))$.
When $xs$ is a list for which this formula has the value true,
then (consp $xs$) is true.
That is, consp is the ACL2 name for the predicate $(\exists y.(\exists ys.P(xs, y, ys)))$.
The universe of discourse for the predicate consp is the set of lists that ACL2 can represent.
That description of consp is specified in the consp axiom
(Figure~\ref{consp-axiom}, page \pageref{consp-axiom}).
So, (consp $xs$) is a way to write the formula
$(\exists y.(\exists ys.(xs$ $=$ (cons $y$ $ys$)$)))$ in ACL2.

When we know a list $ys$ is non-empty,
we can cite the \{\emph{consp}\} axiom 
to rewrite $ys$ in the form (cons $x$ $xs$)
When we do this, we choose the symbols $x$ and $xs$ carefully
to avoid conflicts with other symbols that appear in the context of the discussion.
The \{\emph{consp}\} axiom refers to cons, so we will need a \{\emph{cons}\} axiom.
Since cons cannot construct an empty list,
the cons axiom will specify that the list cons delivers is not empty,
using the notation [$x_1$ $x_2$ \dots $x_{n+1}$],
where $n$ stands for a natural number.
That list cannot be empty because it has $n+1$ elements, and $n+1$
is at least one when $n$ is a natural number.
Therefore, the list can be constructed by cons.

The construction operator, cons, cannot be the whole story, of course.
To compute with lists, we  need to be able to construct them,
but we also need to be able to take them apart.
There are two basic operators for taking lists apart: ``first'' and ``rest''.
We express the relationship between these operators and
the construction operator in the form of equations,
\{\emph{fst}\} and \{\emph{rst}\}, that we take as axioms
(Figure~\ref{first-rest-cons}, page \pageref{first-rest-cons}).

\begin{figure}
\begin{center}
 Axioms \{\emph{cons}\}, \{\emph{first}\}, and \{\emph{rest}\} \\
\begin{tabular}{ll}
 [$x_1$ $x_2$ \dots $x_{n+1}$] = (cons $x_1$ [$x_2$ \dots $x_{n+1}$]) & \{\emph{cons}\} \\
 (first (cons $x$ $xs$)) = $x$                                        & \{\emph{fst}\}\\
 (rest (cons $x$ $xs$))  = $xs$                                       & \{\emph{rst}\} \\
 (first nil) = nil                                                    & \{\emph{fst0}\}\\
 (rest nil) = nil                                                     & \{\emph{rst0}\}
\end{tabular}
\end{center}
\caption{List Constructor and Deconstructors: cons, first, rest}
\label{first-rest-cons}
\end{figure}

The \{\emph{fst}\} axiom is a formal statement of the fact that
the operator ``first'' delivers the first element from non-empty list.
The \{\emph{rst}\} axiom states that the operator ``rest'' delivers
a list like its operand, but without the first element.
Note that the lists to which the operators first and rest
are applied in the axioms have at least one element
because those lists are constructed by the cons operator.
The axioms \{\emph{fst0}\} and \{\emph{rst0}\}
provide an interpretation of the formulas (first nil) and (rest nil),
when the operand is a list with no elements.

We will use equations like the ones in these axioms in the
same way we used the logic equations in Figure~\ref{fig-02-02}
(page \pageref{fig-02-02}) and the arithmetic equations of
Figure~\ref{fig-02-01} (page \pageref{fig-02-01}).
That is, whenever we see a formula like (first (cons $x$ $xs$)),
no matter what formulas $x$ and $xs$ stand for,
we will be able to cite equation \{\emph{fst}\} to replace
(first (cons $x$ $xs$)) by the simpler formula $x$.
Vice versa, we can also cite equation \{\emph{fst}\}
to replace any formula $x$ by the more complicated formula
(first (cons $x$ $xs$)).
Furthermore, the formula $xs$ in the replacement can be
any formula we care to make up, as long as it is grammatically correct.

Similarly, we can cite the equation \{\emph{rst}\} to justify
replacing the formula (rest (cons $x$ $xs$)) by $xs$
and vice versa, regardless of what formulas the symbols $x$ and $xs$ stand for.
In other words, these are ordinary algebraic equations.
The only new factors are
(1)~the kind of mathematical object they denote, and
(2)~the syntactic quirk of prefix notation, instead of the more familiar infix notation.

All properties of lists, as mathematical objects,
derive from the \{cons\}, \{fst\}, and \{rst\} axioms.
For example, there is an operator called ``len''
that delivers the number of elements in a list.\footnote{The
len operator was discussed informally in Chapter~\ref{ch:software-testing-prefix-notation}
(page \pageref{len-op-informal}).}
We can use check-expect to test len in some specific cases.

\begin{Verbatim}
(check-expect (len (cons 8 (cons 3 (cons 7 nil)))) 3)
(check-expect (len nil) 0)
\end{Verbatim}

We can use the doublecheck facility for more general tests.
For example, we would expect that the number of elements
in a list constructed by the cons operation to be
one more than the number of elements in its second operand.
The following property tests this expectation.

\begin{Verbatim}
(defproperty len-cons-test
  (x  :value (random-natural)
   xs :value (random-list-of (random-natural)))
  (= (len (cons x xs))
     (+ 1 (len xs))))
\end{Verbatim}

By the same token, we expect that a list would
have one more element than it would with
its first element removed: (len $xs$) $=$ $1 +$ (len (rest $xs$)).
However, that is true only if the list $xs$
has some elements. It would not be true if $xs$ were nil.
What we want to test is an implication:
(consp $xs$) $\rightarrow$ ((len $xs$) $=$ $1 +$ (len (rest $xs$))).
The ACL2 name for the implication operator is ``implies'',
and we can use that operator to formulate a test that
will check the length of (rest $xs$).

\begin{Verbatim}
(defproperty len-rest-test
  (xs :value (random-list-of (random-natural)))
  (implies (consp xs)
           (= (len xs)
              (+ 1 (len (rest xs))))))
\end{Verbatim}

The equation in the len-rest-test can serve
as an axiom for the len operator in the case
when its operand is a non-empty list.
The axiom for the empty case is simpler.
Figure~\ref{fig:len-axioms} states these two axioms for
the len operator.

\begin{figure}
\begin{center}
Axioms \{\emph{len}\} \\
\begin{tabular}{ll}
(len nil) = 0                            & \{\emph{len0}\} \\
(len (cons $x$ $xs$)) = (+ 1 (len $xs$)) & \{\emph{len1}\}
\end{tabular}
\end{center}
\caption{Length of List: len}
\label{len-equations}
\label{fig:len-axioms}
\end{figure}

We expect the len operator to deliver a natural number,
regardless of the value of its operand.
For the record, we state this property as a theorem.
Later, you will have an opportunity to derive
this theorem from the \{\emph{len}\} axioms.
The theorem refers to the natp operator,
which you have seen before (page \pageref{natp-op}).
It delivers true if its operand is a natural number and false otherwise.
\begin{samepage}
\label{len-nat-thm}
\begin{center}
Theorem \{\emph{len-nat}\} $\forall xs.$(natp (len $xs$))
\end{center}
\end{samepage}

A related fact is that the the length of a non-empty list is strictly positive.
One way to state that fact is to observe that the formula (consp $xs$) is true
if ($>$ (len $xs$) 0) and vice-versa. %(\verb+>+ (len $xs$) 0). %\textit{using math mode instead of \verb}
%In the notation from Chapter~\ref{ch:Boolean-Formulas}:  %\textit{never covered the equiv op}
%(consp $xs$)$\leftrightarrow$(\verb+>+ (len $xs$) 0).
This theorem, too, can be derived from the axioms for
len, consp, and cons. For the moment,
we state the theorem without proof.
\begin{samepage}
\label{consp-len-thm}
\begin{center}
Theorem \{\emph{consp}$=$len$>$0\} $\forall xs.($(consp $xs$) $=$ ($>$ (len $xs$) 0)$)$
\end{center}
\end{samepage}

\begin{aside}
If we want to specify the list [1 2 3 4] in an ACL2 formula,
rather than in a paper-and-pencil formula,
we can, of course, use the cons operator to construct it,
(cons 1 (cons 2 (cons 3 (cons 4 nil)))),
or we can use the list operator (page \pageref{list-op-informal}) to write it more compactly,
(list 1 2 3 4).
However, the single-quote trick provides an even less bulky ACL2 formula for lists
whose elements are numbers (or literals denoting other ACL2 constants).
The formula
'(1 2 3 4) has the same meaning as (list 1 2 3 4).
Normally, ACL2 interprets the first symbol afer a left-parenthesis
as the name of an operator.
However, the single-quote mark suppresses that interpretation and
delivers a list made up of the elements in the parentheses.
Without the single-quote mark,
the formula would make no sense because 1 is not the name of an operator.
\caption{Single-quote Shorthand for Lists}
\label{acl2-single-quote}
\end{aside}

\section{Mathematical Induction}
\label{sec:induction}
The cons, first, and rest operators form the basis for computing with lists,
but there are lots of other operators for lists.
The operator ``append'', previously described informally with check-expect tests
(page \pageref{append-op-informal}), concatenates two lists, as illustrated
in the following check-expect tests,
which use the single-quote notation (Aside~\ref{acl2-single-quote}, page \pageref{acl2-single-quote})
to make them more compact.

\begin{Verbatim}
(check-expect (append '(1 2 3 4) '(5 6 7)) '(1 2 3 4 5 6 7))
(check-expect (append '(1 2 3 4 5) nil) '(1 2 3 4 5))
\end{Verbatim}

One way to provide a more formal definition of append is
to use a schematic for lists
that labels the elements of the list as subscripted variables.
The number of subscripts in the sequence implicitly reveals the number of elements in the list.
\label{list-schematic} In the following list schematics,
the $x$ list has $m$ elements, the $y$ list has $n$ elements,
and the concatenated list has $m+n$ elements.
\begin{samepage}
\begin{center}
(append [$x_1$ $x_2$ \dots $x_m$] [$y_1$ $y_2$ \dots $y_n$]) = [$x_1$ $x_2$ \dots $x_m$ $y_1$ $y_2$ \dots $y_n$]
\end{center}
\end{samepage}

We can use doublecheck to test some properties of append.
If we concatenate the empty list nil with a list $ys$,
we expect to get $ys$ as a result: (append nil $ys$) = $ys$.
If we concatenate a non-empty list $xs$ with a list $ys$,
we expect the first element of the result to be the same as
the first element of $xs$.
Furthermore, we expect the rest of the elements to be
the elements of the list we would get if we concatenated
a list made up of the other elements of $xs$, that is (rest $xs$),
with $ys$.

We would like to express this idea formally,
and to do so it will be helpful to use a special ACL2 operator
called ``if''
that selects one of two formulas based on a true/false
value specified in its first operand.
Its second operand is the formula it selects if
its first operand is true (that is, not nil).
If its first operand is false (that is, nil),
it selects its third operand.

\begin{figure}
\begin{center}
Axioms \{\emph{if}\} \\
\begin{tabular}{ll}
(if $p$ $x$ $y$) = $x$, \emph{if} $p$ $\neq$ nil  & \{\emph{if-true}\}  \\
(if $p$ $x$ $y$) = $y$, \emph{if} $p$ $=$ nil     & \{\emph{if-false}\} \\
\end{tabular}
\end{center}
\caption{Formula Selector: if}
\label{fig:if-axioms}
\end{figure}

Consider the value of (append $xs$ $ys$).
If the first operand is not nil (that is, if (consp $xs$) is true),
we use a formula that appends $xs$ without its first element: (append (rest $xs$) $ys$).
If the first operand is nil, append can simply delivers its second operand.
So, we have two formulas for append, and we can use the consp operator,
in conjunction with the ``if'' operator
to write another doublecheck test for append.

\begin{samepage}
\begin{Verbatim}
(defproperty append-test
  (xs :value (random-list-of (random-natural))
   ys :value (random-list-of (random-natural)))
  (equal (append xs ys)
         (if (consp xs)
             (cons (first xs)
                   (append (rest xs) ys))
             ys)))
\end{Verbatim}
\end{samepage}

\begin{aside}
Why does the property say (equal (append $xs$ $ys$) \dots)
instead of (= (append $xs$ $ys$) \dots)?
The ``='' operator
is restricted to numbers. The operator ``equal'' can check
for equality between other kinds of objects.
You can always use the operator equal,
but you can only use the operator ``='' when both operands are numbers.
Why bother with ``='', when its use is so limited?
We might say it makes the formula look more like an equation,
but that's not really much of an excuse,
since we have already had to conform to prefix notation
instead of the more familiar infix notation.
So, feel free to use the ``equal'' operator all the time if you want to.
%We will be using ``='' when we can and hope it doesn't put too much of an extra burden on you.
\caption{``equal'' vs ``=''}
\label{equal}
\end{aside}

The append-test property might not be the first test you would think of,
but if the test failed to pass,
you would for sure know something was wrong with the append operator.
In fact the property is so plainly correct,
we are going to state it in the form of equations that we accept as axioms
(Figure~\ref{append-equations}, page \pageref{append-equations}).
Like the \{\emph{len}\} theorem, there are two \{\emph{append}\} equations
(Figure~\ref{append-equations}, page \pageref{append-equations}),
and they specify the meaning of the append operation in different situations.
One of them specifies the meaning when the first operand is the empty list,
the other when the list has one or more elements.

\begin{figure}
\begin{center}
Axioms: \{\emph{append}\} \\
\begin{tabular}{ll}
(append (cons $x$ $xs$) $ys$) = (cons $x$ (append $xs$ $ys$)) & \{\emph{app1}\} \\
(append a   $ys$) =  $ys$                                     & \{\emph{app0}\} \\
~~~~\emph{Note: Cite \{\emph{app0}\} only if \{\emph{app1}\} doesn't match.}&\\
\end{tabular}
\end{center}
\caption{List Concatenation: append}
\label{append-equations}
\end{figure}
\todo{These axioms allow non-true-lists as first operand. However, when guards are in effect,
      ACL2 chokes if first operand isn't a true list. 
      When guards are disabled (append 1 (list 2 3)) = (list 2 3)
      I don't want to say anything about guards, but students may see error messages
      that talk about guards. Not sure how to handle this.}

These equations about the append operation are simple enough,
but it turns out that lots of other properties of the
append operation can be derived from them.
For example, we can prove that the length of
the concatenation of two lists is the sum of the lengths of the lists,
which is a property we wrote a doublecheck test for in
Chapter~\ref{ch:software-testing-prefix-notation} (page \pageref{additive-lengths-test}).
We call this theorem the \emph{additive law of concatenation}.
Let's see how a proof of this law could be carried out.

First, let's break it down into a some special cases.
We will use L($n$) as shorthand for the proposition that
(len (append ($x_1$ $x_2$ \dots $x_n$) $ys$))
is the sum of (len ($x_1$ $x_2$ \dots $x_n$)) and (len $ys$).
That makes L a predicate whose universe of discourse is
the natural numbers.

\label{additive-concat-law-predicate}
\begin{center}
% old prefix notation: \begin{tabbing}
% old prefix notation: L($n$) $\equiv$ (= \=(len (append [$x_1$ $x_2$ \dots $x_n$] $ys$))  \\
% old prefix notation:                   \>(+ (len [$x_1$ $x_2$ \dots $x_n$]) (len $ys$)))
% old prefix notation: \end{tabbing}
L($n$) $\equiv$ (len (append [$x_1$ $x_2$ \dots $x_n$] $ys$)) $=$ (+ (len [$x_1$ $x_2$ \dots $x_n$]) (len $ys$))
\end{center}

For the first few values of $n$, L($n$) would stand for the following equations.
\begin{quote}
L(0) $\equiv$ (len (append nil $ys$)) $=$ (+ (len nil) (len $ys$)) \\
L(1) $\equiv$ (len (append [$x_1$] $ys$)) $=$ (+ (len [$x_1$]) (len $ys$)) \\
L(2) $\equiv$ (len (append [$x_1$ $x_2$] $ys$)) $=$ (+ (len [$x_1$ $x_2$]) (len $ys$)) \\
L(3) $\equiv$ (len (append [$x_1$ $x_2$ $x_3$] $ys$)) $=$ (+ (len [$x_1$ $x_2$ $x_3$]) (len $ys$)) \\
L(4) $\equiv$ (len (append [$x_1$ $x_2$ $x_3$ $x_4$] $ys$)) $=$ (+ (len [$x_1$ $x_2$ $x_3$ $x_4$]) (len $ys$))
\end{quote}

\todo{COMMENT ONLY, NO TODO
in case we want to go back to the prefix =
\begin{center}
\begin{tabular}{llll}
L(0) & $\equiv$ & (= &(len (append nil $ys$)) \\
     &          &    &(+ (len nil) (len $ys$))) \\
L(1) & $\equiv$ & (= &(len (append [$x_1$] $ys$)) \\
     &          &    &(+ (len [$x_1$]) (len $ys$))) \\
L(2) & $\equiv$ & (= &(len (append [$x_1$ $x_2$] $ys$))\\
	 &          &    &(+ (len [$x_1$ $x_2$]) (len $ys$))) \\
L(3) & $\equiv$ & (= &(len (append [$x_1$ $x_2$ $x_3$] $ys$)) \\
     &          &    &(+ (len [$x_1$ $x_2$ $x_3$]) (len $ys$))) \\
L(4) & $\equiv$ & (= &(len (append [$x_1$ $x_2$ $x_3$ $x_4$] $ys$)) \\
     &          &    &(+ (len [$x_1$ $x_2$ $x_3$ $x_4$]) (len $ys$)))
\end{tabular}
\end{center}
END OF TODO COMMENT}

We can derive L(0) from the \{\emph{append}\} and \{\emph{len}\} axioms as follows,
starting from the first operand in the equation that L(0) stands for
(which would be the left-hand side of the equation
if it were written in the conventional, infix, way rather than in prefix form),
and ending with the second operand (the right-hand side, conventionally).

\begin{center}
\emph{Proof of L(0), citing axioms} \\
\begin{tabular}{lll}
    & (len (append nil $ys$))  &                                                \\
$=$ & (len $ys$)               & \{\emph{app0}\}     (page \pageref{append-equations})\\
$=$ & (+ (len $ys$) 0)         & \{$+$ identity\}    (page \pageref{fig-02-01}) \\
$=$ & (+ 0 (len $ys$))         & \{$+$ commutative\} (page \pageref{fig-02-01}) \\
$=$ & (+ (len nil) (len $ys$)) & \{\emph{len0}\}     (page \pageref{len-equations})
\end{tabular}
\end{center}

That takes care of L(0). How about L(1)?

\begin{center}
\emph{Proof of L(1), citing axioms and proven equations} \\
\begin{tabular}{lll}
    & (len (append [$x_1$] $ys$))           &                     \\
$=$ & (len (append (cons $x_1$ nil) $ys$)   & \{\emph{cons}\} (page \pageref{first-rest-cons}) \\
$=$ & (len (cons $x_1$ (append nil $ys$)))  & \{\emph{app1}\}     \\
$=$ & (+ 1 (len (append nil $ys$)))         & \{\emph{len1}\}     \\
$=$ & (+ 1 (+ (len nil) (len $ys$)))        & \{L(0)\} ~~~~\emph{Note: L(0) already proved}\\
$=$ & (+ (+ 1 (len nil)) (len $ys$))        & \{$+$ associative\} (page \pageref{fig-02-01}) \\
$=$ & (+ (len (cons $x_1$ nil)) (len $ys$)) & \{\emph{len1}\}     \\
$=$ & (+ (len [$x_1$] (len $ys$))           & \{\emph{cons}\}     \\
\end{tabular}
\end{center}

That was a little harder. Will proving L(2) be still harder? Let's try it.

\begin{center}
\emph{Proof of L(2), citing axioms and proven equations}\\
\begin{tabular}{lll}
    & (len (append [$x_1$ $x_2$] $ys$))         &                     \\
$=$ & (len (append (cons $x_1$ [$x_2$]) $ys$))  & \{\emph{cons}\}     \\
$=$ & (len (cons $x_1$ (append [$x_2$] $ys$)))  & \{\emph{app1}\}     \\
$=$ & (+ 1 (len (append [$x_2$] $ys$)))         & \{\emph{len1}\}     \\
$=$ & (+ 1 (+ (len [$x_2$]) (len $ys$)))        & \{L(1)\} ~~~~\emph{Note: L(1) already proved}\\
$=$ & (+ (+ 1 (len [$x_2$])) (len $ys$))        & \{$+$ associative\} \\
$=$ & (+ (len (cons $x_1$ [$x_2$])) (len $ys$)) & \{\emph{len1}\}     \\
$=$ & (+ (len [$x_1$ $x_2$]) (len $ys$))        & \{\emph{cons}\}     \\
\end{tabular}
\end{center}

Fortunately, proving L(2) was no harder than proving L(1).
In fact the two proofs cite exactly the same equations all the way through,
except in one place.
Where the proof of L(1) cited the equation L(0),
the proof of L(2) cited the equation L(1).
Maybe the proof of L(3) will work the same way.

\begin{center}
\emph{Proof of L(3), citing axioms and proven equations}\\
\begin{tabular}{lll}
    & (len (append [$x_1$ $x_2$ $x_3$] $ys$))         &                     \\
$=$ & (len (append (cons $x_1$ [$x_2$ $x_3$]) $ys$))  & \{\emph{cons}\}     \\
$=$ & (len (cons $x_1$ (append [$x_2$ $x_3$] $ys$)))  & \{\emph{app1}\}     \\
$=$ & (+ 1 (len (append [$x_2$ $x_3$] $ys$)))         & \{\emph{len1}\}     \\
$=$ & (+ 1 (+ (len [$x_2$ $x_3$]) (len $ys$)))        & \{L(2)\} ~~~~\emph{Note: L(2) already proved}\\
$=$ & (+ (+ 1 (len [$x_2$ $x_3$])) (len $ys$))        & \{$+$ associative\} \\
$=$ & (+ (len (cons $x_1$ [$x_2$ $x_3$])) (len $ys$)) & \{\emph{len1}\}     \\
$=$ & (+ (len [$x_1$ $x_2$ $x_3$]) (len $ys$))        & \{\emph{cons}\}     \\
\end{tabular}
\end{center}

\label{induction-rationale}
By now, it's easy to see how to derive L(4) from L(3),
then L(5) from L(4), and so on.
If you had the time and patience, you could prove L(100), L(1000), or even L(1000000)
by following the established pattern.
It would not be hard to write a program to print out the proof of L($n$),
given any natural number $n$.
Since we know how to prove L($n$) for any natural number $n$,
it seems fair to say that we know all those equations are true.
That is, we think we know that the formula ($\forall$$n$.L($n$)) is true.
However, to prove that formula in a formal sense,
we need a rule of inference that allows us to make conclusions
from patterns like those we observed in proving L(1), L(2), and so on.
That rule of inference is known as \emph{mathematical induction}.

Mathematical induction provides a way to prove that
formulas like ($\forall$$n$.P($n$)) are true
when P is a predicate whose universe of discourse is the natural numbers.
If for each natural number $n$, P($n$) stands for a proposition,
then mathematical induction is an inference rule that may be useful
in a proof that ($\forall$$n$.P($n$)) true.
That is not to say that such a proof can always be constructed.
It's just that mathematical induction might provide some help in the process.
The inverse is also true: mathematical induction cannot help
if the universe of discourse is not the natural numbers.\footnote{Mathematical
induction is not the only form
of proof by induction, but all the other forms
(other than transfinite induction, which is a different animal)
can be contorted into proofs by mathematical induction.
We will stick with classical, mathematical induction
and leave the variations for another time.
They are easy to learn for people who know mathematical induction well.}

The rule goes as follows: one can infer the truth of ($\forall$$n$.P($n$))
from proofs of two other propositions.
Those two propositions are
\begin{quote}
\begin{enumerate}
\item P(0), which is known as the ``base case''), and
\item ($\forall$$n$.(P($n$)$\rightarrow$P($n+1$))), which is known as the ``inductive case''.
\end{enumerate}
\end{quote}
It's a very good deal if you think about it.
A direct proof of ($\forall$$n$.P($n$)) would require a proof of proposition P($n$)
for each value of $n$ (0, 1, 2, \dots).
But, in a proof by induction, the only proposition that needs to be proved on its own is P(0).
In the proof any of the other propositions,
you are allowed to cite the previous one in the sequence as a justification for any step in the proof.

The reason you can assume that P($n$) is true in the proof of P($n+1$)
is because the goal is to prove that the formula
P($n$)$\rightarrow$P($n+1$) has the value true.
We know from the truth table of the implication operator
(page \pageref{implication-truth-table}) that the implication
P($n$)$\rightarrow$P($n+1$) is true when P($n$) is false,
regardless of the value of P($n+1$), so we can ignore the case when P($n$) is false.
The upshot is that we only need to verify that P($n+1$) is true when P($n$) is true.
That is, we can assume when proving P($n+1$) that we already know that P($n$) is true.
\begin{figure}
\begin{center}
\begin{tabular}{ll}
Prove P(0)                                         &\emph{base case}\\
 - - - - - - - - - - - - - - - - - - - - -         &\\
Prove ($\forall$$n$.(P($n$)$\rightarrow$P($n+1$))) &\emph{inductive case}\\
-------------------------------------\{induction\} &\\
Infer ($\forall$$n$.P($n$))                        &\\
\end{tabular}
\end{center}
\caption{Mathematical Induction: a Rule of Inference}
\label{fig-04-01}
\label{induction-rule}
\end{figure}

That means that you can cite P($n$) to justify any step in the proof of P($n+1$).
P($n$), which is known as the \emph{induction hypothesis}, gives you a leg up in the proof of P($n+1$).
\label{induction-hyp-def}
Now, let's apply mathematical induction to prove
the additive law of concatenation.
Here, the predicate that we will apply the method to is L (page \pageref{additive-concat-law-predicate}).

\label{len-additive-thm}
We have already proved L(0), so we have already completed one of the
two proofs required to cite the mathematical induction inference rule.
All that is left is to prove ($\forall$$n$.(L($n$)$\rightarrow$L($n+1$))).
That is, we have to derive L($n+1$) from L($n$) for an arbitrary natural number $n$.
Fortunately, we know how to do this. Just copy the derivation of,
say L(3) from L(2), but start with an append formula in which the first operand
is a list with $n+1$ elements, and cite L($n$) where we would have cited L(3).

\begin{center}
\emph{Proof of L(n+1), citing axioms, proven equations, and L(n): L(n) $\rightarrow$ L(n+1)}\\
\begin{tabular}{lll}
    & (len (append [$x_1$ $x_2$ \dots $x_{n+1}$] $ys$))         &                     \\
$=$ & (len (append (cons $x_1$ [$x_2$ \dots $x_{n+1}$]) $ys$))  & \{\emph{cons}\}     \\
$=$ & (len (cons $x_1$ (append [$x_2$ \dots $x_{n+1}$] $ys$)))  & \{\emph{app1}\}     \\
$=$ & (+ 1 (len (append [$x_2$ \dots $x_{n+1}$] $ys$)))         & \{\emph{len1}\}     \\
$=$ & (+ 1 (+ (len [$x_2$ \dots $x_{n+1}$]) (len $ys$)))        & \{L($n$)\}          \\
$=$ & (+ (+ 1 (len [$x_2$ \dots $x_{n+1}$])) (len $ys$))        & \{$+$ associative\} \\
$=$ & (+ (len (cons $x_1$ [$x_2$ \dots $x_{n+1}$])) (len $ys$)) & \{\emph{len1}\}     \\
$=$ & (+ (len [$x_1$ $x_2$ \dots $x_{n+1}$]) (len $ys$))        & \{\emph{cons}\}     \\
\end{tabular}
\end{center}

This completes the mathematical induction proving the
additive law of concatenation.
\begin{samepage}
\begin{center}
\label{additive-law-concatenation}
Theorem \{\emph{additive law of concatenation}\} \\
$\forall$$n$.((len (append [$x_1$ $x_2$ \dots $x_n$] $ys$))
= (+ (len [$x_1$ $x_2$ \dots $x_n$]) (len $ys$)))
\end{center}
\end{samepage}

An important point to notice in this proof is that
we could not cite the \{\emph{cons}\} equation to replace [$x_2$ \dots $x_{n+1}$]
with (cons $x_2$ [$x_3$ \dots $x_{n+1}$]).
The reason we could not do this is that we are trying to derive
L($n+1$) from L($n$) without making any assumptions about $n$
other than the fact that it is a natural number.
Since zero is a natural number, the list [$x_2$ \dots $x_{n+1}$]
could be empty, and the cons operation cannot deliver an empty list as its value.

In the next section, we will prove some properties of append
that confirm its correctness with respect to a specification in terms of other operators.
These properties, and in fact all properties of the append operator,
can be derived from the append axioms (Figure~\ref{append-equations}, page \pageref{append-equations}).
Those axioms state properties of the append operation in two separate cases:
(1)~when the first operand is the empty list (the \{\emph{app0}\} equation), and
(2)~when the first operand is a non-empty list (the \{\emph{app1}\} equation).
When the first operand is the empty list,
the result must be the second operand, no matter what it is.
When the first operand is not empty, it must have a first element.
That element must also be the first element of the result.
The other elements of the result are the ones you would get
if you appended the rest of the first operand with the second operand.

Both of these properties are so straightforward and easy to believe
that we would probably be willing to accept them as axioms with no proof at all,
but it might come as a surprise that all of the other properties
of the append operation can be derived from
the two simple properties \{\emph{app0}\} and \{\emph{app1}\}.
That is the power of mathematical induction.
The two equations of the append axioms
amount to an inductive definition of the append operator.

An inductive definition is circular in the sense
that some of the equations in the definition refer
to the operator on both sides of the equation.
Most of the time, we think circular definitions are not useful,
so it may seem surprising that they can be useful in mathematics.
Some aren't, but some are, and you will
gradually learn how to recognize and create useful,
circular (that is, inductive) definitions.

\begin{figure}
\begin{center}
\begin{tabular}{lp{3.5in}}
\emph{Complete} & All possible combinations of operands are covered by at least one equation in the definition. \\
\emph{Consistent} & Combinations of operands covered by two or more equations define the same value for the operation. \\
\emph{Computational} &
\begin{enumerate}
\item \emph{Non-Inductive Equation}: There is at least equation in which
the operator being defined appears on left-hand side only.
\item \emph{Reduced Computation}: Each invocation of the operator being defined that resides on 
            the right-hand side of an inductive equation has operands that
            are closer to the operands on the left-hand side of a non-inductive equation than to
            the operands on the left-hand side of the inductive equation.
\end{enumerate}
\end{tabular}
\end{center}
\caption{The Three C's: a Guide to Inductive Definitions}
\label{fig:inductive-def-keys}
\end{figure}

It turns out that all operators that can be defined in software
have inductive definitions in the style of the equations
of the append axioms (Figure~\ref{append-equations}, page \pageref{append-equations}).
The keys to an inductive definition of an operator are  listed in
Figure~\ref{fig:inductive-def-keys} (page \pageref{fig:inductive-def-keys}).
All of the software we will discuss will take the form of a collection
of inductive definitions of operators.
That makes it possible to use mathematical induction as
the fundamental tool in verifying, to a logical certainty,
properties of that software.

This is of course not the only way to write software.
In fact, most software is not written in terms of inductive definitions.
But, properties of the software written using conventional methods
make
proofs of their properties clumsy, at best, especially in the framework of classical logic.
So, in terms of understanding what computers do and how they do it,
inductive definitions provide solid footing.
That is why we base our discussion on software written
in terms of inductive definitions rather than conventional methods.

\begin{ExerciseList}

\Exercise Prove $\forall xs.$(natp (len $xs$)).
You may cite \{natp0\} and \{natp1\}, defined as follows.
\begin{center}
\begin{tabular}{ll}
(natp $0$)                                            & \{natp0\}\\
$\forall x.$((natp $x$) $\rightarrow$ (natp (+ x 1))) & \{natp1\}\\
\end{tabular}
\end{center}

\Exercise Prove $\forall xs.$((cdr $xs$) $=$ (nthcdr 1 $xs$)).\\
\emph{Note}: You may assume that $\forall xs.((xs$ $=$ nil$) \vee (\exists y.\exists ys.(xs$ $=$ (cons $y$ $ys$)$)))$

\Exercise Assume the following axioms \{\emph{expt0}\} and \{\emph{expt1}\} are true.
\begin{samepage}
\label{expt-equations}
\begin{center}
Axioms \{\emph{expt}\} \\
\begin{tabular}{ll}
(expt $x$ 0) = 1                                & \{\emph{expt0}\} \\
(expt $x$ (+ $n$ 1)) = ($*$ $x$ (expt $x$ $n$)) & \{\emph{expt1}\} \\
\hline
\end{tabular}
\\ $x$ \emph{is a number}
\\ $n$ \emph{is a natural number}
\\ ($*$ $x$ $y$) = $x \times y$
\end{center}
\end{samepage}
Prove the following theorem \{\emph{expt}\}, where $n$ is a natural number and $x$ is a number.
\begin{samepage}
\label{expt-thm}
\begin{center}
Theorem \{\emph{expt}\} \\
(expt $x$ $n$) = $x^n$
\end{center}
\end{samepage}

\end{ExerciseList}

\section{Defun: Defining Operators in ACL2}
\label{sec:defun}

Now, we are going to let you in on a little secret.
The axioms we wrote for the append operator are very
close to a specification of that operator in ACL2
(and most other programming languages, too, although
it is rarely done this way).
There are many other choices we could have made,
but the ACL2 system gives us not just a programming language,
but also a mechanized logic to help in verifying properties of
that software to a logical certainty,
and Proof Pad has a partially automated testing system to
check out properties before we try to prove them.
So, there are some advantages, especially for studying logic.

Operators are defined in ACL2 with a defun command,
which has four parts.
\begin{quote}
(defun $f$ ($x_1$ $x_2$ \dots $x_n$) \emph{\dots ACL2-formula \dots})

\begin{enumerate}
\item the keyword ``defun''
\item a name for the operator being defined ($f$)
\item a list enclosed in parentheses of names designating operands ($x_1$ $x_2$ \dots $x_n$)
\item an ACL2 formula specifying the value the operator will deliver
\end{enumerate}
\end{quote}

Most of the time, the formula for the value the operator delivers
will have subformulas specifying alternative values for different cases.
Formulas interpreted as predicates select one of
the subformulas to produce the value corresponding to the operands.

In Section \ref{sec:induction} (Figure~\ref{append-equations}, page \pageref{append-equations})
we defined the append operator with two equations,
one for the case when the first operand was the empty list,
and the other for the case when the first operand was non-empty.
The ACL2 definition, following that pattern, has two subformulas,
one for each case.
It uses the if operator
(Figure~\ref{fig:if-axioms}, page \pageref{fig:if-axioms})
to select the appropriate formula.

Figure~\ref{fig:append-defun} (page \pageref{fig:append-defun})
shows the ACL2 notation for the axioms of append
(Figure~\ref{append-equations}, page \pageref{append-equations}),
which, as you know now, amount to an inductive definition of append.
As it happens, the append operator is an ACL2 intrinsic.
It is defined by the ACL2 system, so the definition
in Figure~\ref{fig:append-defun} is redundant,
and the ACL2 system will tell you that if you try to define it.
Shortly, we will begin to define operators that are not
intrinsic, so they need definitions,
but we will use one or two familiar examples, like this one,
as a starting point to put us on the right track.

\begin{figure}
\begin{center}
Axioms: \{\emph{append}\} \\
\begin{tabular}{ll}
(append (cons $x$ $xs$) $ys$) = (cons $x$ (append $xs$ $ys$)) & \{\emph{app1}\} \\
(append $a$ $ys$) =  $ys$                                     & \{\emph{app0}\} \\
~~~~\emph{Note: Cite \{\emph{app0}\} only if \{\emph{app1}\} doesn't match.}&\\
\end{tabular}
\begin{Verbatim}
(defun append (xs ys)      ; intrinsic operator, defun is redundant
  (if (consp xs)                               ; select formula
      (cons (first xs) (append (rest xs) ys))  ; {app1}, xs not nil
      ys))                                     ; {app0}, xs is nil
\end{Verbatim}
\end{center}
\caption{Defining Concatenation: append}
\label{fig:append-defun}
\end{figure}

So, now you know. We've been writing programs on the sly,
passing them off as axioms.
Why? Because that's how we want you to think of them.
A program is a collection of axioms, expressed as equations
that specify properties that you want to operators to have.
You can reason from those equations using the same methods
you have used in reasoning about Boolean equations or numeric equations.
The program is written in the syntax of a programming language,
which makes it look a bit stilted.
That is always the case in programming languages because
they have their own syntax, and you have to conform to it.
It pays off, though.
If you stick with the program, you can get the computer to carry out
the computations you want done.

Since definitions must use the ACL2 syntax,
they don't look much like equations,
but if they are complete, consistent, and computational
(Figure~\ref{fig:inductive-def-keys}, page \pageref{fig:inductive-def-keys}),
the values they deliver will have the properties you derive
from the equations.
They may not have all the properties you expected.
They may have bugs.
But, you'll have a good chance of fixing them with
automated testing (defproperty)
and the reasoning assistance of the ACL2 mechanized logic.

Going forward, we will define operators that aren't
intrinsic in ACL2 (and, therefore, need definitions)
both in the form of an ACL2 defun
and in the form of equations for paper-and-pencil reasoning.
The ACL2 definitions produce operators with matching axioms and
make it possible to apply automated testing and mechanized logic
to confirm some of the properties of those computations.
When the operators we are discussing are intrinsic,
we will usually not include defun forms for them,
just axioms for paper-and-pencil reasoning.
Automated testing and mechanized logic will make use
of their intrinsic definitions in the ACL2 system.

\section{Contatenation, Prefixes, and Suffixes}
\label{sec:append-prefix-suffix}
%%% in this section, prove the correctness of append
%%% with respect to a (prefix n xs) operator and (nthcdr n xs).

If you concatenate two lists, $xs$ and $ys$,
you would expect to be able to retrieve the elements
of $ys$ by dropping some of the elements of the concatenation.
How many elements would you need to drop?
That depends on the number of elements in $xs$.
If there are $n$ elements in $xs$ and you drop $n$ elements
from (append $xs$ $ys$), you expect the result to be identical
to the list $ys$. To express that expectation we can use
an intrinsic operator in ACL2 with the arcane name ``nthcdr''.
The nthcdr operator has two operands: a natural number and a list.
The formula (nthcdr $n$ $xs$) delivers a list like $xs$,
but without its first $n$ elements.
If $xs$ has fewer than $n$ elements,
then the formula delivers the empty list.
In any case, nthcdr delivers a suffix of the list
supplied as its second operand.

If the first operand (the number of elements to be dropped) is zero,
you would expect
nthcdr to deliver the entire list, having dropped no elements.
If the second operand has no elements,
you would expect
nthcdr to deliver a list just like that
(that is, a list with no elements).
Combining these two observations, we find that
$xs$ would be a suitable value for (nthcdr $n$ $xs$)
if either $n$ is zero or $xs$ has no elements.

The other possibility is that $n$ is not zero and $xs$ has some elements.
Since the first operand is a natural number,
being non-zero is the same as being one or more.
In that case you would expect (nthcdr $n$ $xs$) to deliver
the same list that it would deliver
if you dropped the first element of $xs$
and then, in addition, dropped one fewer elements than $n$ says to drop.
Together, these two actions would drop $n$ elements:
first one element, then $(n - 1)$ more elements.
The axioms in Figure~\ref{fig:nthcdr-defun} (page \pageref{fig:nthcdr-defun})
express these observations as equations.

The figure also contains an ACL2 definition of nthcdr, which
is of course redundant because nthcdr if intrinsic in ACL2.\footnote{If
you submit a definition of nthcdr,
the system will inform you of the redundancy.}
The definition uses the predicate consp
(Figure~\ref{consp-axiom}, page \pageref{consp-axiom})
to find out whether the list contains some elements and
uses the predicate
\label{posp-def} posp
to determine whether
the number of elements to be dropped is one or more.
It combines these predicates with the ``and'' operator,
which is the ACL2 notation for the $\wedge$ operator in logic.
\label{and-op=informal}
The value (and $a$ $b$) false (nil)
if either $a$ or $b$ is false and true otherwise.
So, the ACL2 definition matches the axioms.

\begin{figure}
\begin{center}
Axioms \{\emph{nthcdr}\} \\
\begin{tabular}{ll}
(nthcdr $(n+1)$ (cons $x$ $xs$) = (nthcdr $n$ $xs$) & \{\emph{sfx1}\}   \\
(nthcdr $n$ $xs$) = $xs$                            & \{\emph{sfx0}\}   \\
~~~~\emph{Note 1: Cite \{\emph{sfx0}\} only if \{\emph{sfx1}\} doesn't match.}&\\
~~~~\emph{Note 2: $n$ is a natural number.}
\end{tabular}
\begin{Verbatim}
(defun nthcdr (n xs)        ; intrinsic operator, defun is redundant
  (if (and (posp n) (consp xs))   ; predicate selects result formula
      (nthcdr (- n 1) (rest xs))  ; {sfx1}
      xs))                        ; {sf0}
\end{Verbatim}
\end{center}
\caption{Defining List Suffix Extractor: nthcdr}
\label{fig:nthcdr-defun}
% old label for nthcdr axioms: \label{nthcdr-equations}
\end{figure}

\todo{FIXED NOW, REX THINKS as of 5SEP2017
Rex: sfx1 isn't true, right?
I'm not sure we want to introduce it as an axiom, if later we'll have to explain it isn't really true.
Ruben: left as is for now, with (natp n) implicit, but inserted a comment about the type of n
Update (Rex 5Sep 2017: I think it's fixed, now.
}

The equations in Figure~\ref{fig:nthcdr-defun} cover all combinations
of values that the operands of nthcdr can have
The first operand is a natural number,
so it's either zero or bigger than zero.
The second operand, a list, either has some elements or it doesn't.
So the definition is complete, having covered all the cases.
The cases do not overlap, so we don't need to worry about
consistency between the axioms.

There is a subtlety that needs explanation, however.
The operand prototypes in the
\{sfx1\} axiom match when the first operand is a non-zero natural number\footnote{$(n+1)$
cannot be zero when $n$ is a natural number.}
and the second operand is a non-empty list.\footnote{That
is, when (consp(cons $x$ $xs$)) is true,
as it must be according to the consp axiom (page \pageref{consp-axiom}).}
However, the operand prototypes in the \{sfx0\} axiom match anything.
There is a note restricting
citations of the second axiom to cases
where the first axiom does not apply.
This is a new wrinkle.
Usually we state axioms that are independent of each other,
but the constraint in the note conforms to the meaning
of the (if $p$ $a$ $b$) formula, which chooses formula $b$
only if $p$ has the value nil (representing false).
With this convention, the two axioms
do not share any combination of operands, so they cannot
cause an inconsistency in the specified results.

That covers two of the three C's guidelines for defining operators
(Figure~\ref{fig:inductive-def-keys}, page \pageref{fig:inductive-def-keys}).
The equations are complete and consistent.
The third guideline (computational) has two parts, one of which is
a requirement that at least one axiom must be non-inductive.
The \{sfx0\} equation is not inductive because the nthcdr operator
is not invoked on the right-hand side of the equation.
In that case, nthcdr just delivers its second operand, as is.
So, the axioms pass muster on that part of the computational guideline.
With regard to the inductive axiom \{sfx1\},
the operands on the right-hand side of the equation are
smaller and shorter than the operands on the left-hand side,
which makes them closer to the non-inductive case,
since that axiom, \{sfx0\}, will apply if either the first
operand is zero or the second one doesn't have any elements.
So, the equations conform to the three C's guidelines and,
therefore, they define an operator.

Now, we are in a position to verify the relationship
between the append and nthcdr operators that started this discussion.
Namely, we want to prove that if the lists $xs$ and $ys$ are concatenated,
and then (len $xs$) elements are dropped from the beginning of the
concatenation, the result will be the list $ys$.
We will use S($n$) as a shorthand for this property
when $xs$ has $n$ elements.

\begin{samepage}
\begin{center}
\label{append-prefix-thm-predicate}
S($n$) $\equiv$ (nthcdr (len [$x_1$ $x_2$ \dots $x_n$]) (append [$x_1$ $x_2$ \dots $x_n$] $ys$)) $=$ $ys$
\end{center}
\end{samepage}

\todo{COMMENT ONLY, NO TODO
Just in case we decide to go back to ACL2 syntax for the def'n of S
S($n$) $\equiv$ (equal & (nthcdr & (len [$x_1$ $x_2$ \dots $x_n$])          \\
                       &         & (append [$x_1$ $x_2$ \dots $x_n$] $ys$)) \\
                       & $ys$)   &                                          \\
}

\label{append-suffix-thm-pencil-proof} \todo{COMMENT ONLY, NO TODO label added 16Sep2017}
S is a predicate indexed by the natural numbers,
so the formula $\forall n.$S$(n)$ is a candidate for proof by induction.
According to the rule of inference for mathematical induction
(Figure~\ref{induction-rule}, page \pageref{induction-rule}),
we are obliged to prove two things:
(1)~the formula S(0) is true and
(2)~the formula S($n+1$) is true under the assumption that S($n$) is true,
regardless of what natural number $n$ stands for. Let's do those two proofs.

First, we prove S(0).
When $n$ is zero, the list [$x_1$ $x_2$ \dots $x_n$] is empty,
which is normally denoted by the symbol nil.
So, S(0) stands for the following equation.

\begin{samepage}
\begin{center}
S(0) $\equiv$ (nthcdr (len nil) (append nil $ys$)) $=$ $ys$
\end{center}
\end{samepage}

\todo{COMMENT ONLY, NO TODO
Just in case we decide to go back to ACL2 syntax for the def'n of S
\begin{samepage}
\begin{center}
\begin{tabular}{ll}
S(0) $\equiv$ (equal & (nthcdr (len nil) (append nil $ys$)) \\
                     & $ys$)                                \\
\end{tabular}
\end{center}
\end{samepage}
END OF COMMENT ONLY, NO TODO}

As is our usual practice when proving an equation,
we start with the formula on one side and use known
equations to gradually transform that formula
into the one on the other side of the equation.

\begin{center}
\begin{tabular}{lll}
    & (nthcdr (len nil) (append nil $ys$))  &                                                  \\
$=$ & (nthcdr (len nil) $ys$)               & \{\emph{app0}\} (page \pageref{fig:append-defun})\\
$=$ & (nthcdr 0 $ys$)                       & \{\emph{len0}\} (page \pageref{len-equations})   \\
$=$ & $ys$                                  & \{\emph{sfx0}\}                                  \\
\end{tabular}
\end{center}

That takes care of S(0). Next, we prove S($n+1$), assuming that S($n$) is true.

\begin{samepage}
\begin{center}
%\begin{tabular}{lll}
S($n+1$) $\equiv$ (nthcdr (len [$x_1$ $x_2$ \dots $x_{n+1}$]) (append [$x_1$ $x_2$ \dots $x_{n+1}$] $ys$)) $=$ $ys$
%\end{tabular}
\end{center}
\end{samepage}

\begin{center}
\begin{tabular}{llll}
    & (nthcdr & (len [$x_1$ $x_2$ \dots $x_{n+1}$])                 & \\
    &         & (append [$x_1$ $x_2$ \dots $x_{n+1}$] $ys$))        & \\
$=$ & (nthcdr & (len (cons $x_1$ [$x_2$ \dots $x_{n+1}$])))         & \{\emph{cons}\} (page \pageref{first-rest-cons}) \\
    &         & (append (cons $x_1$ [$x_2$ \dots $x_{n+1}$]) $ys$)) & \{\emph{cons}\}                                \\
$=$ & (nthcdr & (+ 1 (len [$x_2$ \dots $x_{n+1}$]))                 & \{\emph{len1}\} (page \pageref{len-equations})       \\
    &         & (cons $x_1$ (append [$x_2$ \dots $x_{n+1}$]) $ys$)) & \{\emph{app1}\} (Figure \ref{fig:append-defun}, page \pageref{fig:append-defun})\\
$=$ & (nthcdr & (+ (len [$x_2$ \dots $x_{n+1}$]) 1)                 & \{\emph{+ commutative}\} (page \pageref{fig-02-01})  \\
    &         & (cons $x_1$ (append [$x_2$ \dots $x_{n+1}$]) $ys$)) &                                                      \\
$=$ & (nthcdr & (len [$x_2$ \dots $x_{n+1}$])                       & \{\emph{sfx1}\}                                      \\
    &         & (append [$x_2$ \dots $x_{n+1}$] $ys$))              &                                                      \\
$=$ & $ys$    &                                                     & \{S($n$)\}                                           \\
\end{tabular}
\end{center}

The last step in the proof is justified by citing S($n$).
This is a little tricky because the formula that S($n$)
stands for is not exactly the same as the formula in the next-to-last step of the proof.
We interpret the formula [$x_1$ $x_2$ \dots $x_n$] in the definition of S($n$)
to stand for any list with $n$ elements.
The elements in the list [$x_2$ \dots $x_{n+1}$] are numbered 2 through $n+1$,
which means there must be exactly $n$ of them.

With this interpretation, the formula in the next-to-last step
matches the formula in the definition of S($n$),
which makes it legitimate to cite S($n$) to justify
the transformation to $ys$ in the last step of the proof.
We will use this interpretation frequently in proofs.
We refer to it as the \emph{numbered-list} interpretation
or \{\emph{nlst}\} for short
(Figure~\ref{numbered-list-interpretation}, page \pageref{numbered-list-interpretation}).

At this point, we know that (append $xs$ $ys$) delivers
a list that has the right elements at the end.
How about the beginning?
We expect the concatenation to start with the elements of the list $xs$,
so if we extract the first $n$ elements of (append $xs$ $ys$), where $n$ is (len $xs$),
we would expect to get a list identical to $xs$.
To express this expectation formally, we need a operator that,
given a number $n$ and a list $xs$, delivers the first $n$ elements of $xs$.
Let's call that operator ``prefix'' and think about properties it would have to satisfy.

Of course, if $n$ is zero, or if $xs$ is empty,
(prefix $n$ $xs$) must be the empty list.
If $n$ is non-zero natural number and $xs$ is not empty,
then the first element of (prefix $n$ $xs$) must be the first element of $xs$,
the the other elements must be the first $n-1$ elements of (rest $xs$).
Figure~\ref{prefix-equations} (page \pageref{prefix-equations}) displays
equations that define the prefix operator.
We can derive the prefix property of the append operator
from those equations and the axioms of the append operator
(Figure~\ref{fig:append-defun}, page \pageref{fig:append-defun}).
The proof will cite mathematical induction proving $\forall n.$P($n$),
where the predicate P is defined as follows.

\begin{samepage}
\begin{center}
P($n$) $\equiv$ (prefix (len [$x_1$ $x_2$ \dots $x_n$]) (append [$x_1$ $x_2$ \dots $x_n$] $ys$))
                $=$ [$x_1$ $x_2$ \dots $x_n$])
\end{center}
\end{samepage}

We will prove that P(0) is true, and also that P($n+1$) is true whenever P($n$) is true. Then, we will cite mathematical induction to conclude that P($n$) is true, regardless of which natural number $n$ stands for.

\begin{figure}
\begin{center}
Axioms \{\emph{prefix}\}                                           \\
\begin{tabular}{ll}
(prefix $(n + 1)$ (cons $x$ $xs$)) = (cons $x$ (prefix $n$ $x$s)) & \{\emph{pfx1}\} \\
(prefix $n$ $xs$) =  nil                                          & \{\emph{pfx0}\} \\
~~~~\emph{Note 1: Cite \{\emph{pfx0}\} only if \{\emph{pfx1}\} doesn't match.}&\\
~~~~\emph{Note 2: $n$ is a natural number.}
\end{tabular}
\begin{Verbatim}
(defun prefix (n xs)
  (if (and (posp n) (consp xs))   ; predicate selects result formula
      (cons (first xs) (prefix (- n 1) (rest xs)))  ; {pfx1}
      xs))                                          ; {pfx0}
\end{Verbatim}
\end{center}
\caption{Defining List Prefix Extractor: prefix}
\label{prefix-equations}
\end{figure}

\begin{center}
P($0$) $\equiv$ (prefix (len nil) (append nil $ys$)) $=$ nil
\end{center}

As in the proof of the append suffix theorem, we start with the formula on one side of the equation and use known equations to gradually transform that formula to the one on the other side of the equation.

\begin{center}
\begin{tabular}{lll}
    & (prefix (len nil) (append nil $ys$))  &                                                      \\
$=$ & (prefix 0 (append nil $ys$))          & \{\emph{len0}\} (page \pageref{len-equations})   \\
$=$ & nil                                   & \{\emph{pfx0}\}                                      \\
\end{tabular}
\end{center}

That takes care of P(0). Figure~\ref{pfx-induc} (page \pageref{pfx-induc}) displays a proof of P($n$) $\rightarrow$ P($n+1$).

\begin{figure}
\begin{center}
P($n+1$) $\equiv$ (prefix (len [$x_1$ $x_2$ \dots $x_{n+1}$]) (append [$x_1$ $x_2$ \dots $x_{n+1}$] $ys$)) $=$ [$x_1$ $x_2$ \dots $x_{n+1}$]
\end{center}

\todo{Rex: This following indentation isn't perfect, but it's close.  I haven't figured out how to remove the vertical space before the tabbing, though I can probably hack it....
      COMMENT BY REX: Looks too strung out in print, better to put citations on same line as new formula, I think.
                      but I'm afraid to tamper with it.}

\begin{center}
	\setlength{\topsep}{0pt}
	\setlength{\partopsep}{0pt}
\begin{tabular} {lp{3in}p{1.5in}}
    & \begin{tabbing}
			(prefix \=(len [$x_1$ $x_2$ \dots $x_{n+1}$]) \\
         	        \>(append [$x_1$ $x_2$ \dots $x_{n+1}$] $ys$))
		\end{tabbing}
	& \\
$=$ & \begin{tabbing}
		(prefix \=(len (cons $x_1$ [$x_2$ \dots $x_{n+1}$])) \\
                \>(append (cons $x_1$ [$x_2$ \dots $x_{n+1}$]) $ys$))
		\end{tabbing}
	& \{\emph{cons}\} (page \pageref{first-rest-cons}) \\
$=$ & \begin{tabbing}
			(prefix \=(+ 1 (len [$x_2$ \dots $x_{n+1}$])) \\
                    \>(cons $x_1$ (append [$x_2$ \dots $x_{n+1}$] $ys$)))
		\end{tabbing}
    & \{\emph{len1}\} (page \pageref{len-equations}) \hfill\break
      \{\emph{app1}\} (page \pageref{append-equations})    \\

$=$ & \begin{tabbing}
		(cons \=(first (cons $x_1$ [$x_2$ \dots $x_{n+1}$])) \\
			  \>(prefix \=(- (+ 1 (len [$x_2$ \dots $x_{n+1}$])) 1) \\
			  \>        \>(rest (cons $x_1$ (append [$x_2$ \dots $x_{n+1}$] $ys$)))))
		\end{tabbing}
	& \{\emph{pfx1}\} \\
$=$ & \begin{tabbing}
		(cons \=$x_1$ \\
			  \>(prefix \=(len [$x_2$ \dots $x_{n+1}$]) \\
			  \>        \>(append [$x_2$ \dots $x_{n+1}$] $ys$)))
		\end{tabbing}
	& \{\emph{fst}\} (page \pageref{first-rest-cons}) \hfill\break
	  \{\emph{arithmetic}\} \hfill\break
	  \{\emph{rst}\} (page \pageref{first-rest-cons}) \\
$=$ & \begin{tabbing}
		(cons \=$x_1$ \\
			  \>[$x_2$ \dots $x_{n+1}$] )
		\end{tabbing}
	& \{P($n$)\} \\
$=$ & [$x_1$ $x_2$ \dots $x_{n+1}$] & \{\emph{cons}\} (page \pageref{first-rest-cons}) \\
\end{tabular}
\end{center}
\caption{Proof: $\forall n.$ P($n$) $\rightarrow$ P($n+1$)}
\label{pfx-induc}
\end{figure}

At this point we know three important facts about the append operator:
\begin{quote}
\begin{itemize}
\item additive length theorem: (len (append $xs$ $ys$)) = (+ (len $xs$) (len $ys$))
\label{app-pfx-thm}
\item append-prefix theorem: (prefix (len $xs$) (append $xs$ $ys$)) = $xs$
\item append-suffix theorem: (nthcdr (len $xs$) (append $xs$ $ys$)) = $ys$
\end{itemize}
\end{quote}

Together, these theorems provide some assurance that append correctly concatenates lists.
We could think of them as ``correctness properties'' for the append operation.
There are, of course, an infinite variety of other facts about the append operation.
Their relative importance depends on how we are using the operation.
A property that is sometimes important to know is that concatenation is associative,
which is a property of addition and multiplication in the domain of numbers
(Figure~\ref{fig-02-01}, page \pageref{fig-02-01}).
That is, if there are three lists to be concatenated,
you you could concatenate the first list with the concatenation of the last two.
Or, you could concatenate the first two, then append the third list at the end.

\begin{samepage}
\label{app-assoc}
\begin{center}
Theorem \{\emph{app-assoc}\} (append $xs$ (append $ys$ $zs$)) = (append (append $xs$ $ys$) $zs$)
\end{center}
\end{samepage}

This theorem can be proved by mathematical induction.
Formally, we will assume that
we can always write a list $xs$ in the pencil-and-paper format that
displays its elements. We state this as the \{lst\} axiom.

\begin{center}
\label{axiom:lst}
Axiom \{lst\} $\forall xs.\exists n.\exists$[$x_1$ $x_2$ \dots $x_n$].($xs$ $=$ [$x_1$ $x_2$ \dots $x_n$])
\end{center}

With that axiom, the formula $\forall$$n$.A($n$))
is a restatement of the \{\emph{app-assoc}\} theorem that paves the way for a proof
by mathematical induction, where the predicate A is defined as follows.

\begin{samepage}
\begin{center}
A($n$) $\equiv$ (append [$x_1$ $x_2$ \dots $x_n$] (append $ys$ $zs$)) $=$ (append (append [$x_1$ $x_2$ \dots $x_n$] $ys$) $zs$)
\end{center}
\end{samepage}

Then the goal would be to prove that the formula $\forall$$n$.A($n$)) is true.
We leave that proof as an exercise.

\begin{ExerciseList}

\Exercise Prove the \{\emph{app-assoc}\} theorem (page \pageref{app-assoc}).

\todo{COMMENT ONLY, NO TODO
Reviewer 2 points out that Ch4 talks about ACL2 programs and even about
defun (in the following exercise), but does not provide a proper explanation.
Ch5 then more-or-less assumes the reader already knows about defun.
Also, Ch3 is already talking about testing ACL2 programs, and
has a test of the reciprocals program, r, without a defun for r.
This needs to be fixed.
One way to handle it would be to add a section to Ch3 to explain defun.
The intro material can be moved from Ch5,
and this exercise or something like it could
provide an example in this chapter (Ch4) for reasoning by induction
with a defined, rather than intrinsic, operator.
Update (Rex 10Sep2017): added the defun section and replace r(n).
Plan to move and expand mechanized logic section and halting problem to chapter after ch04 (ch04a.tex, I guess).
}

\Exercise Suppose the operator rep is defined as follows.
\label{rep-equations}
\begin{Verbatim}
(defun rep (n x)
  (if (posp n)
      (cons x (rep (- n 1) x))   ; {rep1}
      nil))                      ; {rep0}
\end{Verbatim}
Prove the following theorem \{\emph{rep-len}\}.
In the theorem, $n$ can be any natural number and $x$ can be any entity.
\begin{samepage}
\label{rep-len}
\begin{center}
Theorem \{\emph{rep-len}\} \\
(len (rep n x)) = n
\end{center}
\end{samepage}

\Exercise Assume the following axioms \{\emph{mem0}\} and \{\emph{mem1}\} are true.
\begin{samepage}
\label{member-equal-equations}
\begin{center}
Axioms \{\emph{member-equal}\} \\
\begin{tabular}{ll}
(member-equal y (cons $x$ $xs$)) = (equal $y$ $x$) $\vee$ (member-equal $y$ $xs$)) & \{\emph{mem1}\} \\
(member-equal y nil) = nil                                                         & \{\emph{mem0}\} \\
\end{tabular}
\end{center}
\end{samepage}
Prove the following theorem \{\emph{rep-mem}\}.
\begin{samepage}
\label{rep-mem}
\begin{center}
Theorem \{\emph{rep-mem}\} \\
(member-equal $y$ (rep $n$ $x$)) $\rightarrow$ (member-equal y (cons $x$ nil))
\end{center}
\end{samepage}

\Exercise Prove Theorem \{app-nil\}: $\forall n.$([$x_1$ $x_2$ \dots $x_{n}$] = (append [$x_1$ $x_2$ \dots $x_{n}$] nil))

\Exercise Prove $\forall xs.$((nthcdr (len xs) (append $xs$ nil)) $=$ nil).

\end{ExerciseList}

\todo{COMMENT ONLY, NO TODO
next section will introduce defthm and proofs using the ACL2 mechanized logic
by replaying all of the theorems of this section in ACL2 notation}

%% All references to Dracula taken out (30Aug2017 - rlp)
%% I think we should use Proof Pad for all doublecheck and other interface-to-ACL2 issues.
%% We can explain in an aside, when we first mention Proof Pad,
%%    that ACL2s and emacs are other interfaces,
%%    that ACL2s has its own, extensive, random-test facility,
%%    that it is perfectly reasonable for students to use another interface to ACL2,
%%    that if they use another interface, they will need to interpret our doublecheck examples in, say, ACL2 fashion.
%%\end{comment}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "book"
%%% End:
