\chapter{Mathematical Induction}

\textit{Induction, basic proofs, \dots}

\section{Lists as Mathematical Objects}
\label{sec:lists-as-obj}
A sequence is an ordered list of elements. In fact, we will more often use the term shorter term ``list'' for this kind of mathematical object. Our notation for lists displays the elements of the list, enclosed in parentheses, separated by spaces. For example, the formula ``(8 3 7)'' denotes the list with first element 8, second element 3, and third element 7. The formula ``(9 8 3 7)'' denotes a list with the same elements, but with an additional element ``9'' at the beginning. We use the symbol ``nil'' for the empty list (that is, the list with no elements).

We will start with three basic operators for lists. One of them, the construction operator, ``cons'', inserts a new element at the beginning of a sequence. Formulas using ``cons'', like all formulas in the mathematical notation we have been using to discuss software concepts, are written in prefix form. So, the formula ``(cons $x$ $xs$)'' denotes the list with the same elements as the list $xs$, but with an additional element $x$ inserted at the beginning. If $x$ stands for the number ``9'', and $xs$ stands for the list ``(8 3 7)'', then ``(cons $x$ $xs$)'' constructs the list ``(9 8 3 7)''.

Any list can be constructed by starting from the empty list and using the construction operator to insert the elements of the list, one by one. For example, the formula ``(cons 8 (cons 3 (cons 7 nil)))'' is another notation for the list ``(8 3 7)''. In fact, using the operator ``cons'' is the only way to construct non-empty lists. The empty list ``nil'' is given. All other lists (that is, all non-empty lists) are constructed using the ``cons'' operator. The formula ``(8 3 7)'' is shorthand for ``(cons 8 (cons 3 (cons 7 nil)))''.

The operator that checks for non-empty lists is ``consp''. The formula ``(consp $xs$)'' delivers true if $xs$ is a non-empty list and false otherwise. The \{\emph{cons}\} axiom of list construction is a formal statement of the fact that all non-empty lists are constructed with the ``cons'' operator.

\label{cons-axiom-formal}
Axiom \{\emph{cons}\} (consp $xs$) $\leftrightarrow$ ($\exists y. \exists ys.$ ($xs$ = (cons $y$ $ys$)))

We will often cite the \{\emph{cons}\} axiom to write a formula like (cons $x$ $xs$) in place of any list we know is not empty. When we do this, we will take care to choose the symbols $x$ and $xs$ to avoid conflicts with other symbols that appear in the context of the discussion.
Furthermore, we will often cite a less formal version of the \{\emph{cons}\} axiom when we know we are dealing with a non-empty list. For example, the list ($x_1$ $x_2$ \dots $x_{n+1}$) cannot be empty because it has $n+1$ elements, and $n+1$ is at least one when $n$ is a natural number. (We will always assume that subscripts are natural numbers.)

\label{cons-axiom-informal}
Informal Axiom \{\emph{cons}\}
($x_1$ $x_2$ \dots $x_{n+1}$) = (cons $x_1$ ($x_2$ \dots $x_{n+1}$))

The construction operator, ``cons'', cannot be the whole story, of course. To compute with lists, we  need to be able to construct them, but we also need to be able to take them apart. There are two basic operators for taking lists apart: ``first'' and ``rest''. We express the relationship between these operators and the construction operator in the form of equations (\{\emph{first}\} and \{\emph{rest}\}), along with the informal version of the \{\emph{cons}\} axiom.

\label{first-rest-cons}
\begin{tabular}{ll}
 Axioms: \{\emph{cons}\}, \{\emph{first}\}, and \{\emph{rest}\}       &                 \\
 ($x_1$ $x_2$ \dots $x_{n+1}$) = (cons $x_1$ ($x_2$ \dots $x_{n+1}$)) & \{\emph{cons}\} \\
 (first (cons $x$ $xs$)) = $x$                                        & \{\emph{first}\}\\
 (rest (cons $x$ $xs$))  = $xs$                                       & \{\emph{rest}\} \\
\end{tabular}

The \{\emph{first}\} axiom is a formal statement of the fact that the operator ``first'' delivers the first element from non-empty list. The \{\emph{rest}\} axiom states that the operator ``rest'' delivers a list like its argument, but without the first element. Note that the list in the \{\emph{first}\} and \{\emph{rest}\} axioms have at least one element because they are constructed by the cons operator.

We will use equations like the ones in these axioms in the same way we used the logic equations in Figure~\ref{fig-02-02} (see page \pageref{fig-02-02}) and the arithmetic equations of Figure~\ref{fig-02-01} (see page \pageref{fig-02-01}). That is, whenever we see a formula like ``(first (cons $x$ $xs$))'', no matter what formulas $x$ and $xs$ stand for, we will be able to cite equation \{\emph{first}\} to replace ``(first (cons $x$ $xs$))'' by the simpler formula ``$x$''. Vice versa, we can also cite equation \{\emph{first}\} to replace any formula ``$x$'' by the more complicated formula ``(first (cons $x$ $xs$))''. Furthermore, the formula ``$xs$'' in the replacement can be any formula we care to make up, as long as it is grammatically correct.

Similarly, we can cite the equation \{\emph{rest}\} to justify replacing the formula ``(rest (cons $x$ $xs$))'' by ``$xs$'' and vice versa, regardless of what formulas the symbols ``$x$'' and ``$x$'' stand for. In other words, these are ordinary algebraic equations. The only new factors are
(1)~the kind of mathematical object they denote (lists, instead of numbers or True/False propositions), and
(2)~the syntactic quirk of prefix notation (instead of the more familiar infix notation).

All properties of lists, as mathematical objects, derive from the \{cons\} axiom and equations \{first\} and \{rest\}. For example, suppose there is an operator called ``len'' that delivers the number of elements in a list. We can use check-expect to test len in some specific cases.

\begin{lstlisting}
(check-expect (len (cons 8 (cons 3 (cons 7 nil)))) 3)
(check-expect nil 0)
\end{lstlisting}

We can use the doublecheck facility to automate tests. We expect that the number of elements in a non-empty list is one more than the number of elements remaining in the list after the first one is dropped using the ``rest'' operator. The following property tests this expectation.

\begin{lstlisting}
(defproperty len-test
  (xs :value (random-list-of (random-natural)))
  (= (len xs)
     (if (consp xs)
         (+ 1 (len (rest xs)))
         0)))
\end{lstlisting}

\begin{comment} ...suppressing defthm for now...
When a property holds under all circumstances, we can sometimes use the automated logic of ACL2 to prove it. To do so, we formulate the property as a theorem and press the ``Start'' button in the Dracula proof panel (right side of Dracula window). When the ``ACL2!\verb+>+'' prompt appears in the lower pane in the proof panel, we press the ``Admit'' arrow, and the automated logic of ACL2 starts trying to prove the theorem.

Theorem definitions are similar to property definitions, but the keyword is ``defthmd'' instead of ``defproperty''. The following theorem definition states the len-test property in a form that the automated logic of ACL2 can use to attempt a proof that the property holds under all circumstances.

\label{len-thm}
\begin{lstlisting}
(defthmd len-thm
  (= (len xs)
     (if (consp xs)
         (+ 1 (len (rest xs))) ; {len1}
         0)))                  ; {len0}
\end{lstlisting}

ACL2 interprets variables in theorems as if they were universally quantified. So, the formula ``(= (len $xs$) (if (consp $xs$) (+ 1 (len (rest $xs$))) 0))'' in the definition of len-thm means ``($\forall$$xs$.(= (len $xs$) (if (consp $xs$) (+ 1 (len (rest $xs$))) 0)))''.
In this case, ACL2 successfully proves the theorem, and Dracula colors the theorem green. (If ACL2 had failed to prove the theorem, Dracula would have colored it pink.) Because ACL2 succeeds in proving the theorem, we know that the ``len-test'' property from our doublecheck testing is true under all circumstances. We can cite this fact in proofs.

The len theorem contains two formulas that have the same meaning as (len $xs$). One of them, which we have labeled ``\{\emph{len1}\}'', applies when the argument in an invocation of len is a list with at least one element (that is, (consp $xs$) is true).  The other formula, which we have labeled ``\{\emph{len0}\}'', applies when the argument is the empty list (nil).
\end{comment}

This property holds under all circumstances. We can express the idea in the form of equations that serve as axioms for the len operator.

\label{len-equations}
\begin{center}
\begin{tabular}{ll}
Axioms: \{\emph{len}\}
(len nil) = 0                            & \{\emph{len0}\} \\
(len (cons $x$ $xs$)) = (+ (len $xs$) 1) & \{\emph{len1}\}
\end{tabular}
\end{center}

\begin{comment}
We also expect the ``len'' operator to deliver a natural number, regardless of what its argument is. We can state this in the form of a theorem using the ``natp'' operator, which delivers true if its argument is a natural number and false if it isn't.

\label{len-nat-thm}
\begin{lstlisting}
(defthmd len-is-natural-number-thm
  (natp (len xs)))
\end{lstlisting}

ACL2 succeeds in proving this theorem, too, so we now know that the formula (len $xs$) delivers a non-negative integer, regardless of what formula $xs$ stands for. We will use the label \{\emph{len-nat}\} when we cite this theorem in proofs.

A related fact is that the formula (consp $xs$) is logically equivalent to the formula (\verb+>+ (len $xs$) 0). In the notation from Chapter~\ref{ch:Boolean-Formulas}: (consp $xs$)$\leftrightarrow$(\verb+>+ (len $xs$) 0). The name of the equivalence operator in ACL2 is ``iff'', so in ACL2 notation, the formula would be:
(iff (consp $xs$) (\verb+>+ (len $xs$) 0)). Or, stated as a theorem, it looks like this:

\begin{lstlisting}
(defthmd consp<->len>0-thm
  (iff (consp xs) (> (len xs) 0)))
\end{lstlisting}
\end{comment}

We expect the ``len'' operator to deliver a natural number, regardless of what its argument is, and we can derive this property of len from its axioms. Instead of plodding through this derivation at this point, we are going to proceed to some more interesting issues. For the record, we state it as a theorem. Later, you will have a chance to derive this theorem from the \{\emph{len}\} axioms. The theorem refers to the natp operator, which you have seen before (see page \pageref{natp-op}). It delivers true if its argument is a natural number and false otherwise.

\label{len-nat-thm}
Theorem \{\emph{len-nat}\} $\forall xs.$(natp (len $xs$))

A related fact is that the formula (consp $xs$) is logically equivalent to the formula (\verb+>+ (len $xs$) 0). In the notation from Chapter~\ref{ch:Boolean-Formulas}: (consp $xs$)$\leftrightarrow$(\verb+>+ (len $xs$) 0). This theorem, too, can be derived from the\{\emph{len}\} axioms, but we will take a pass on proving the theorem, for the moment, and state it without proof.

\label{consp-len-thm}
Theorem \{\emph{consp}$\leftrightarrow$len$>$0\} $\forall xs.$(consp $xs$)$\leftrightarrow$(\verb+>+ (len $xs$) 0)

\section{Mathematical Induction}
\label{sec:induction}
The cons, first, and rest operators form the basis for computing with lists, but there are lots of others, too. For example, consider an operator ``append'' that concatenates two lists. We describe this operator using an informal schematic for lists that labels the elements of the list as variables with natural numbers as subscripts. The number of integers in the subscript sequence implicitly reveals the number of elements in the list.

\label{list-schematic} In the following list schematics, the ``$x$'' list has $m$ elements, the ``$y$'' list has $n$ elements, and the concatenated list has $m+n$ elements.
\begin{center}
(append ($x_1$ $x_2$ \dots $x_m$) ($y_1$ $y_2$ \dots $y_n$)) = ($x_1$ $x_2$ \dots $x_m$ $y_1$ $y_2$ \dots $y_n$)
\end{center}

Some simple tests might bolster our understanding of the operator.

\begin{lstlisting}
(check-expect (append '(1 2 3 4) '(5 6 7))
              '(1 2 3 4 5 6 7))
(check-expect (append '(1 2 3 4 5) nil)
              '(1 2 3 4 5))
\end{lstlisting}

\begin{aside}
What is the single-quote mark doing in the formula '(1 2 3 4)? It is there to avoid confusing lists overlaps with computational formulas. By default, the ACL2 system interprets a formula like (f $x$ $y$ $z$) as an invocation of the operator ``f'' with operands $x$, $y$, and $z$. ACL2 interprets the first symbol it encounters after a left parenthesis as the name of an operator, and it interprets the other formulas, up to the matching right parenthesis, as operands.
So, ACL2 interprets the ``1'' in the formula (1 2 3 4) as the name of an operator.
Because there is no operator with the name ``1'', the interpretation fails.

If we want to specify the list ``(1 2 3 4)'' in a formula, we can, of course, use the cons operator to construct it: (cons 1 (cons 2 (cons 3 (cons 4 nil)))). But, that's too bulky for regular use. The single-quote trick provides a shorthand: '(1 2 3 4) has the same meaning as the bulky version. The single-quote mark suppresses the default interpretation of the first symbol after the left-parenthesis and delivers the list whose elements are in the parentheses. Without the single-quote mark, the ``1'' in ``(1 2 3 4)'' would be interpreted as an operator, and because there is no operator named ``1'', the formula would make no sense.
\caption{Single-quote Shorthand for Lists}
\label{quote}
\end{aside}

We can use doublecheck for more extensive testing. If we concatenate the empty list nil with a list $ys$, we expect to get $ys$ as a result: (append nil $ys$) = nil. If we concatenate a non-empty list $xs$ with a list $ys$, we expect the first element of the result to be the same as the first element of $xs$. Furthermore, we expect the rest of the elements to be the elements of the list we would get if we concatenated a list made up of the other elements of $xs$, that is (rest $xs$),  with $ys$. The following property definition expresses this idea formally.

\begin{lstlisting}
(defproperty append-test
  (xs :value (random-list-of (random-natural))
   ys :value (random-list-of (random-natural)))
  (equal (append xs ys)
         (if (consp xs)
             (cons (first xs)
                   (append (rest xs) ys))
             ys)))
\end{lstlisting}

\begin{aside}
Why does the property say ``(equal (append $xs$ $ys$) \dots)'' instead of ``(= (append $xs$ $ys$) \dots)''? the ``='' operator is restricted to numbers. The ``equal'' operator can check for equality between other kinds of objects. You can always use ``equal'', but you can only use ``='' when both operands are numbers. Why bother with ``='', when its use is so limited? We might say it makes the formula look more like an equation, but that's not really much of an excuse, since we have already had to conform to prefix notation instead of the more familiar infix notation. So, feel free to use the ``equal'' operator all the time if you want to. We will be using ``='' when we can and hope it doesn't put too much of an extra burden on you.
\caption{``equal'' vs ``=''}
\label{equal}
\end{aside}

\begin{comment}
This might not be the first test you would think of, but if the test failed to pass, you would for sure know something was wrong with the append operator.
This is another property that ACL2 can prove when it is stated as a theorem.

\begin{lstlisting}
(defthmd append-thm
  (equal (append xs ys)
         (if (consp xs)
             (cons (first xs)            ; {app1}
                   (append (rest xs) ys))
             ys)))                       ; {app0}
\end{lstlisting}
\end{comment}

This might not be the first test you would think of, but if the test failed to pass, you would for sure know something was wrong with the append operator. In fact the property is so plainly correct, we are going to state it in the form of equations that we accept as axioms.

Like the \{\emph{len}\} theorem, there are two \{\emph{append}\} equations, and they specify the meaning of an append operation in different situations. One of them specifies the meaning when the first argument in the invocation is a list with at least one element (that is, when (consp $xs$) is true), the other when it has no elements (that is, when it is nil).

\label{append-equations}
\begin{center}
\begin{tabular}{ll}
Axioms: \{\emph{append}\}                                     &                 \\
(append nil $ys$) =  $ys$                                     & \{\emph{app0}\} \\
(append (cons $x$ $xs$) $ys$) = (cons $x$ (append $xs$ $ys$)) & \{\emph{app1}\} \\
\end{tabular}
\end{center}

\label{additive-law-concatenation}
These equations about the append operation simple enough, but it turns out that lots of other properties of the append operation can be derived from them. For example, we can prove that the length of the concatenation of two lists is the sum of the lengths of the lists. We call this theorem the ``additive law of concatenation''. Let's see how a proof of this law could be carried out.

First, let's break it down into a sequence of special cases. We will use L($n$) as shorthand for the proposition that (len (append ($x_1$ $x_2$ \dots $x_n$) $ys$)) is the sum of (len ($x_1$ $x_2$ \dots $x_n$)) and (len $ys$):

\begin{quote}
\begin{tabbing}
L($n$) $\equiv$ (= \=(len (append ($x_1$ $x_2$ \dots $x_n$) $ys$))  \\
                   \>(+ (len ($x_1$ $x_2$ \dots $x_n$)) (len $ys$)))
\end{tabbing}
\end{quote}

For the first few values of $n$, L($n$) would stand for the following equations.
% L(0) $\equiv$ (= (len (append nil $ys$)) (+ (len nil) (len $ys$))) \\
% L(1) $\equiv$ (= (len (append ($x_1$) $ys$)) (+ (len ($x_1$)) (len $ys$))) \\
% L(2) $\equiv$ (= (len (append ($x_1$ $x_2$) $ys$) (+ (len ($x_1$ $x_2$)) (len $ys$))) \\
% L(3) $\equiv$ (= (len (append ($x_1$ $x_2$ $x_3$) $ys$)) (+ (len ($x_1$ $x_2$ $x_3$)) (len $ys$))) \\
% L(4) $\equiv$ (= (len (append ($x_1$ $x_2$ $x_3$ $x_4$) $ys$)) (+ (len ($x_1$ $x_2$ $x_3$ $x_4$)) (len $ys$)))

\begin{center}
\begin{tabular}{llll}
L(0) & $\equiv$ & (= &(len (append nil $ys$)) \\
     &          &    &(+ (len nil) (len $ys$))) \\
L(1) & $\equiv$ & (= &(len (append ($x_1$) $ys$)) \\
     &          &    &(+ (len ($x_1$)) (len $ys$))) \\
L(2) & $\equiv$ & (= &(len (append ($x_1$ $x_2$) $ys$) 	\\
	 &          &    &(+ (len ($x_1$ $x_2$)) (len $ys$))) \\
L(3) & $\equiv$ & (= &(len (append ($x_1$ $x_2$ $x_3$) $ys$)) \\
     &          &    &(+ (len ($x_1$ $x_2$ $x_3$)) (len $ys$))) \\
L(4) & $\equiv$ & (= &(len (append ($x_1$ $x_2$ $x_3$ $x_4$) $ys$)) \\
     &          &    &(+ (len ($x_1$ $x_2$ $x_3$ $x_4$)) (len $ys$)))
\end{tabular}
\end{center}

We can derive L(0) from the \{\emph{append}\} and \{\emph{len}\} axioms as follows, starting from the first operand in the equation that L(0) stands for (the left-hand side, if the equation were written in the conventional way rather than prefix form), and ending with the second operand (right-hand side).

\begin{center}
\begin{tabular}{lll}
    & (len (append nil $ys$))  &                                                \\
$=$ & (len $ys$)               & \{\emph{app0}\}                                \\
$=$ & (+ (len $ys$) 0)         & \{$+$ identity\}    (page \pageref{fig-02-01}) \\
$=$ & (+ 0 (len $ys$))         & \{$+$ commutative\} (page \pageref{fig-02-01}) \\
$=$ & (+ (len nil) (len $ys$)) & \{\emph{len0}\} \\
\end{tabular}
\end{center}

That was easy. How about L(1)?

\begin{center}
\begin{tabular}{lll}
    & (len (append ($x_1$) $ys$))           &                     \\
$=$ & (len (append (cons $x_1$ nil) $ys$)   & \{\emph{cons}\}     \\
$=$ & (len (cons $x_1$ (append nil $ys$)))  & \{\emph{app1}\}     \\
$=$ & (+ 1 (len (append nil $ys$)))         & \{\emph{len1}\}     \\
$=$ & (+ 1 (+ (len nil) (len $ys$)))        & \{L(0)\}            \\
$=$ & (+ (+ 1 (len nil)) (len $ys$))        & \{$+$ associative\} (page \pageref{fig-02-01}) \\
$=$ & (+ (len (cons $x_1$ nil)) (len $ys$)) & \{\emph{len1}\}     \\
$=$ & (+ (len ($x_1$) (len $ys$))           & \{\emph{cons}\}     \\
\end{tabular}
\end{center}

That was a little harder. Will proving L(2) be still harder? Let's try it.

\begin{center}
\begin{tabular}{lll}
    & (len (append ($x_1$ $x_2$) $ys$))         &                     \\
$=$ & (len (append (cons $x_1$ ($x_2$)) $ys$))  & \{\emph{cons}\}     \\
$=$ & (len (cons $x_1$ (append ($x_2$) $ys$)))  & \{\emph{app1}\}     \\
$=$ & (+ 1 (len (append ($x_2$) $ys$)))         & \{\emph{len1}\}     \\
$=$ & (+ 1 (+ (len ($x_2$)) (len $ys$)))        & \{L(1)\}            \\
$=$ & (+ (+ 1 (len ($x_2$))) (len $ys$))        & \{$+$ associative\} \\
$=$ & (+ (len (cons $x_1$ ($x_2$))) (len $ys$)) & \{\emph{len1}\}     \\
$=$ & (+ (len ($x_1$ $x_2$)) (len $ys$))        & \{\emph{cons}\}     \\
\end{tabular}
\end{center}

Fortunately, proving L(2) was no harder than proving L(1). In fact the two proofs cite exactly the same equations all the way through, except in one place. Where the proof of L(1) cited the equation L(0), the proof of L(2) cited the equation L(1). Maybe the proof of L(3) will work the same way.

\begin{center}
\begin{tabular}{lll}
    & (len (append ($x_1$ $x_2$ $x_3$) $ys$))         &                     \\
$=$ & (len (append (cons $x_1$ ($x_2$ $x_3$)) $ys$))  & \{\emph{cons}\}     \\
$=$ & (len (cons $x_1$ (append ($x_2$ $x_3$) $ys$)))  & \{\emph{app1}\}     \\
$=$ & (+ 1 (len (append ($x_2$ $x_3$) $ys$)))         & \{\emph{len1}\}     \\
$=$ & (+ 1 (+ (len ($x_2$ $x_3$)) (len $ys$)))        & \{L(2)\}            \\
$=$ & (+ (+ 1 (len ($x_2$ $x_3$))) (len $ys$))        & \{$+$ associative\} \\
$=$ & (+ (len (cons $x_1$ ($x_2$ $x_3$))) (len $ys$)) & \{\emph{len1}\}     \\
$=$ & (+ (len ($x_1$ $x_2$ $x_3$)) (len $ys$))        & \{\emph{cons}\}     \\
\end{tabular}
\end{center}

By now, it's easy to see how to derive L(4) from L(3), then L(5) from L(4), and so on. If you had the time and patience, you could surely prove L(100), L(1000), or even L(1000000) by deriving the next one from the one you just finished proving, following the established pattern. We could even write a program to print out the proof of L($n$), given any natural number $n$.

Since we know how to prove L($n$) for any natural number $n$, it seems fair to say that we know all those equations are true. However, to complete proof of the formula ($\forall$$n$.L($n$)), we need a rule of inference that allows us to make conclusions from patterns like those we observed in proving L(1), L(2), and so on. That rule of inference is known as ``mathematical induction''.

Mathematical induction provides a way to prove that formulas like ($\forall$$n$.P($n$)) are true when P is a predicate whose universe of discourse is the natural numbers. If for each natural number $n$, P($n$) stands for a proposition, then mathematical induction is an applicable inference rule in a proof that is ($\forall$$n$.P($n$)) true. That is not to say that such a proof can be constructed. It's just that mathematical induction might provide some help in the process.

The rule goes as follows: one can infer the truth of ($\forall$$n$.P($n$)) from proofs of two other propositions. Those two propositions are P(0) and ($\forall$$n$.(P($n$)$\rightarrow$P($n+1$))). It's a very good deal if you think about it. A direct proof of ($\forall$$n$.P($n$)) would require a proof of proposition P($n$) for each value of $n$ (0, 1, 2, \dots). But, in a proof by induction, the only proposition that needs to be proved on its own is P(0). In the proof any of the other propositions, you are allowed to cite the previous one in the sequence as a justification for any step in the proof.

The reason you can assume that P($n$) is true in the proof of P($n+1$) is because the goal is to prove that the formula P($n$)$\rightarrow$P($n+1$) has the value ``true''. We know from the truth table of the implication operator (see page \pageref{implication-truth-table}) that the formula P($n$)$\rightarrow$P($n+1$) is true when P($n$) is false. So, we only need to verify that the formula is true when P($n$) is true. The formula will be true in this case when P($n+1$) is true. So, all we need to prove is that P($n+1$) under the assumption that P($n$) is true.

That is, in the proof of P($n+1$), you can cite P($n$) to justify any step in the proof. P($n$) gives you a leg up in the proof of P($n+1$) and is known as the ``induction hypothesis''.

\begin{figure}
\begin{center}
\begin{tabular}{l}
Prove P(0) \\
Prove ($\forall$$n$.(P($n$)$\rightarrow$P($n+1$))) \\
\hline
Infer ($\forall$$n$.P($n$))
\end{tabular}
\end{center}
\caption{Mathematical Induction--a rule of inference}
\label{fig-04-01}
\end{figure}

Now, let's apply mathematical induction to prove the additive law of concatenation. Here, the predicate that we will apply the method to is L:

\begin{quote}
\begin{tabbing}
L($n$) $\equiv$ (= \=(len (append ($x_1$ $x_2$ \dots $x_n$) $ys$))  \\
                   \>(+ (len ($x_1$ $x_2$ \dots $x_n$)) (len $ys$)))
\end{tabbing}
\end{quote}

\label{len-additive-thm}
We have already proved L(0). All that is left is to prove ($\forall$$n$.(L($n$)$\rightarrow$L($n+1$))). That is, we have to derive L($n+1$) from L($n$) for an arbitrary natural number $n$. Fortunately, we know how to do this. Just copy the derivation of, say L(3) from L(2), but start with an append formula in which the first operand is a list with $n+1$ elements, and cite L($n$) where we would have cited L(3).

\begin{center}
\begin{tabular}{lll}
    & (len (append ($x_1$ $x_2$ \dots $x_{n+1}$) $ys$))         &                     \\
$=$ & (len (append (cons $x_1$ ($x_2$ \dots $x_{n+1}$)) $ys$))  & \{\emph{cons}\}     \\
$=$ & (len (cons $x_1$ (append ($x_2$ \dots $x_{n+1}$) $ys$)))  & \{\emph{app1}\}     \\
$=$ & (+ 1 (len (append ($x_2$ \dots $x_{n+1}$) $ys$)))         & \{\emph{len1}\}     \\
$=$ & (+ 1 (+ (len ($x_2$ \dots $x_{n+1}$)) (len $ys$)))        & \{L($n$)\}          \\
$=$ & (+ (+ 1 (len ($x_2$ \dots $x_{n+1}$))) (len $ys$))        & \{$+$ associative\} \\
$=$ & (+ (len (cons $x_1$ ($x_2$ \dots $x_{n+1}$))) (len $ys$)) & \{\emph{len1}\}     \\
$=$ & (+ (len ($x_1$ $x_2$ \dots $x_{n+1}$)) (len $ys$))        & \{\emph{cons}\}     \\
\end{tabular}
\end{center}

An important point to notice in this proof is that we could not cite the \{\emph{cons}\} equation to replace ($x_2$ \dots $x_{n+1}$) with (cons $x_2$ ($x_3$ \dots $x_{n+1}$)). The reason we could not do this is that we are trying to derived L($n+1$) from L($n$) without making any assumptions about $n$ other than the fact that it is a natural number. Since zero is a natural number, the list ($x_2$ \dots $x_{n+1}$) could be empty, and the cons operation cannot deliver an empty list as its value.

In the next section, we will prove some properties of append that confirm its correctness with respect to a specification in terms of other operators. These properties, and in fact all properties of the append operator, can be derived from the append theorem. That theorem states properties of the append operation in two cases: (1)~when the first operand is the empty list (the \{\emph{app0}\} equation), and (2)~when the first operand is a non-empty list (the \{\emph{app1}\} equation). When the first operand is the empty list, the result must be the second operand, no matter what it is. When the first operand is not empty, it must have a first element. That element must also be the first element of the result. The other elements of the result are the ones you would get if you appended the rest of the first operand with the second operand.

Both of these properties are so straightforward and easy to believe that we would probably be willing to accept them as axioms, with no proof at all. It might come as a surprise that all of the other properties of the append operation can be derived from the two simple properties \{\emph{app0}\} and \{\emph{app1}\}. That is the power of mathematical induction. The two equations of the append theorem amount to an inductive definition of the append operator.

An inductive definition is circular in the sense that some of the equations in the definition refer to the operator on both sides of the equation. Most of the time, we think circular definitions are not useful, so it may seem surprising that they can be useful in mathematics. Some aren't, but some of them are, and you will gradually learn how to recognize and create useful, circular (that is, inductive) definitions.

\begin{figure}
\begin{center}
\begin{tabular}{lp{3.5in}}
\emph{Complete} & All possible combinations of operands are covered by at least one equation in the definition. \\
\emph{Consistent} & Combinations of operands covered by by two or more equations imply the same value for the operation. \\
\emph{Computational} & There is at least one non-inductive equation, and all invocations of the operator on the right-hand side of inductive equations have operands that are closer to the operands on the left-hand side of a non-inductive equation than the operands on the left-hand side of the inductive equation. (An inductive equations refer to the operator being defined on both sides of the equation.)
\end{tabular}
\caption{Key to Inductive Definition: The Three C's}
\end{center}
\label{fig:inductive-def-keys}
\end{figure}

It turns out that all functions that can be defined in software have inductive definitions in the style of the equations of the append theorem. The keys to an inductive definition of an operator are listed in Figure~\ref{fig:inductive-def-keys}
(see page \pageref{fig:inductive-def-keys}). All of the software we will discuss will take the form of a collection of inductive definitions of operators. That makes it possible to use mathematical induction as the fundamental tool in verifying properties of that software to a logical certainty.

This is not the only way to write software. In fact, most software is not written in terms of inductive definitions. But, properties of the software written using conventional methods cannot be derived using conventional logic. So, in terms of understanding what computers do and how they do it, inductive definitions provide solid footing. That is why we base our presentation on software written in terms of inductive definitions rather than by conventional methods.


\section{Contatenation, Prefixes, and Suffixes}
\label{sec:append-prefix-suffix}
%%% in this section, prove the correctness of append
%%% with respect to a (prefix n xs) operator and (nthcdr n xs).

If you concatenate two lists, $xs$ and $ys$, you would expect to be able to retrieve the elements of $ys$ by dropping some of the elements of the concatenated lists. How many elements would you need to drop? That depends on the number of elements in $xs$. If there are $n$ elements in $xs$, and you drop $n$ elements from (append $xs$ $ys$), you expect the result to be identical to the list $ys$. We can state that expectation by using an intrinsic operation in ACL2 with the arcane name ``nthcdr''. The nthcdr operation takes two arguments: a natural number and a list. The formula (nthcdr $n$ $xs$) delivers a list like $xs$, but without its first $n$ elements. If $xs$ has fewer than $n$ elements, then the formula delivers the empty list.

\begin{comment}
ACL2 can prove this theorem, but the proof requires knowing something about the algebra of numbers. Fortunately, someone has worked out a basic theory of numeric algebra in ACL2 terms, and we can take advantage of that by importing it into our working environment. To do this, we use a command called ``include-book''. The name of the ``book'' with the theory we need is ``arithmetic/top'', and it resides in the ``system'' directory of ACL2.

\begin{lstlisting}
(include-book "arithmetic/top" :dir :system)
(defthmd append-suffix-thm
  (equal (nthcdr (len xs) (append xs ys))
         ys))
\end{lstlisting}

Let's see how we could prove this theorem. We would need to know some properties of the nthcdr operation. The following are three properties that are so easily believable, we are going to take them as axioms. The symbol $n$ stands for a natural number in these axioms. They would not be true if $n$ were, say, $-1$.
\end{comment}

The following equations state some simple properties of the nthcdr operation that we take as axioms.

\label{nthcdr-equations}
\begin{center}
\begin{tabular}{ll}
Axioms \{\emph{nthcdr}\}                               &                     \\
(nthcdr 0 $xs$) = $xs$                                 & \{\emph{sfx0}\}     \\
(nthcdr $n$ nil) =  nil                                & \{\emph{sfx-nil}\}  \\
(nthcdr (+ $n$ 1) (cons $x$ $xs$)) = (nthcdr $n$ $xs$) & \{\emph{sfx1}\}     \\
\end{tabular}
\end{center}


\todo{Rex: sfx1 isn't true, right?  I'm not sure we want to introduce it as an axiom, if later we'll have to explain it isn't really true. Ruben: left as is for now, with (natp n) implicit, but inserted a comment about the type of n}

Given this background, we state the expected relationship between the append and nthcdr operators in terms of a sequence of special cases. We will use S($n$) as a shorthand for special case number $n$. There will be one case for each natural number.

\begin{center}
\begin{tabular}{lll}
S($n$) $\equiv$ (equal & (nthcdr & (len ($x_1$ $x_2$ \dots $x_n$))          \\
                       &         & (append ($x_1$ $x_2$ \dots $x_n$) $ys$)) \\
                       & $ys$)   &                                          \\
\end{tabular}
\end{center}

 If S($n$) to be true, regardless of what natural number $n$ stands for, then the formula ($\forall$$n$.S($n$)) is true. Since the universe of discourse of the predicate S is the natural number, mathematical induction may be useful in verifying that formula. All we need to do is to prove that (1)~the formula S(0) is true and (2)~the formula S($n+1$) is true under the assumption that S($n$) is true, regardless of what natural number $n$ stands for. Let's do that.

First, we prove S(0). When $n$ is zero, the list ($x_1$ $x_2$ \dots $x_n$) is empty, which is normally denoted by the symbol ``nil''. So, S(0) stands for the following equation.

\begin{center}
\begin{tabular}{ll}
S(0) $\equiv$ (equal & (nthcdr (len nil) (append nil $ys$)) \\
                     & $ys$)                                \\
\end{tabular}
\end{center}

Following our usual practice when proving an equation, we start with the formula on one side and use previously known equations to gradually transform that formula to the one on the other side of the equation.

\begin{center}
\begin{tabular}{lll}
    & (nthcdr (len nil) (append nil $ys$))  &                                                      \\
$=$ & (nthcdr (len nil) $ys$)               & \{\emph{app0}\} (see page \pageref{append-equations})\\
$=$ & (nthcdr 0 $ys$)                       & \{\emph{len0}\} (see page \pageref{len-equations})   \\
$=$ & $ys$                                  & \{\emph{sfx0}\}                                      \\
\end{tabular}
\end{center}

That takes care of S(0). Next, we prove S($n+1$), assuming that S($n$) is true.

\begin{center}
\begin{tabular}{lll}
S($n+1$) $\equiv$ (equal & (nthcdr & (len ($x_1$ $x_2$ \dots $x_{n+1}$))          \\
                         &         & (append ($x_1$ $x_2$ \dots $x_{n+1}$) $ys$)) \\
                         & $ys$)   &                                              \\
\end{tabular}
\end{center}

\begin{center}
\begin{tabular}{llll}
    & (nthcdr & (len ($x_1$ $x_2$ \dots $x_{n+1}$))          & \\
    &         & (append ($x_1$ $x_2$ \dots $x_{n+1}$) $ys$)) & \\
$=$ & (nthcdr & (len (cons $x_1$ ($x_2$ \dots $x_{n+1}$)))          & \{\emph{cons}\} (page \pageref{cons-axiom-informal}) \\
    &         & (append (cons $x_1$ ($x_2$ $x_2$ \dots $x_{n+1}$)) $ys$)) & \{\emph{cons}\}                                    \\
$=$ & (nthcdr & (+ (len ($x_2$ \dots $x_{n+1}$)) 1)                 & \{\emph{len1}\} (page \pageref{len-equations})       \\
    &         & (cons $x_1$ (append ($x_2$ \dots $x_{n+1}$)) $ys$)) & \{\emph{app1}\} (page \pageref{append-equations})    \\
$=$ & (nthcdr & (len ($x_2$ \dots $x_{n+1}$))                       & \{\emph{sfx1}\}                                          \\
    &         & (append ($x_2$ \dots $x_{n+1}$) $ys$))              &                                                          \\
$=$ & $ys$    &                                                     & \{S($n$)\}                                              \\
\end{tabular}
\end{center}

The last step in the proof is justified by citing S($n$). This is a little tricky because the formula that S($n$) stands for is not exactly the same as the formula in the next-to-last step of the proof. We interpret the formula ($x_1$ $x_2$ \dots $x_n$) in the definition of S($n$) to stand for any list with $n$ elements. The elements in the list ($x_2$ \dots $x_{n+1}$) are numbered 2 through $n+1$, which means there must be exactly $n$ of them.

With this interpretation, the formula in the next-to-last step matches the formula in the definition of S($n$), which makes it legitimate to cite S($n$) to justify the transformation to $ys$ in the last step of the proof. We will use this interpretation frequently in proofs. We refer to it as the ``numbered-list interpretation'', or \{\emph{nlst}\} for short.

\label{numbered-list-interpretation}
\begin{center}
($x_m$ \dots $x_n$) denotes a list with max($n-m+1$, 0) elements \{\emph{nlst}\}
\end{center}

\todo{Rex: We may want to skip this paragraph for now.  We can introduce this notation later, when needed. Ruben: right, done}
\begin{comment}
Sometimes, we will take this interpretation even further: ($x_m$ $x_{m+k}$ \dots $x_n$) stands for a list with
max($\lceil \frac{n - m + 1}{k} \rceil$, 0)
elements, where $\lceil x \rceil$ means the next integer that is $x$ or more. For example, both of the following formulas stand for the number 2: $\lceil \frac {4}{3}\rceil$, $\lceil \frac {4}{2}\rceil$. We will take the numbered-list interpretation \{\emph{nlst}\} to include this more general pattern, where subscripts in a numbered list may stride along leaving gaps of a certain, fixed size in between.

At this point, we know that (append $xs$ $ys$) delivers a list that has the right elements at the end. How about the beginning? We expect the concatenation to start with the elements of the list $xs$, so if we extract the first $n$ elements of (append $xs$ $ys$), where $n$ is (len $xs$), we would expect to get a list identical to $xs$. To express this expectation formally, we need a function that, given a number $n$ and a list $xs$, delivers the first $n$ elements of $xs$. Let's call that function ``prefix'' and think about properties it would have to satisfy.

Of course, if $n$ is zero, or if $xs$ is empty, (prefix $n$ $xs$) must be the empty list. If $n$ is non-zero natural number and $xs$ is not empty, then the first element of (prefix $n$ $xs$) must be the first element of $xs$, the the other elements must be the first $n-1$ elements of (rest $xs$). The following theorem puts these expectations in formal terms. The formula (posp $n$) refers to the intrinsic ACL2 operator ``posp''. It is true if $n$ is a non-zero natural number (that is, a strictly positive integer) and false otherwise.

\begin{lstlisting}
(defthmd prefix-thm
  (equal (prefix n xs)
         (if (and (posp n)
                  (consp xs))
             (cons (first xs)                 ; {pfx1}
                   (prefix (- n 1) (rest xs)))
             nil)))                           ; {pfx0}
\end{lstlisting}

These two equations are consistent, and they cover all the possibilities. They are also foundational and computational, in the sense of Figure \ref{fig:inductive-def-keys}. So, all properties that the prefix function satisfies can be derived from these equations. They comprise a definition of the function.
\end{comment}

Of course, if $n$ is zero, or if $xs$ is empty, (prefix $n$ $xs$) must be the empty list. If $n$ is non-zero natural number and $xs$ is not empty, then the first element of (prefix $n$ $xs$) must be the first element of $xs$, the the other elements must be the first $n-1$ elements of (rest $xs$). The following equations, which we take as axioms, put these expectations in formal terms. The formula (posp $n$) refers to the intrinsic ACL2 operator ``posp''. It is true if $n$ is a non-zero natural number (that is, a strictly positive integer) and false otherwise.

\label{prefix-equations}
\begin{center}
\begin{tabular}{ll}
Axioms \{\emph{prefix}\}                                           \\
(prefix 0 xs) = nil                          & \{\emph{pfx0}\}     \\
(prefix n nil) =  nil                        & \{\emph{pfx-nil}\}  \\
(prefix (+ n 1) (cons x xs)) = (prefix n xs) & \{\emph{pfx1}\}     \\
\end{tabular}
\end{center}

\begin{comment}
The prefix operator is not intrinsic in ACL2, but we can use ``defun'' to add it to the collection. In the definition, we provide a name for the function and state the equations that determine its computational properties. The equations take the same form in the definition as in a theorem, but a function definition must also specify the names it will use to refer the arguments of the function. Those names, which we refer to as the ``formal arguments'' or ``formal parameters'', appear as a list following the name of the function in the defun.

\begin{lstlisting}
(defun prefix (n xs)
  (if (and (posp n)
           (consp xs))
      (cons (first xs)                 ; {pfx1}
            (prefix (- n 1) (rest xs)))
      nil))                            ; {pfx0}
\end{lstlisting}

With this definition in place, you can observe the results of computing prefixes by entering formulas in the command panel of Dracula. That is the lower left panel, just below the one containing the definitions. The command panel is activated by pressing the Dracula Run button. Then, Dracula will respond to the formula (prefix 3 '(5 3 9 3 8)) with value (5 3 9). Try it out. Enter a formula invoking the prefix function and observe the response, just to get familiar with the operation.

We can state the prefix property of the append function in the form of a theorem. However, there is a technicality that needs to be discussed before stating the theorem. The cons operator produces a list when its second operand is a list, but it produces a different kind of object when its second argument is not a list. ACL2 provides an operator called ``true-listp'' that distinguishes between lists and other kinds of objects that the cons function can construct. So, (true-listp $xs$) is true when $xs$ is a list and false when it is some other kind of object.

When the first operand in the invocation of append is not a list, the prefix property fails to hold, and the theorem must take this into account. To do so, the theorem takes the form of an implication in which the hypothesis requires the first operand of append to be a list. Under that condition, it is correct to conclude that the prefix of the concatenation matches the first argument. That leads to the following formulation of the prefix property of the append operation.

\begin{lstlisting}
(defthmd append-prefix-thm
  (implies (true-listp xs)
           (equal (prefix (len xs) (append xs ys))
                  xs)))
\end{lstlisting}

ACL2 succeeds in proving this theorem on its own, but a little more practice with proof by mathematical induction won't hurt us, so let's do a paper-and-pencil proof ourselves. In our proof we will assume, as usual, that the notation ($x_1$ $x_2$ \dots $x_n$) stands for a list, so we don't need to worry about the hypothesis in the implication. It is automatically satisfied, and we can focus on the conclusion. As before, we will use P($n$) as a shorthand for special case number $n$.
\end{comment}

We can derive the prefix property of the append function from the equations for the prefix and append operations.
The proof will cite mathematical induction.  As before, we will use a shorthand for special case number $n$.

\todo{Rex: Should we replace xs with (x1 x2 ... xn). Ruben: right, done}

\begin{quote}
\begin{tabbing}
P($n$) $\equiv$ (equal \=(prefix \=(len ($x_1$ $x_2$ \dots $x_n$))          \\
                       \>        \>(append ($x_1$ $x_2$ \dots $x_n$) $ys$)) \\
                       \>($x_1$ $x_2$ \dots $x_n$))                         \\
\end{tabbing}
\end{quote}

We will prove that P(0) is true, and also that P($n+1$) is true whenever P($n$) is true. Then, we will cite mathematical induction to conclude that P($n$) is true, regardless of which natural number $n$ stands for.

\begin{quote}
\begin{tabbing}
P($n$) $\equiv$ (equal \=(prefix \=(len nil)          \\
                       \>        \>(append nil $ys$)) \\
                       \>nil)                         \\
\end{tabbing}
\end{quote}

As in the proof of the append suffix theorem, we start with the formula on one side of the equation and use known equations to gradually transform that formula to the one on the other side of the equation.

\begin{center}
\begin{tabular}{lll}
    & (prefix (len nil) (append nil $ys$))  &                                                      \\
$=$ & (prefix 0 (append nil $ys$))          & \{\emph{len0}\} (see page \pageref{len-equations})   \\
$=$ & nil                                   & \{\emph{pfx0}\}                                      \\
\end{tabular}
\end{center}

That takes care of P(0). Next, we prove P($n+1$), assuming that P($n$) is true.

\begin{quote}
\begin{tabbing}
P($n+1$) $\equiv$ (equal \=(prefix \=(len ($x_1$ $x_2$ \dots $x_{n+1}$))        \\
                       \>        \>(append ($x_1$ $x_2$ \dots $x_{n+1}$) $ys$)) \\
                       \>($x_1$ $x_2$ \dots $x_{n+1}$))                         \\
\end{tabbing}
\end{quote}

\todo{Rex: This following indentation isn't perfect, but it's close.  I haven't figured out how to remove the vertical space before the tabbing, though I can probably hack it....}

\begin{center}
	\setlength{\topsep}{0pt}
	\setlength{\partopsep}{0pt}
\begin{tabular} {lp{3in}p{1.5in}}
    & \begin{tabbing}
			(prefix \=(len ($x_1$ $x_2$ \dots $x_{n+1}$)) \\
         	        \>(append ($x_1$ $x_2$ \dots $x_{n+1}$) $ys$))
		\end{tabbing}
	& \\
$=$ & \begin{tabbing}
		(prefix \=(len (cons $x_1$ ($x_2$ \dots $x_{n+1}$))) \\
                \>(append (cons $x_1$ ($x_2$ $x_2$ \dots $x_{n+1}$)) $ys$))
		\end{tabbing}
	& \{\emph{cons}\} (page \pageref{cons-axiom-informal}) \\
$=$ & \begin{tabbing}
			(prefix \=(+ (len ($x_2$ \dots $x_{n+1}$)) 1) \\
                    \>(cons $x_1$ (append ($x_2$ \dots $x_{n+1}$) $ys$)))
		\end{tabbing}
    & \{\emph{len1}\} (page \pageref{len-equations}) \hfill\break
      \{\emph{app1}\} (page \pageref{append-equations})    \\

$=$ & \begin{tabbing}
		(cons \=(first (cons $x_1$ ($x_2$ \dots $x_{n+1}$))) \\
			  \>(prefix \=(- (+ (len ($x_2$ \dots $x_{n+1}$)) 1) 1) \\
			  \>        \>(rest (cons $x_1$ (append ($x_2$ \dots $x_{n+1}$) $ys$)))))
		\end{tabbing}
	& \{\emph{pfx1}\} \\
$=$ & \begin{tabbing}
		(cons \=$x_1$ \\
			  \>(prefix \=(len ($x_2$ \dots $x_{n+1}$)) \\
			  \>        \>(append ($x_2$ \dots $x_{n+1}$) $ys$)))
		\end{tabbing}
	& \{\emph{first}\} (page \pageref{first-rest-cons}) \hfill\break
	  \{\emph{arithmetic}\} \hfill\break
	  \{\emph{rest}\} (page \pageref{first-rest-cons}) \\
$=$ & \begin{tabbing}
		(cons \=$x_1$ \\
			  \>($x_2$ \dots $x_{n+1}$) )
		\end{tabbing}
	& \{P($n$)\} \\
$=$ & ($x_1$ $x_2$ \dots $x_{n+1}$) & \{\emph{cons}\} (page \pageref{cons-axiom-informal}) \\
\end{tabular}
\end{center}

At this point we know three important facts about the append function:
\begin{itemize}
\item additive length theorem: (len (append $xs$ $ys$)) = (+ (len $xs$) (len $ys$))
\item append-prefix theorem: (prefix (len $xs$) (append $xs$ $ys$)) = $xs$
\item append-suffix theorem: (nthcdr (len $xs$) (append $xs$ $ys$)) = $ys$
\end{itemize}

Together, these theorems provide a deep level of understanding of the append operation. They give us confidence that it correctly concatenates lists. We refer to these theorems as ``correctness properties'' for the append operation. They are, of course, an infinite variety of other facts about the append operation. Their relative importance depends on how we are using the operation.

A property that is sometimes important to know is that concatenation is ``associative''. That is, if there are three lists to be concatenated, you you could concatenate the first list with the concatenation of the last two. Or, you could concatenate the first two, then append that with the third.

\begin{quote}
\label{app-assoc}
Theorem \{\emph{app-assoc}\} \\
(append $xs$ (append $ys$ $zs$)) = (append (append $xs$ $ys$) $zs$)
\end{quote}

Addition and multiplication of numbers are associative in an analogous way (but subtraction and division aren't associative). Another way to say this is that the formula ($\forall$$n$.A($n$)) is true, where the predicate A is defined as follows.

\begin{center}
\begin{tabular} {lll}
A($n$) $\equiv$  & (equal & (append ($x_1$ $x_2$ \dots $x_n$) (append $ys$ $zs$)) \\
                 &        & (append (append ($x_1$ $x_2$ \dots $x_n$) $ys$) $zs$) \\
\end{tabular}
\end{center}

Putting it this way makes the theorem amenable to a proof by mathematical induction. We leave that as a something you can use to practice your proof skills.

\todo{Ruben: The ExerciseList tag doesn't put in any vertical space, but should, I think.}

\begin{ExerciseList}
\Exercise Carry out a paper-and-pencil proof by mathematical induction of the \{\emph{app-assoc}\} theorem.

\begin{comment}
\todo{Rex: I don't understand your hint below.  Is it necessary? Ruben: Sorry. Thought they were necessary assumptions. Will omit them in the section that introduces proofs using mechanized logic.}

\Exercise State the \{\emph{app-assoc}\} theorem in ACL2 notation.
(\emph{Hint}. The theorem must be stated in the form of an implication whose hypothesis requires the objects $xs$ and $ys$ in the definition of A($n$) must be lists, so you will need to state the theorem as an implication whose hypothesis invokes the true-listp function twice to require $xs$ and $ys$ to be lists. The conclusion of the implication will, of course, be the equation between the two concatenation formulas that interchange the concatenation order.)

\Exercise Use Dracula to produce a mechanized proof of the \{\emph{app-assoc}\} theorem.
\end{comment}

\end{ExerciseList}

\todo{next section will introduce defthmd and proofs using the ACL2 mechanized logic by replaying all of the theorems of this section in ACL2 notation}

\section{Mechanized Logic}
\label{sec:mech-logic}
The proofs we have been doing depend on matching grammatical elements in formulas against templates in axioms and theorems. The formulas are then transformed to equivalent ones with different grammatical structures. Gradually, we move from a starting formula to a concluding one to verify an equation for a new theorem.

It is easy to make mistakes in this detailed, syntax-matching process, but computers carry it out flawlessly. This relieves us from an obligation to focus with monk-like devotion on the required grammatical analysis. We can leave it to the computer count on having it done right.

There are several mechanized logic systems that people use to assist with proofs of the kind we have been doing. One of them is ACL2 (A Computational Logic for Applicative Common Lisp). Theorems for the ACL2 proof engine are stated in the same form as properties for the DoubleCheck testing facility in Dracula. ACL2 has a built-in strategy for finding inductive proofs, and for some theorems it succeeds in fully automating proofs. It also permits people to guide it through proofs while it pushes through all of the grammatical details.

To illustrate how this works, we will go the theorems discussed earlier in this chapter, one by one. The notation for stating theorems in ACL2 form will be familiar, but not identical to the one we have been using for our paper-and-pencil proofs. For one thing, it employs prefix notation throughout, and we have been using a mixture of prefix and infix.

Our first proof by mathematical induction verified the additive law of concatenation (see page \pageref{additive-law-concatenation}). Our statement of the theorem asserted that a proposition L($n$) is true, regardless of which natural number $n$ stands for: ($\forall$$n$.L($n$)). L($n$) is a shorthand for the following formula:
\begin{quote}
\begin{tabbing}
L($n$) $\equiv$ (= \=(len (append ($x_1$ $x_2$ \dots $x_n$) $ys$))  \\
                   \>(+ (len ($x_1$ $x_2$ \dots $x_n$)) (len $ys$)))
\end{tabbing}
\end{quote}

We could have used the DoubleCheck facility of Dracula to run tests on this property.

\begin{lstlisting}
(defproperty additive-law-of-concatenation-tst
    (xs :value (random-list-of (random-natural))
     ys :value (random-list-of (random-natural)))
  (= (len (append xs ys))
     (+ (len xs) (len ys))))
\end{lstlisting}

Of course, the DoubleCheck specification of this property cannot employ the informal notation of the numbered list interpretation (see page \pageref{numbered-list-interpretation}). Instead, the property simply uses a symbol $xs$ to stand for the list. The property does not state the length of $xs$, but we know its length will be some natural number, $n$, so the property, as stated, has the same meaning as the formula that L($n$) stands for.

The statement of the additive law as a theorem in the form required by ACL2 cannot use the informal notation, either. In fact, the theorem takes a form that is like the property specification, except for the :value portion and the keyword ``defproperty''.

Theorem statements in ACL2 start with the ``defthmd'' keyword. After that comes a name for the theorem and the Boolean formula that expresses the meaning of the theorem, as illustrated in the following definition.

\begin{lstlisting}
(defthmd additive-law-of-concatenation-thm
  (= (len (append xs ys))
     (+ (len xs) (len ys))))
\end{lstlisting}

The mechanized logic of ACL2 fully automates the proof of this theorem. It uses a built-in, heuristic procedure to find an induction scheme and pushes the proof through on its own. To see ACL2 in action, enter the above theorem in the program pane of the Dracula window (the upper left pane), press the start button in the ACL2 pane (the right half of the ACL2 window). When the Admit button lights up, press it.

After a short time, the theorem will turn green, indicating a successful proof. Details of the proof appear in the ACL2 pane. Later we will learn how to interpret some of these details, but for now, we are just looking for success (green coloring of the theorem in the program pane) or failure (red coloring).

Probably you can follow the above example to convert all theorems from this chapter into ACL2 theorem statements. Just to make sure, we will look at another one, then leave the rest for practice exercises.

The append-suffix theorem, which states that when the first argument in an append formula is a list of length $n$, then you can reconstruct the second argument by dropping $n$ elements from the front of the concatenation. We stated this this theorem in the form ($\forall$$n$.S($n$)), where S($n$) is a shorthand for the following formula.

\begin{center}
\begin{tabular}{lll}
S($n$) $\equiv$ (equal & (nthcdr & (len ($x_1$ $x_2$ \dots $x_n$))          \\
                       &         & (append ($x_1$ $x_2$ \dots $x_n$) $ys$)) \\
                       & $ys$)   &                                          \\
\end{tabular}
\end{center}

The following definition specifies this theorem in ACL2 notation.

\begin{lstlisting}
(defthmd append-suffix-thm
  (equal (nthcdr (len xs) (append xs ys))
         ys))
\end{lstlisting}

ACL2 can prove this theorem, but the proof requires knowing something about the algebra of numbers, such as the associative law of addition. Fortunately, someone has worked out a basic theory of numeric algebra in ACL2 terms, and we can take advantage of that by importing it into the working environment. To do this, we use a command called ``include-book''. The name of the book with the theory we need is ``arithmetic/top'', and it resides in the ``system'' directory of ACL2.

\begin{lstlisting}
(include-book "arithmetic/top" :dir :system)
\end{lstlisting}

The include-book command makes that theory accessible to the mechanized logic. When you put the command above the append-suffix theorem in the program pane and press the start button and then the Admit All button, ACL2 succeeds in the proof without further assistance. For practice, try it yourself.

\begin{ExerciseList}
\Exercise Define the \{\emph{append-prefix}\} theorem in ACL2 notation, and use Dracula to run it through the mechanized logic. If you state it correctly, the proof should succeed.

\Exercise Define the \{\emph{append associativity}\} theorem in ACL2 notation, and use Dracula to run it through the mechanized logic. If you state it correctly, the proof should succeed.
\end{ExerciseList}

%%% this might be enough on induction and lists for now ... move on to next chapter: binary numerals and the ripple-carry adder

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "book"
%%% End:
